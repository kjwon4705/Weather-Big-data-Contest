{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d216edbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tslearn.preprocessing import TimeSeriesScalerMeanVariance\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sktime.transformations.panel.rocket import Rocket\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sktime.regression.kernel_based import RocketRegressor\n",
    "from sktime.datatypes._panel._convert import from_2d_array_to_nested\n",
    "from keras.layers import LSTM, Dense\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sktime.regression.deep_learning import CNNRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67011f5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def list_files_recursive(directory):\n",
    "    file_list = []  # 파일 이름을 저장할 빈 리스트를 생성\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for name in files:\n",
    "            file_list.append(os.path.join(root, name))  # 리스트에 파일 이름 추가\n",
    "    return file_list  # 리스트 반환\n",
    "\n",
    "# 사용 예:\n",
    "directory = \"./Test\" \n",
    "test_col = list_files_recursive(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5eb94c7",
   "metadata": {},
   "source": [
    "# LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "057a55f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_mae(weather):\n",
    "    # initialize result dictionaries\n",
    "    mae_results = {}\n",
    "    TC_pred_results = {}\n",
    "\n",
    "    train = pd.read_csv(\"Train_data.csv\")\n",
    "    train['Date'] = pd.to_datetime(train['Date'])\n",
    "\n",
    "    # Add filter for months based on weather\n",
    "    if weather == 'spring':\n",
    "        train = train[train['Date'].dt.month.isin([2, 3, 4])]\n",
    "    elif weather == 'summer':\n",
    "        train = train[train['Date'].dt.month.isin([5, 6, 7])]\n",
    "    elif weather == 'autumn':\n",
    "        train = train[train['Date'].dt.month.isin([8, 9, 10])]\n",
    "    elif weather == 'winter':\n",
    "        train = train[train['Date'].dt.month.isin([11, 12, 1])]\n",
    "\n",
    "    # 스케일러 생성\n",
    "    # 평균 0, 표준편차 1로 스케일링\n",
    "    scaler = StandardScaler()\n",
    "    y_scaler = StandardScaler()\n",
    "\n",
    "    # train 데이터로 스케일러 학습\n",
    "    x_train = scaler.fit_transform(train.iloc[:,2:12])\n",
    "    y_train = y_scaler.fit_transform(train.iloc[:,-1].values.reshape(-1, 1))\n",
    "    \n",
    "    for file in test_col:\n",
    "        if weather in file:\n",
    "            test = pd.read_csv(file, encoding = 'utf-8')\n",
    "            test['Date'] = pd.to_datetime(test['Date'])\n",
    "            \n",
    "            x_test = scaler.transform(test.iloc[:,2:12])\n",
    "            y_test = test.iloc[:,-1].values  # add this line\n",
    "\n",
    "            x_train_df = pd.DataFrame(x_train)\n",
    "            x_test_df = pd.DataFrame(x_test)\n",
    "\n",
    "            # Create a model\n",
    "            model = LinearRegression()\n",
    "\n",
    "            # Fit the model\n",
    "            model.fit(x_train_df, y_train)\n",
    "\n",
    "            # Make predictions\n",
    "            y_pred = model.predict(x_test_df)\n",
    "    \n",
    "            TC_pred = y_scaler.inverse_transform(y_pred.reshape(-1, 1))\n",
    "\n",
    "            # Evaluate the model\n",
    "            mae = mean_absolute_error(y_test, TC_pred)\n",
    "\n",
    "            # save the results with the filename as the key\n",
    "            filename = os.path.splitext(os.path.basename(file))[0]  # extract filename without extension\n",
    "            mae_results[filename] = mae\n",
    "            TC_pred_results[filename] = TC_pred\n",
    "\n",
    "    return mae_results, TC_pred_results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3a302f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_spring_mae, linear_spring_TC_pred = linear_mae('spring')\n",
    "linear_summer_mae, linear_summer_TC_pred = linear_mae('summer')\n",
    "linear_autumn_mae, linear_autumn_TC_pred = linear_mae('autumn')\n",
    "linear_winter_mae, linear_winter_TC_pred = linear_mae('winter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd58494a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert each dictionary to a DataFrame\n",
    "linear_spring_df = pd.DataFrame.from_dict(linear_spring_mae, orient='index', columns=['MAE'])\n",
    "linear_summer_df = pd.DataFrame.from_dict(linear_summer_mae, orient='index', columns=['MAE'])\n",
    "linear_autumn_df = pd.DataFrame.from_dict(linear_autumn_mae, orient='index', columns=['MAE'])\n",
    "linear_winter_df = pd.DataFrame.from_dict(linear_winter_mae, orient='index', columns=['MAE'])\n",
    "\n",
    "# Concatenate all the DataFrames along columns\n",
    "linear_mae_df = pd.concat([linear_spring_df, linear_summer_df, linear_autumn_df, linear_winter_df], axis=0)\n",
    "linear_mae_df.columns = ['linear_MAE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a97aa20b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'146_spring': 2.9587657016724505,\n",
       " '212_spring': 2.497689055714031,\n",
       " '245_spring': 3.265469056907144}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_spring_mae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cece89d",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46499e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgboost_model(weather):\n",
    "    # initialize result dictionaries\n",
    "    mae_results = {}\n",
    "    TC_pred_results = {}\n",
    "\n",
    "    train = pd.read_csv(\"Train_data.csv\")\n",
    "    train['Date'] = pd.to_datetime(train['Date'])\n",
    "\n",
    "    # Add filter for months based on weather\n",
    "    if weather == 'spring':\n",
    "        train = train[train['Date'].dt.month.isin([2, 3, 4])]\n",
    "    elif weather == 'summer':\n",
    "        train = train[train['Date'].dt.month.isin([5, 6, 7])]\n",
    "    elif weather == 'autumn':\n",
    "        train = train[train['Date'].dt.month.isin([8, 9, 10])]\n",
    "    elif weather == 'winter':\n",
    "        train = train[train['Date'].dt.month.isin([11, 12, 1])]\n",
    "\n",
    "    # 스케일러 생성\n",
    "    # 평균 0, 표준편차 1로 스케일링\n",
    "    scaler = StandardScaler()\n",
    "    y_scaler = StandardScaler()\n",
    "\n",
    "    # train 데이터로 스케일러 학습\n",
    "    x_train = scaler.fit_transform(train.iloc[:,2:12])\n",
    "    y_train = y_scaler.fit_transform(train.iloc[:,-1].values.reshape(-1, 1))\n",
    "    \n",
    "    for file in test_col:\n",
    "        if weather in file:\n",
    "            test = pd.read_csv(file)\n",
    "            test['Date'] = pd.to_datetime(test['Date'])\n",
    "            \n",
    "            x_test = scaler.transform(test.iloc[:,2:12])\n",
    "            y_test = test.iloc[:,-1].values  # add this line\n",
    "\n",
    "            x_train_df = pd.DataFrame(x_train)\n",
    "            x_test_df = pd.DataFrame(x_test)\n",
    "\n",
    "            # Create a model\n",
    "            model = XGBRegressor(objective='reg:squarederror', n_estimators=150)\n",
    "\n",
    "            # Fit the model\n",
    "            model.fit(x_train_df, y_train)\n",
    "\n",
    "            # Make predictions\n",
    "            y_pred = model.predict(x_test_df)\n",
    "    \n",
    "            TC_pred = y_scaler.inverse_transform(y_pred.reshape(-1, 1))\n",
    "\n",
    "            # Evaluate the model\n",
    "            mae = mean_absolute_error(y_test, TC_pred)\n",
    "\n",
    "            # save the results with the filename as the key\n",
    "            filename = os.path.splitext(os.path.basename(file))[0]  # extract filename without extension\n",
    "            mae_results[filename] = mae\n",
    "            TC_pred_results[filename] = TC_pred\n",
    "\n",
    "    return mae_results, TC_pred_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ca397e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_spring_mae, xgb_spring_TC_pred = xgboost_model('spring')\n",
    "xgb_summer_mae, xgb_summer_TC_pred = xgboost_model('summer')\n",
    "xgb_autumn_mae, xgb_autumn_TC_pred = xgboost_model('autumn')\n",
    "xgb_winter_mae, xgb_winter_TC_pred = xgboost_model('winter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38547b0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'146_spring': 2.8600666831613863,\n",
       " '212_spring': 2.733978886673924,\n",
       " '245_spring': 2.935691374791853}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_spring_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3535e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert each dictionary to a DataFrame\n",
    "xgb_spring_df = pd.DataFrame.from_dict(xgb_spring_mae, orient='index', columns=['MAE'])\n",
    "xgb_summer_df = pd.DataFrame.from_dict(xgb_summer_mae, orient='index', columns=['MAE'])\n",
    "xgb_autumn_df = pd.DataFrame.from_dict(xgb_autumn_mae, orient='index', columns=['MAE'])\n",
    "xgb_winter_df = pd.DataFrame.from_dict(xgb_winter_mae, orient='index', columns=['MAE'])\n",
    "\n",
    "# Concatenate all the DataFrames along columns\n",
    "xgb_mae_df = pd.concat([xgb_spring_df, xgb_summer_df, xgb_autumn_df, xgb_winter_df], axis=0)\n",
    "xgb_mae_df.columns = ['xgb_MAE']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b0529af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xgb_MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>146_spring</th>\n",
       "      <td>2.860067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212_spring</th>\n",
       "      <td>2.733979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245_spring</th>\n",
       "      <td>2.935691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146_summer</th>\n",
       "      <td>2.068598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212_summer</th>\n",
       "      <td>2.508226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245_summer</th>\n",
       "      <td>2.838604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146_autumn</th>\n",
       "      <td>1.506823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212_autumn</th>\n",
       "      <td>2.176668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245_autumn</th>\n",
       "      <td>2.125981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146_winter</th>\n",
       "      <td>1.665869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212_winter</th>\n",
       "      <td>1.850723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245_winter</th>\n",
       "      <td>2.309207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             xgb_MAE\n",
       "146_spring  2.860067\n",
       "212_spring  2.733979\n",
       "245_spring  2.935691\n",
       "146_summer  2.068598\n",
       "212_summer  2.508226\n",
       "245_summer  2.838604\n",
       "146_autumn  1.506823\n",
       "212_autumn  2.176668\n",
       "245_autumn  2.125981\n",
       "146_winter  1.665869\n",
       "212_winter  1.850723\n",
       "245_winter  2.309207"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_mae_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a8b67d",
   "metadata": {},
   "source": [
    "# RandomForest_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5e5f907",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def RandomForest_model(weather):\n",
    "    # initialize result dictionaries\n",
    "    mae_results = {}\n",
    "    TC_pred_results = {}\n",
    "\n",
    "    train = pd.read_csv(\"Train_data.csv\")\n",
    "    train['Date'] = pd.to_datetime(train['Date'])\n",
    "\n",
    "    # Add filter for months based on weather\n",
    "    if weather == 'spring':\n",
    "        train = train[train['Date'].dt.month.isin([2, 3, 4])]\n",
    "    elif weather == 'summer':\n",
    "        train = train[train['Date'].dt.month.isin([5, 6, 7])]\n",
    "    elif weather == 'autumn':\n",
    "        train = train[train['Date'].dt.month.isin([8, 9, 10])]\n",
    "    elif weather == 'winter':\n",
    "        train = train[train['Date'].dt.month.isin([11, 12, 1])]\n",
    "\n",
    "    # 스케일러 생성\n",
    "    # 평균 0, 표준편차 1로 스케일링\n",
    "    scaler = StandardScaler()\n",
    "    y_scaler = StandardScaler()\n",
    "\n",
    "    # train 데이터로 스케일러 학습\n",
    "    x_train = scaler.fit_transform(train.iloc[:,2:12])\n",
    "    y_train = y_scaler.fit_transform(train.iloc[:,-1].values.reshape(-1, 1))\n",
    "    \n",
    "    for file in test_col:\n",
    "        if weather in file:\n",
    "            test = pd.read_csv(file)\n",
    "            test['Date'] = pd.to_datetime(test['Date'])\n",
    "            \n",
    "            x_test = scaler.transform(test.iloc[:,2:12])\n",
    "            y_test = test.iloc[:,-1].values  # add this line\n",
    "\n",
    "            x_train_df = pd.DataFrame(x_train)\n",
    "            x_test_df = pd.DataFrame(x_test)\n",
    "\n",
    "            # Create a model\n",
    "            model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "            # Fit the model\n",
    "            model.fit(x_train_df, y_train.ravel())\n",
    "\n",
    "            # Make predictions\n",
    "            y_pred = model.predict(x_test_df)\n",
    "    \n",
    "            TC_pred = y_scaler.inverse_transform(y_pred.reshape(-1, 1))\n",
    "        \n",
    "            \n",
    "            # Evaluate the model\n",
    "            mae = mean_absolute_error(y_test, TC_pred)\n",
    "\n",
    "            # save the results with the filename as the key\n",
    "            filename = os.path.splitext(os.path.basename(file))[0]  # extract filename without extension\n",
    "            mae_results[filename] = mae\n",
    "            TC_pred_results[filename] = TC_pred\n",
    "\n",
    "    return mae_results, TC_pred_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aeb27bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest_spring_mae, randomforest_spring_TC_pred = RandomForest_model('spring')\n",
    "randomforest_summer_mae, randomforest_summer_TC_pred = RandomForest_model('summer')\n",
    "randomforest_autumn_mae, randomforest_autumn_TC_pred = RandomForest_model('autumn')\n",
    "randomforest_winter_mae, randomforest_winter_TC_pred = RandomForest_model('winter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "830f98d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert each dictionary to a DataFrame\n",
    "randomforest_spring_df = pd.DataFrame.from_dict(randomforest_spring_mae, orient='index', columns=['MAE'])\n",
    "randomforest_summer_df = pd.DataFrame.from_dict(randomforest_summer_mae, orient='index', columns=['MAE'])\n",
    "randomforest_autumn_df = pd.DataFrame.from_dict(randomforest_autumn_mae, orient='index', columns=['MAE'])\n",
    "randomforest_winter_df = pd.DataFrame.from_dict(randomforest_winter_mae, orient='index', columns=['MAE'])\n",
    "\n",
    "# Concatenate all the DataFrames along columns\n",
    "randomforest_mae_df = pd.concat([randomforest_spring_df, randomforest_summer_df, randomforest_autumn_df, randomforest_winter_df], axis=0)\n",
    "randomforest_mae_df.columns = ['randomforest_MAE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a83e9fe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>randomforest_MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>146_spring</th>\n",
       "      <td>1.874011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212_spring</th>\n",
       "      <td>2.730103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245_spring</th>\n",
       "      <td>2.948562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146_summer</th>\n",
       "      <td>1.105620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212_summer</th>\n",
       "      <td>2.329581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245_summer</th>\n",
       "      <td>2.794261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146_autumn</th>\n",
       "      <td>0.766125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212_autumn</th>\n",
       "      <td>1.947382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245_autumn</th>\n",
       "      <td>2.161125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146_winter</th>\n",
       "      <td>0.908747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212_winter</th>\n",
       "      <td>1.858714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245_winter</th>\n",
       "      <td>2.306708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            randomforest_MAE\n",
       "146_spring          1.874011\n",
       "212_spring          2.730103\n",
       "245_spring          2.948562\n",
       "146_summer          1.105620\n",
       "212_summer          2.329581\n",
       "245_summer          2.794261\n",
       "146_autumn          0.766125\n",
       "212_autumn          1.947382\n",
       "245_autumn          2.161125\n",
       "146_winter          0.908747\n",
       "212_winter          1.858714\n",
       "245_winter          2.306708"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomforest_mae_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19dd153a",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d863fdc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def MLP_model(weather):\n",
    "    # initialize result dictionaries\n",
    "    mae_results = {}\n",
    "    TC_pred_results = {}\n",
    "\n",
    "    train = pd.read_csv(\"Train_data.csv\")\n",
    "    train['Date'] = pd.to_datetime(train['Date'])\n",
    "\n",
    "    # Add filter for months based on weather\n",
    "    if weather == 'Spring':\n",
    "        train = train[train['Date'].dt.month.isin([3, 4, 5])]\n",
    "    elif weather == 'Summer':\n",
    "        train = train[train['Date'].dt.month.isin([6, 7, 8])]\n",
    "    elif weather == 'Autumn':\n",
    "        train = train[train['Date'].dt.month.isin([9, 10, 11])]\n",
    "    elif weather == 'Winter':\n",
    "        train = train[train['Date'].dt.month.isin([12, 1, 2])]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    y_scaler = StandardScaler()\n",
    "\n",
    "    x_train = scaler.fit_transform(train.iloc[:,2:12])\n",
    "    y_train = y_scaler.fit_transform(train.iloc[:,-1].values.reshape(-1, 1))\n",
    "    \n",
    "    for file in test_col:\n",
    "        if weather in file:\n",
    "            test = pd.read_csv(file)\n",
    "            test['Date'] = pd.to_datetime(test['Date'])\n",
    "            \n",
    "            x_test = scaler.transform(test.iloc[:,2:12])\n",
    "            y_test = test.iloc[:,-1].values  # add this line\n",
    "\n",
    "            x_train_df = pd.DataFrame(x_train)\n",
    "            x_test_df = pd.DataFrame(x_test)\n",
    "\n",
    "            # Create the model structure\n",
    "            model = Sequential()\n",
    "            model.add(Dense(64, input_dim=x_train_df.shape[1], activation='relu'))  # Input layer\n",
    "            model.add(Dense(32, activation='relu'))  # Hidden layer\n",
    "            model.add(Dense(1))  # Output layer\n",
    "\n",
    "            # Compile the model\n",
    "            model.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "\n",
    "            # Create early stopping\n",
    "            early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "            # Fit the model\n",
    "            model.fit(x_train_df, y_train, epochs=50, batch_size=64, verbose=2, callbacks=[early_stopping], validation_split=0.2)\n",
    "\n",
    "            # Make predictions\n",
    "            y_pred = model.predict(x_test_df)\n",
    "    \n",
    "            TC_pred = y_scaler.inverse_transform(y_pred)\n",
    "\n",
    "            # Evaluate the model\n",
    "            mae = mean_absolute_error(y_test, TC_pred)\n",
    "\n",
    "            # save the results with the filename as the key\n",
    "            filename = os.path.splitext(os.path.basename(file))[0]  # extract filename without extension\n",
    "            mae_results[filename] = mae\n",
    "            TC_pred_results[filename] = TC_pred\n",
    "\n",
    "    return mae_results, TC_pred_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96faf9ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5478/5478 - 4s - loss: 0.1800 - val_loss: 0.1790 - 4s/epoch - 690us/step\n",
      "Epoch 2/50\n",
      "5478/5478 - 3s - loss: 0.1720 - val_loss: 0.1830 - 3s/epoch - 587us/step\n",
      "Epoch 3/50\n",
      "5478/5478 - 3s - loss: 0.1705 - val_loss: 0.1894 - 3s/epoch - 577us/step\n",
      "Epoch 4/50\n",
      "5478/5478 - 3s - loss: 0.1697 - val_loss: 0.1830 - 3s/epoch - 583us/step\n",
      "Epoch 5/50\n",
      "5478/5478 - 3s - loss: 0.1689 - val_loss: 0.1880 - 3s/epoch - 601us/step\n",
      "Epoch 6/50\n",
      "5478/5478 - 3s - loss: 0.1684 - val_loss: 0.1841 - 3s/epoch - 584us/step\n",
      "Epoch 7/50\n",
      "5478/5478 - 3s - loss: 0.1681 - val_loss: 0.1876 - 3s/epoch - 585us/step\n",
      "Epoch 8/50\n",
      "5478/5478 - 3s - loss: 0.1677 - val_loss: 0.1850 - 3s/epoch - 592us/step\n",
      "Epoch 9/50\n",
      "5478/5478 - 3s - loss: 0.1675 - val_loss: 0.1828 - 3s/epoch - 601us/step\n",
      "Epoch 10/50\n",
      "5478/5478 - 3s - loss: 0.1672 - val_loss: 0.1811 - 3s/epoch - 607us/step\n",
      "Epoch 11/50\n",
      "5478/5478 - 3s - loss: 0.1669 - val_loss: 0.1889 - 3s/epoch - 616us/step\n",
      "70/70 [==============================] - 0s 482us/step\n",
      "Epoch 1/50\n",
      "5478/5478 - 4s - loss: 0.1806 - val_loss: 0.1804 - 4s/epoch - 672us/step\n",
      "Epoch 2/50\n",
      "5478/5478 - 3s - loss: 0.1721 - val_loss: 0.1801 - 3s/epoch - 593us/step\n",
      "Epoch 3/50\n",
      "5478/5478 - 3s - loss: 0.1706 - val_loss: 0.1837 - 3s/epoch - 597us/step\n",
      "Epoch 4/50\n",
      "5478/5478 - 3s - loss: 0.1696 - val_loss: 0.1826 - 3s/epoch - 597us/step\n",
      "Epoch 5/50\n",
      "5478/5478 - 3s - loss: 0.1690 - val_loss: 0.1852 - 3s/epoch - 594us/step\n",
      "Epoch 6/50\n",
      "5478/5478 - 3s - loss: 0.1685 - val_loss: 0.1889 - 3s/epoch - 598us/step\n",
      "Epoch 7/50\n",
      "5478/5478 - 3s - loss: 0.1681 - val_loss: 0.1859 - 3s/epoch - 597us/step\n",
      "Epoch 8/50\n",
      "5478/5478 - 3s - loss: 0.1678 - val_loss: 0.1854 - 3s/epoch - 602us/step\n",
      "Epoch 9/50\n",
      "5478/5478 - 3s - loss: 0.1674 - val_loss: 0.1812 - 3s/epoch - 597us/step\n",
      "Epoch 10/50\n",
      "5478/5478 - 3s - loss: 0.1672 - val_loss: 0.1870 - 3s/epoch - 600us/step\n",
      "Epoch 11/50\n",
      "5478/5478 - 3s - loss: 0.1669 - val_loss: 0.1850 - 3s/epoch - 589us/step\n",
      "Epoch 12/50\n",
      "5478/5478 - 3s - loss: 0.1668 - val_loss: 0.1857 - 3s/epoch - 589us/step\n",
      "70/70 [==============================] - 0s 498us/step\n",
      "Epoch 1/50\n",
      "5478/5478 - 4s - loss: 0.1800 - val_loss: 0.1864 - 4s/epoch - 672us/step\n",
      "Epoch 2/50\n",
      "5478/5478 - 3s - loss: 0.1725 - val_loss: 0.1806 - 3s/epoch - 589us/step\n",
      "Epoch 3/50\n",
      "5478/5478 - 3s - loss: 0.1709 - val_loss: 0.1833 - 3s/epoch - 591us/step\n",
      "Epoch 4/50\n",
      "5478/5478 - 3s - loss: 0.1697 - val_loss: 0.1839 - 3s/epoch - 591us/step\n",
      "Epoch 5/50\n",
      "5478/5478 - 3s - loss: 0.1689 - val_loss: 0.1786 - 3s/epoch - 592us/step\n",
      "Epoch 6/50\n",
      "5478/5478 - 3s - loss: 0.1684 - val_loss: 0.1833 - 3s/epoch - 601us/step\n",
      "Epoch 7/50\n",
      "5478/5478 - 3s - loss: 0.1680 - val_loss: 0.1785 - 3s/epoch - 595us/step\n",
      "Epoch 8/50\n",
      "5478/5478 - 3s - loss: 0.1678 - val_loss: 0.1838 - 3s/epoch - 599us/step\n",
      "Epoch 9/50\n",
      "5478/5478 - 3s - loss: 0.1677 - val_loss: 0.1835 - 3s/epoch - 594us/step\n",
      "Epoch 10/50\n",
      "5478/5478 - 3s - loss: 0.1673 - val_loss: 0.1850 - 3s/epoch - 596us/step\n",
      "Epoch 11/50\n",
      "5478/5478 - 3s - loss: 0.1671 - val_loss: 0.1847 - 3s/epoch - 597us/step\n",
      "Epoch 12/50\n",
      "5478/5478 - 3s - loss: 0.1670 - val_loss: 0.1829 - 3s/epoch - 597us/step\n",
      "Epoch 13/50\n",
      "5478/5478 - 3s - loss: 0.1667 - val_loss: 0.1828 - 3s/epoch - 598us/step\n",
      "Epoch 14/50\n",
      "5478/5478 - 3s - loss: 0.1665 - val_loss: 0.1824 - 3s/epoch - 585us/step\n",
      "Epoch 15/50\n",
      "5478/5478 - 3s - loss: 0.1665 - val_loss: 0.1849 - 3s/epoch - 591us/step\n",
      "Epoch 16/50\n",
      "5478/5478 - 3s - loss: 0.1662 - val_loss: 0.1829 - 3s/epoch - 591us/step\n",
      "Epoch 17/50\n",
      "5478/5478 - 3s - loss: 0.1661 - val_loss: 0.1818 - 3s/epoch - 596us/step\n",
      "70/70 [==============================] - 0s 477us/step\n",
      "Epoch 1/50\n",
      "5478/5478 - 4s - loss: 0.1794 - val_loss: 0.1856 - 4s/epoch - 674us/step\n",
      "Epoch 2/50\n",
      "5478/5478 - 3s - loss: 0.1721 - val_loss: 0.1839 - 3s/epoch - 588us/step\n",
      "Epoch 3/50\n",
      "5478/5478 - 3s - loss: 0.1704 - val_loss: 0.1813 - 3s/epoch - 590us/step\n",
      "Epoch 4/50\n",
      "5478/5478 - 3s - loss: 0.1696 - val_loss: 0.1834 - 3s/epoch - 590us/step\n",
      "Epoch 5/50\n",
      "5478/5478 - 3s - loss: 0.1689 - val_loss: 0.1852 - 3s/epoch - 583us/step\n",
      "Epoch 6/50\n",
      "5478/5478 - 3s - loss: 0.1685 - val_loss: 0.1839 - 3s/epoch - 589us/step\n",
      "Epoch 7/50\n",
      "5478/5478 - 3s - loss: 0.1681 - val_loss: 0.1815 - 3s/epoch - 587us/step\n",
      "Epoch 8/50\n",
      "5478/5478 - 3s - loss: 0.1678 - val_loss: 0.1847 - 3s/epoch - 592us/step\n",
      "Epoch 9/50\n",
      "5478/5478 - 3s - loss: 0.1675 - val_loss: 0.1814 - 3s/epoch - 593us/step\n",
      "Epoch 10/50\n",
      "5478/5478 - 3s - loss: 0.1673 - val_loss: 0.1910 - 3s/epoch - 591us/step\n",
      "Epoch 11/50\n",
      "5478/5478 - 3s - loss: 0.1670 - val_loss: 0.1850 - 3s/epoch - 597us/step\n",
      "Epoch 12/50\n",
      "5478/5478 - 3s - loss: 0.1670 - val_loss: 0.1874 - 3s/epoch - 597us/step\n",
      "Epoch 13/50\n",
      "5478/5478 - 3s - loss: 0.1667 - val_loss: 0.1895 - 3s/epoch - 586us/step\n",
      "72/72 [==============================] - 0s 491us/step\n",
      "Epoch 1/50\n",
      "5478/5478 - 4s - loss: 0.1811 - val_loss: 0.1848 - 4s/epoch - 660us/step\n",
      "Epoch 2/50\n",
      "5478/5478 - 3s - loss: 0.1722 - val_loss: 0.1804 - 3s/epoch - 596us/step\n",
      "Epoch 3/50\n",
      "5478/5478 - 3s - loss: 0.1704 - val_loss: 0.1797 - 3s/epoch - 594us/step\n",
      "Epoch 4/50\n",
      "5478/5478 - 3s - loss: 0.1694 - val_loss: 0.1872 - 3s/epoch - 594us/step\n",
      "Epoch 5/50\n",
      "5478/5478 - 3s - loss: 0.1688 - val_loss: 0.1842 - 3s/epoch - 598us/step\n",
      "Epoch 6/50\n",
      "5478/5478 - 3s - loss: 0.1683 - val_loss: 0.1862 - 3s/epoch - 592us/step\n",
      "Epoch 7/50\n",
      "5478/5478 - 3s - loss: 0.1679 - val_loss: 0.1828 - 3s/epoch - 604us/step\n",
      "Epoch 8/50\n",
      "5478/5478 - 3s - loss: 0.1676 - val_loss: 0.1916 - 3s/epoch - 595us/step\n",
      "Epoch 9/50\n",
      "5478/5478 - 3s - loss: 0.1673 - val_loss: 0.1917 - 3s/epoch - 594us/step\n",
      "Epoch 10/50\n",
      "5478/5478 - 3s - loss: 0.1671 - val_loss: 0.1891 - 3s/epoch - 590us/step\n",
      "Epoch 11/50\n",
      "5478/5478 - 3s - loss: 0.1669 - val_loss: 0.1964 - 3s/epoch - 590us/step\n",
      "Epoch 12/50\n",
      "5478/5478 - 3s - loss: 0.1667 - val_loss: 0.1902 - 3s/epoch - 593us/step\n",
      "Epoch 13/50\n",
      "5478/5478 - 3s - loss: 0.1666 - val_loss: 0.1888 - 3s/epoch - 597us/step\n",
      "72/72 [==============================] - 0s 479us/step\n",
      "Epoch 1/50\n",
      "5478/5478 - 4s - loss: 0.1796 - val_loss: 0.1834 - 4s/epoch - 665us/step\n",
      "Epoch 2/50\n",
      "5478/5478 - 3s - loss: 0.1724 - val_loss: 0.1878 - 3s/epoch - 581us/step\n",
      "Epoch 3/50\n",
      "5478/5478 - 3s - loss: 0.1706 - val_loss: 0.1866 - 3s/epoch - 583us/step\n",
      "Epoch 4/50\n",
      "5478/5478 - 3s - loss: 0.1694 - val_loss: 0.1834 - 3s/epoch - 595us/step\n",
      "Epoch 5/50\n",
      "5478/5478 - 3s - loss: 0.1686 - val_loss: 0.1896 - 3s/epoch - 584us/step\n",
      "Epoch 6/50\n",
      "5478/5478 - 3s - loss: 0.1681 - val_loss: 0.1853 - 3s/epoch - 580us/step\n",
      "Epoch 7/50\n",
      "5478/5478 - 3s - loss: 0.1678 - val_loss: 0.1789 - 3s/epoch - 591us/step\n",
      "Epoch 8/50\n",
      "5478/5478 - 3s - loss: 0.1674 - val_loss: 0.1838 - 3s/epoch - 588us/step\n",
      "Epoch 9/50\n",
      "5478/5478 - 3s - loss: 0.1672 - val_loss: 0.1899 - 3s/epoch - 588us/step\n",
      "Epoch 10/50\n",
      "5478/5478 - 3s - loss: 0.1670 - val_loss: 0.1914 - 3s/epoch - 589us/step\n",
      "Epoch 11/50\n",
      "5478/5478 - 3s - loss: 0.1667 - val_loss: 0.1847 - 3s/epoch - 591us/step\n",
      "Epoch 12/50\n",
      "5478/5478 - 3s - loss: 0.1666 - val_loss: 0.1853 - 3s/epoch - 586us/step\n",
      "Epoch 13/50\n",
      "5478/5478 - 3s - loss: 0.1665 - val_loss: 0.1902 - 3s/epoch - 592us/step\n",
      "Epoch 14/50\n",
      "5478/5478 - 3s - loss: 0.1664 - val_loss: 0.1828 - 3s/epoch - 586us/step\n",
      "Epoch 15/50\n",
      "5478/5478 - 3s - loss: 0.1662 - val_loss: 0.1849 - 3s/epoch - 579us/step\n",
      "Epoch 16/50\n",
      "5478/5478 - 3s - loss: 0.1661 - val_loss: 0.1834 - 3s/epoch - 583us/step\n",
      "Epoch 17/50\n",
      "5478/5478 - 3s - loss: 0.1660 - val_loss: 0.1914 - 3s/epoch - 583us/step\n",
      "72/72 [==============================] - 0s 514us/step\n",
      "Epoch 1/50\n",
      "5478/5478 - 4s - loss: 0.1806 - val_loss: 0.1881 - 4s/epoch - 657us/step\n",
      "Epoch 2/50\n",
      "5478/5478 - 3s - loss: 0.1722 - val_loss: 0.1856 - 3s/epoch - 598us/step\n",
      "Epoch 3/50\n",
      "5478/5478 - 3s - loss: 0.1704 - val_loss: 0.1825 - 3s/epoch - 591us/step\n",
      "Epoch 4/50\n",
      "5478/5478 - 3s - loss: 0.1695 - val_loss: 0.1832 - 3s/epoch - 595us/step\n",
      "Epoch 5/50\n",
      "5478/5478 - 3s - loss: 0.1688 - val_loss: 0.1849 - 3s/epoch - 592us/step\n",
      "Epoch 6/50\n",
      "5478/5478 - 3s - loss: 0.1684 - val_loss: 0.1863 - 3s/epoch - 592us/step\n",
      "Epoch 7/50\n",
      "5478/5478 - 3s - loss: 0.1680 - val_loss: 0.1843 - 3s/epoch - 592us/step\n",
      "Epoch 8/50\n",
      "5478/5478 - 3s - loss: 0.1676 - val_loss: 0.1867 - 3s/epoch - 588us/step\n",
      "Epoch 9/50\n",
      "5478/5478 - 3s - loss: 0.1674 - val_loss: 0.1850 - 3s/epoch - 598us/step\n",
      "Epoch 10/50\n",
      "5478/5478 - 3s - loss: 0.1672 - val_loss: 0.1876 - 3s/epoch - 595us/step\n",
      "Epoch 11/50\n",
      "5478/5478 - 3s - loss: 0.1669 - val_loss: 0.1880 - 3s/epoch - 601us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50\n",
      "5478/5478 - 3s - loss: 0.1668 - val_loss: 0.1864 - 3s/epoch - 589us/step\n",
      "Epoch 13/50\n",
      "5478/5478 - 3s - loss: 0.1666 - val_loss: 0.1841 - 3s/epoch - 587us/step\n",
      "72/72 [==============================] - 0s 503us/step\n",
      "Epoch 1/50\n",
      "5478/5478 - 4s - loss: 0.1791 - val_loss: 0.1820 - 4s/epoch - 667us/step\n",
      "Epoch 2/50\n",
      "5478/5478 - 3s - loss: 0.1720 - val_loss: 0.1853 - 3s/epoch - 590us/step\n",
      "Epoch 3/50\n",
      "5478/5478 - 3s - loss: 0.1704 - val_loss: 0.1863 - 3s/epoch - 596us/step\n",
      "Epoch 4/50\n",
      "5478/5478 - 3s - loss: 0.1694 - val_loss: 0.1846 - 3s/epoch - 594us/step\n",
      "Epoch 5/50\n",
      "5478/5478 - 3s - loss: 0.1689 - val_loss: 0.1819 - 3s/epoch - 596us/step\n",
      "Epoch 6/50\n",
      "5478/5478 - 3s - loss: 0.1684 - val_loss: 0.1859 - 3s/epoch - 594us/step\n",
      "Epoch 7/50\n",
      "5478/5478 - 3s - loss: 0.1679 - val_loss: 0.1819 - 3s/epoch - 592us/step\n",
      "Epoch 8/50\n",
      "5478/5478 - 3s - loss: 0.1676 - val_loss: 0.1837 - 3s/epoch - 592us/step\n",
      "Epoch 9/50\n",
      "5478/5478 - 3s - loss: 0.1673 - val_loss: 0.1855 - 3s/epoch - 591us/step\n",
      "Epoch 10/50\n",
      "5478/5478 - 3s - loss: 0.1671 - val_loss: 0.1895 - 3s/epoch - 596us/step\n",
      "Epoch 11/50\n",
      "5478/5478 - 3s - loss: 0.1668 - val_loss: 0.1846 - 3s/epoch - 594us/step\n",
      "Epoch 12/50\n",
      "5478/5478 - 3s - loss: 0.1667 - val_loss: 0.1832 - 3s/epoch - 595us/step\n",
      "Epoch 13/50\n",
      "5478/5478 - 3s - loss: 0.1664 - val_loss: 0.1870 - 3s/epoch - 590us/step\n",
      "Epoch 14/50\n",
      "5478/5478 - 3s - loss: 0.1662 - val_loss: 0.1853 - 3s/epoch - 598us/step\n",
      "Epoch 15/50\n",
      "5478/5478 - 3s - loss: 0.1660 - val_loss: 0.1922 - 3s/epoch - 603us/step\n",
      "Epoch 16/50\n",
      "5478/5478 - 3s - loss: 0.1659 - val_loss: 0.1862 - 3s/epoch - 596us/step\n",
      "Epoch 17/50\n",
      "5478/5478 - 3s - loss: 0.1658 - val_loss: 0.1850 - 3s/epoch - 594us/step\n",
      "72/72 [==============================] - 0s 579us/step\n",
      "Epoch 1/50\n",
      "5478/5478 - 4s - loss: 0.1796 - val_loss: 0.1787 - 4s/epoch - 715us/step\n",
      "Epoch 2/50\n",
      "5478/5478 - 3s - loss: 0.1726 - val_loss: 0.1805 - 3s/epoch - 600us/step\n",
      "Epoch 3/50\n",
      "5478/5478 - 3s - loss: 0.1707 - val_loss: 0.1843 - 3s/epoch - 610us/step\n",
      "Epoch 4/50\n",
      "5478/5478 - 3s - loss: 0.1697 - val_loss: 0.1812 - 3s/epoch - 600us/step\n",
      "Epoch 5/50\n",
      "5478/5478 - 3s - loss: 0.1691 - val_loss: 0.1863 - 3s/epoch - 614us/step\n",
      "Epoch 6/50\n",
      "5478/5478 - 3s - loss: 0.1686 - val_loss: 0.1822 - 3s/epoch - 600us/step\n",
      "Epoch 7/50\n",
      "5478/5478 - 3s - loss: 0.1682 - val_loss: 0.1824 - 3s/epoch - 605us/step\n",
      "Epoch 8/50\n",
      "5478/5478 - 3s - loss: 0.1677 - val_loss: 0.1882 - 3s/epoch - 599us/step\n",
      "Epoch 9/50\n",
      "5478/5478 - 3s - loss: 0.1674 - val_loss: 0.1862 - 3s/epoch - 602us/step\n",
      "Epoch 10/50\n",
      "5478/5478 - 3s - loss: 0.1672 - val_loss: 0.1806 - 3s/epoch - 604us/step\n",
      "Epoch 11/50\n",
      "5478/5478 - 3s - loss: 0.1670 - val_loss: 0.1817 - 3s/epoch - 603us/step\n",
      "72/72 [==============================] - 0s 494us/step\n",
      "Epoch 1/50\n",
      "5478/5478 - 4s - loss: 0.1799 - val_loss: 0.1846 - 4s/epoch - 675us/step\n",
      "Epoch 2/50\n",
      "5478/5478 - 3s - loss: 0.1725 - val_loss: 0.1811 - 3s/epoch - 599us/step\n",
      "Epoch 3/50\n",
      "5478/5478 - 3s - loss: 0.1708 - val_loss: 0.1836 - 3s/epoch - 605us/step\n",
      "Epoch 4/50\n",
      "5478/5478 - 3s - loss: 0.1698 - val_loss: 0.1857 - 3s/epoch - 613us/step\n",
      "Epoch 5/50\n",
      "5478/5478 - 3s - loss: 0.1692 - val_loss: 0.1835 - 3s/epoch - 613us/step\n",
      "Epoch 6/50\n",
      "5478/5478 - 3s - loss: 0.1685 - val_loss: 0.1845 - 3s/epoch - 611us/step\n",
      "Epoch 7/50\n",
      "5478/5478 - 3s - loss: 0.1682 - val_loss: 0.1846 - 3s/epoch - 606us/step\n",
      "Epoch 8/50\n",
      "5478/5478 - 3s - loss: 0.1678 - val_loss: 0.1873 - 3s/epoch - 603us/step\n",
      "Epoch 9/50\n",
      "5478/5478 - 3s - loss: 0.1676 - val_loss: 0.1915 - 3s/epoch - 600us/step\n",
      "Epoch 10/50\n",
      "5478/5478 - 3s - loss: 0.1673 - val_loss: 0.1819 - 3s/epoch - 600us/step\n",
      "Epoch 11/50\n",
      "5478/5478 - 3s - loss: 0.1671 - val_loss: 0.1871 - 3s/epoch - 602us/step\n",
      "Epoch 12/50\n",
      "5478/5478 - 4s - loss: 0.1669 - val_loss: 0.1884 - 4s/epoch - 661us/step\n",
      "72/72 [==============================] - 0s 543us/step\n",
      "Epoch 1/50\n",
      "5478/5478 - 5s - loss: 0.1790 - val_loss: 0.1885 - 5s/epoch - 930us/step\n",
      "Epoch 2/50\n",
      "5478/5478 - 4s - loss: 0.1727 - val_loss: 0.1815 - 4s/epoch - 645us/step\n",
      "Epoch 3/50\n",
      "5478/5478 - 3s - loss: 0.1709 - val_loss: 0.1795 - 3s/epoch - 613us/step\n",
      "Epoch 4/50\n",
      "5478/5478 - 3s - loss: 0.1699 - val_loss: 0.1792 - 3s/epoch - 616us/step\n",
      "Epoch 5/50\n",
      "5478/5478 - 3s - loss: 0.1693 - val_loss: 0.1842 - 3s/epoch - 604us/step\n",
      "Epoch 6/50\n",
      "5478/5478 - 3s - loss: 0.1686 - val_loss: 0.1820 - 3s/epoch - 617us/step\n",
      "Epoch 7/50\n",
      "5478/5478 - 3s - loss: 0.1681 - val_loss: 0.1826 - 3s/epoch - 618us/step\n",
      "Epoch 8/50\n",
      "5478/5478 - 3s - loss: 0.1678 - val_loss: 0.1803 - 3s/epoch - 590us/step\n",
      "Epoch 9/50\n",
      "5478/5478 - 3s - loss: 0.1675 - val_loss: 0.1839 - 3s/epoch - 587us/step\n",
      "Epoch 10/50\n",
      "5478/5478 - 3s - loss: 0.1672 - val_loss: 0.1856 - 3s/epoch - 591us/step\n",
      "Epoch 11/50\n",
      "5478/5478 - 3s - loss: 0.1669 - val_loss: 0.1819 - 3s/epoch - 605us/step\n",
      "Epoch 12/50\n",
      "5478/5478 - 3s - loss: 0.1666 - val_loss: 0.1826 - 3s/epoch - 594us/step\n",
      "Epoch 13/50\n",
      "5478/5478 - 3s - loss: 0.1665 - val_loss: 0.1897 - 3s/epoch - 592us/step\n",
      "Epoch 14/50\n",
      "5478/5478 - 3s - loss: 0.1664 - val_loss: 0.1839 - 3s/epoch - 586us/step\n",
      "72/72 [==============================] - 0s 493us/step\n",
      "Epoch 1/50\n",
      "5478/5478 - 4s - loss: 0.1801 - val_loss: 0.1838 - 4s/epoch - 665us/step\n",
      "Epoch 2/50\n",
      "5478/5478 - 3s - loss: 0.1727 - val_loss: 0.1835 - 3s/epoch - 589us/step\n",
      "Epoch 3/50\n",
      "5478/5478 - 3s - loss: 0.1709 - val_loss: 0.1800 - 3s/epoch - 583us/step\n",
      "Epoch 4/50\n",
      "5478/5478 - 3s - loss: 0.1699 - val_loss: 0.1848 - 3s/epoch - 585us/step\n",
      "Epoch 5/50\n",
      "5478/5478 - 3s - loss: 0.1692 - val_loss: 0.1858 - 3s/epoch - 594us/step\n",
      "Epoch 6/50\n",
      "5478/5478 - 3s - loss: 0.1685 - val_loss: 0.1848 - 3s/epoch - 586us/step\n",
      "Epoch 7/50\n",
      "5478/5478 - 3s - loss: 0.1680 - val_loss: 0.1829 - 3s/epoch - 583us/step\n",
      "Epoch 8/50\n",
      "5478/5478 - 3s - loss: 0.1677 - val_loss: 0.1857 - 3s/epoch - 594us/step\n",
      "Epoch 9/50\n",
      "5478/5478 - 3s - loss: 0.1675 - val_loss: 0.1910 - 3s/epoch - 609us/step\n",
      "Epoch 10/50\n",
      "5478/5478 - 3s - loss: 0.1672 - val_loss: 0.1801 - 3s/epoch - 608us/step\n",
      "Epoch 11/50\n",
      "5478/5478 - 3s - loss: 0.1670 - val_loss: 0.1787 - 3s/epoch - 625us/step\n",
      "Epoch 12/50\n",
      "5478/5478 - 3s - loss: 0.1668 - val_loss: 0.1807 - 3s/epoch - 618us/step\n",
      "Epoch 13/50\n",
      "5478/5478 - 3s - loss: 0.1667 - val_loss: 0.1857 - 3s/epoch - 604us/step\n",
      "Epoch 14/50\n",
      "5478/5478 - 3s - loss: 0.1664 - val_loss: 0.1887 - 3s/epoch - 605us/step\n",
      "Epoch 15/50\n",
      "5478/5478 - 3s - loss: 0.1663 - val_loss: 0.1820 - 3s/epoch - 626us/step\n",
      "Epoch 16/50\n",
      "5478/5478 - 3s - loss: 0.1662 - val_loss: 0.1849 - 3s/epoch - 618us/step\n",
      "Epoch 17/50\n",
      "5478/5478 - 3s - loss: 0.1660 - val_loss: 0.1879 - 3s/epoch - 613us/step\n",
      "Epoch 18/50\n",
      "5478/5478 - 3s - loss: 0.1659 - val_loss: 0.1851 - 3s/epoch - 596us/step\n",
      "Epoch 19/50\n",
      "5478/5478 - 3s - loss: 0.1657 - val_loss: 0.1844 - 3s/epoch - 587us/step\n",
      "Epoch 20/50\n",
      "5478/5478 - 3s - loss: 0.1656 - val_loss: 0.1837 - 3s/epoch - 586us/step\n",
      "Epoch 21/50\n",
      "5478/5478 - 3s - loss: 0.1657 - val_loss: 0.1866 - 3s/epoch - 607us/step\n",
      "72/72 [==============================] - 0s 451us/step\n"
     ]
    }
   ],
   "source": [
    "MLP_spring_mae, MLP_spring_TC_pred = MLP_model('spring')\n",
    "MLP_summer_mae, MLP_summer_TC_pred = MLP_model('summer')\n",
    "MLP_autumn_mae, MLP_autumn_TC_pred = MLP_model('autumn')\n",
    "MLP_winter_mae, MLP_winter_TC_pred = MLP_model('winter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd7b74bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert each dictionary to a DataFrame\n",
    "MLP_spring_df = pd.DataFrame.from_dict(MLP_spring_mae, orient='index', columns=['MAE'])\n",
    "MLP_summer_df = pd.DataFrame.from_dict(MLP_summer_mae, orient='index', columns=['MAE'])\n",
    "MLP_autumn_df = pd.DataFrame.from_dict(MLP_autumn_mae, orient='index', columns=['MAE'])\n",
    "MLP_winter_df = pd.DataFrame.from_dict(MLP_winter_mae, orient='index', columns=['MAE'])\n",
    "\n",
    "# Concatenate all the DataFrames along columns\n",
    "MLP_mae_df = pd.concat([MLP_spring_df, MLP_summer_df, MLP_autumn_df, MLP_winter_df], axis=0)\n",
    "MLP_mae_df.columns = ['MLP_MAE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "521b822b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MLP_MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>146_spring</th>\n",
       "      <td>3.128461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212_spring</th>\n",
       "      <td>3.382251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245_spring</th>\n",
       "      <td>2.819685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146_summer</th>\n",
       "      <td>2.217413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212_summer</th>\n",
       "      <td>2.720822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245_summer</th>\n",
       "      <td>2.956115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146_autumn</th>\n",
       "      <td>1.872520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212_autumn</th>\n",
       "      <td>2.053449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245_autumn</th>\n",
       "      <td>2.029369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146_winter</th>\n",
       "      <td>1.855936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212_winter</th>\n",
       "      <td>1.798033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245_winter</th>\n",
       "      <td>2.262796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             MLP_MAE\n",
       "146_spring  3.128461\n",
       "212_spring  3.382251\n",
       "245_spring  2.819685\n",
       "146_summer  2.217413\n",
       "212_summer  2.720822\n",
       "245_summer  2.956115\n",
       "146_autumn  1.872520\n",
       "212_autumn  2.053449\n",
       "245_autumn  2.029369\n",
       "146_winter  1.855936\n",
       "212_winter  1.798033\n",
       "245_winter  2.262796"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLP_mae_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3df18c",
   "metadata": {},
   "source": [
    "# Rocket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e74c690",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Rocket_model(weather):\n",
    "    # initialize result dictionaries\n",
    "    mae_results = {}\n",
    "    TC_pred_results = {}\n",
    "\n",
    "    train = pd.read_csv(\"Train_data.csv\")\n",
    "    train['Date'] = pd.to_datetime(train['Date'])\n",
    "\n",
    "    # Add filter for months based on weather\n",
    "    if weather == 'spring':\n",
    "        train = train[train['Date'].dt.month.isin([2, 3, 4])]\n",
    "    elif weather == 'summer':\n",
    "        train = train[train['Date'].dt.month.isin([5, 6, 7])]\n",
    "    elif weather == 'autumn':\n",
    "        train = train[train['Date'].dt.month.isin([8, 9, 10])]\n",
    "    elif weather == 'winter':\n",
    "        train = train[train['Date'].dt.month.isin([11, 12, 1])]\n",
    "\n",
    "    # 스케일러 생성\n",
    "    # 평균 0, 표준편차 1로 스케일링\n",
    "    scaler = StandardScaler()\n",
    "    y_scaler = StandardScaler()\n",
    "\n",
    "    # train 데이터로 스케일러 학습\n",
    "    x_train = scaler.fit_transform(train.iloc[:,2:12])\n",
    "    y_train = y_scaler.fit_transform(train.iloc[:,-1].values.reshape(-1, 1))\n",
    "\n",
    "    x_train = from_2d_array_to_nested(pd.DataFrame(x_train))\n",
    "    y_train = y_train.ravel()\n",
    "\n",
    "    for file in test_col:\n",
    "        if weather in file:\n",
    "            test = pd.read_csv(file)\n",
    "            test['Date'] = pd.to_datetime(test['Date'])\n",
    "            \n",
    "            x_test = scaler.transform(test.iloc[:,2:12])\n",
    "            \n",
    "            x_test = from_2d_array_to_nested(pd.DataFrame(x_test))\n",
    "            y_test = test.iloc[:,-1].values.ravel()\n",
    "\n",
    "            # Create a model\n",
    "            reg = RocketRegressor(num_kernels=500)\n",
    "\n",
    "            # Fit the model\n",
    "            reg.fit(x_train, y_train)\n",
    "\n",
    "            # Make predictions\n",
    "            y_pred = reg.predict(x_test)\n",
    "    \n",
    "            TC_pred = y_scaler.inverse_transform(y_pred.reshape(-1, 1))\n",
    "\n",
    "            # Evaluate the model\n",
    "            mae = mean_absolute_error(y_test, TC_pred)\n",
    "\n",
    "            # save the results with the filename as the key\n",
    "            filename = os.path.splitext(os.path.basename(file))[0]  # extract filename without extension\n",
    "            mae_results[filename] = mae\n",
    "            TC_pred_results[filename] = TC_pred\n",
    "\n",
    "    return mae_results, TC_pred_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "efe528e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROCKET_spring_mae, ROCKET_spring_TC_pred = Rocket_model('spring')\n",
    "ROCKET_summer_mae, ROCKET_summer_TC_pred = Rocket_model('summer')\n",
    "ROCKET_autumn_mae, ROCKET_autumn_TC_pred = Rocket_model('autumn')\n",
    "ROCKET_winter_mae, ROCKET_winter_TC_pred = Rocket_model('winter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4d7715b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert each dictionary to a DataFrame\n",
    "ROCKET_spring_df = pd.DataFrame.from_dict(ROCKET_spring_mae, orient='index', columns=['MAE'])\n",
    "ROCKET_summer_df = pd.DataFrame.from_dict(ROCKET_summer_mae, orient='index', columns=['MAE'])\n",
    "ROCKET_autumn_df = pd.DataFrame.from_dict(ROCKET_autumn_mae, orient='index', columns=['MAE'])\n",
    "ROCKET_winter_df = pd.DataFrame.from_dict(ROCKET_winter_mae, orient='index', columns=['MAE'])\n",
    "\n",
    "# Concatenate all the DataFrames along columns\n",
    "ROCKET_mae_df = pd.concat([ROCKET_spring_df, ROCKET_summer_df, ROCKET_autumn_df, ROCKET_winter_df], axis=0)\n",
    "ROCKET_mae_df.columns = ['ROCKET_MAE']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d80b34ba",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROCKET_MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>146_spring</th>\n",
       "      <td>3.424482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212_spring</th>\n",
       "      <td>3.710736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245_spring</th>\n",
       "      <td>3.046481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146_summer</th>\n",
       "      <td>2.511090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212_summer</th>\n",
       "      <td>2.788610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245_summer</th>\n",
       "      <td>3.091276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146_autumn</th>\n",
       "      <td>1.945156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212_autumn</th>\n",
       "      <td>2.218871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245_autumn</th>\n",
       "      <td>2.597645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146_winter</th>\n",
       "      <td>2.104441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212_winter</th>\n",
       "      <td>2.114252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245_winter</th>\n",
       "      <td>2.724552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ROCKET_MAE\n",
       "146_spring    3.424482\n",
       "212_spring    3.710736\n",
       "245_spring    3.046481\n",
       "146_summer    2.511090\n",
       "212_summer    2.788610\n",
       "245_summer    3.091276\n",
       "146_autumn    1.945156\n",
       "212_autumn    2.218871\n",
       "245_autumn    2.597645\n",
       "146_winter    2.104441\n",
       "212_winter    2.114252\n",
       "245_winter    2.724552"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ROCKET_mae_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d7afc0",
   "metadata": {},
   "source": [
    "# Lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e269970c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Lightgbm_model(weather):\n",
    "    # initialize result dictionaries\n",
    "    mae_results = {}\n",
    "    TC_pred_results = {}\n",
    "\n",
    "    train = pd.read_csv(\"Train_data.csv\")\n",
    "    train['Date'] = pd.to_datetime(train['Date'])\n",
    "\n",
    "    # Add filter for months based on weather\n",
    "    if weather == 'spring':\n",
    "        train = train[train['Date'].dt.month.isin([2, 3, 4])]\n",
    "    elif weather == 'summer':\n",
    "        train = train[train['Date'].dt.month.isin([5, 6, 7])]\n",
    "    elif weather == 'autumn':\n",
    "        train = train[train['Date'].dt.month.isin([8, 9, 10])]\n",
    "    elif weather == 'winter':\n",
    "        train = train[train['Date'].dt.month.isin([11, 12, 1])]\n",
    "\n",
    "    # 스케일러 생성\n",
    "    # 평균 0, 표준편차 1로 스케일링\n",
    "    scaler = StandardScaler()\n",
    "    y_scaler = StandardScaler()\n",
    "\n",
    "    # train 데이터로 스케일러 학습\n",
    "    x_train = scaler.fit_transform(train.iloc[:,2:12])\n",
    "    y_train = y_scaler.fit_transform(train.iloc[:,-1].values.reshape(-1, 1))\n",
    "    \n",
    "    for file in test_col:\n",
    "        if weather in file:\n",
    "            test = pd.read_csv(file)\n",
    "            test['Date'] = pd.to_datetime(test['Date'])\n",
    "            \n",
    "            x_test = scaler.transform(test.iloc[:,2:12])\n",
    "            y_test = y_scaler.transform(test.iloc[:,-1].values.reshape(-1, 1))\n",
    "\n",
    "            x_train_df = pd.DataFrame(x_train)\n",
    "            x_test_df = pd.DataFrame(x_test)\n",
    "\n",
    "            # laoding data\n",
    "            lgb_train = lgb.Dataset(x_train_df, y_train)\n",
    "            lgb_eval = lgb.Dataset(x_test_df, y_test, reference=lgb_train)\n",
    "\n",
    "            # fitting the model\n",
    "            model = lgb.train(params,\n",
    "                 train_set=lgb_train,\n",
    "                 valid_sets=lgb_eval)\n",
    "\n",
    "            # Make predictions\n",
    "            y_pred = model.predict(x_test_df)\n",
    "    \n",
    "            TC_pred = y_scaler.inverse_transform(y_pred.reshape(-1, 1))\n",
    "            y_test = y_scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "        \n",
    "\n",
    "            # Evaluate the model\n",
    "            mae = mean_absolute_error(y_test, TC_pred)\n",
    "\n",
    "            # save the results with the filename as the key\n",
    "            filename = os.path.splitext(os.path.basename(file))[0]  # extract filename without extension\n",
    "            mae_results[filename] = mae\n",
    "            TC_pred_results[filename] = TC_pred\n",
    "\n",
    "    return mae_results, TC_pred_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff52ff8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: learnnig_rage\n",
      "[1]\tvalid_0's l1: 0.871479\tvalid_0's l2: 1.102\n",
      "[2]\tvalid_0's l1: 0.811272\tvalid_0's l2: 0.956019\n",
      "[3]\tvalid_0's l1: 0.757543\tvalid_0's l2: 0.836386\n",
      "[4]\tvalid_0's l1: 0.710156\tvalid_0's l2: 0.737363\n",
      "[5]\tvalid_0's l1: 0.667086\tvalid_0's l2: 0.653411\n",
      "[6]\tvalid_0's l1: 0.630478\tvalid_0's l2: 0.586555\n",
      "[7]\tvalid_0's l1: 0.596697\tvalid_0's l2: 0.527186\n",
      "[8]\tvalid_0's l1: 0.56638\tvalid_0's l2: 0.478234\n",
      "[9]\tvalid_0's l1: 0.540347\tvalid_0's l2: 0.438186\n",
      "[10]\tvalid_0's l1: 0.518433\tvalid_0's l2: 0.405057\n",
      "[11]\tvalid_0's l1: 0.497399\tvalid_0's l2: 0.375822\n",
      "[12]\tvalid_0's l1: 0.478472\tvalid_0's l2: 0.351173\n",
      "[13]\tvalid_0's l1: 0.46312\tvalid_0's l2: 0.331539\n",
      "[14]\tvalid_0's l1: 0.449602\tvalid_0's l2: 0.315005\n",
      "[15]\tvalid_0's l1: 0.437275\tvalid_0's l2: 0.300528\n",
      "[16]\tvalid_0's l1: 0.425158\tvalid_0's l2: 0.287201\n",
      "[17]\tvalid_0's l1: 0.415916\tvalid_0's l2: 0.277221\n",
      "[18]\tvalid_0's l1: 0.406511\tvalid_0's l2: 0.267473\n",
      "[19]\tvalid_0's l1: 0.398659\tvalid_0's l2: 0.259569\n",
      "[20]\tvalid_0's l1: 0.391984\tvalid_0's l2: 0.2535\n",
      "[21]\tvalid_0's l1: 0.386552\tvalid_0's l2: 0.248793\n",
      "[22]\tvalid_0's l1: 0.380316\tvalid_0's l2: 0.242922\n",
      "[23]\tvalid_0's l1: 0.375078\tvalid_0's l2: 0.237774\n",
      "[24]\tvalid_0's l1: 0.370252\tvalid_0's l2: 0.233156\n",
      "[25]\tvalid_0's l1: 0.365194\tvalid_0's l2: 0.22833\n",
      "[26]\tvalid_0's l1: 0.361368\tvalid_0's l2: 0.225602\n",
      "[27]\tvalid_0's l1: 0.357564\tvalid_0's l2: 0.221867\n",
      "[28]\tvalid_0's l1: 0.354975\tvalid_0's l2: 0.219876\n",
      "[29]\tvalid_0's l1: 0.352136\tvalid_0's l2: 0.217302\n",
      "[30]\tvalid_0's l1: 0.349476\tvalid_0's l2: 0.214622\n",
      "[31]\tvalid_0's l1: 0.34673\tvalid_0's l2: 0.212193\n",
      "[32]\tvalid_0's l1: 0.344567\tvalid_0's l2: 0.21016\n",
      "[33]\tvalid_0's l1: 0.342766\tvalid_0's l2: 0.208424\n",
      "[34]\tvalid_0's l1: 0.340695\tvalid_0's l2: 0.206541\n",
      "[35]\tvalid_0's l1: 0.339827\tvalid_0's l2: 0.205953\n",
      "[36]\tvalid_0's l1: 0.338209\tvalid_0's l2: 0.20453\n",
      "[37]\tvalid_0's l1: 0.336655\tvalid_0's l2: 0.203054\n",
      "[38]\tvalid_0's l1: 0.335719\tvalid_0's l2: 0.202279\n",
      "[39]\tvalid_0's l1: 0.334211\tvalid_0's l2: 0.200769\n",
      "[40]\tvalid_0's l1: 0.332805\tvalid_0's l2: 0.199473\n",
      "[41]\tvalid_0's l1: 0.332078\tvalid_0's l2: 0.199027\n",
      "[42]\tvalid_0's l1: 0.331437\tvalid_0's l2: 0.198755\n",
      "[43]\tvalid_0's l1: 0.330002\tvalid_0's l2: 0.197183\n",
      "[44]\tvalid_0's l1: 0.329211\tvalid_0's l2: 0.196986\n",
      "[45]\tvalid_0's l1: 0.328258\tvalid_0's l2: 0.196122\n",
      "[46]\tvalid_0's l1: 0.327196\tvalid_0's l2: 0.195427\n",
      "[47]\tvalid_0's l1: 0.326641\tvalid_0's l2: 0.195026\n",
      "[48]\tvalid_0's l1: 0.326004\tvalid_0's l2: 0.194506\n",
      "[49]\tvalid_0's l1: 0.324939\tvalid_0's l2: 0.193562\n",
      "[50]\tvalid_0's l1: 0.324264\tvalid_0's l2: 0.193192\n",
      "[51]\tvalid_0's l1: 0.324198\tvalid_0's l2: 0.193313\n",
      "[52]\tvalid_0's l1: 0.324049\tvalid_0's l2: 0.193176\n",
      "[53]\tvalid_0's l1: 0.323929\tvalid_0's l2: 0.193103\n",
      "[54]\tvalid_0's l1: 0.323361\tvalid_0's l2: 0.192772\n",
      "[55]\tvalid_0's l1: 0.323166\tvalid_0's l2: 0.192719\n",
      "[56]\tvalid_0's l1: 0.322758\tvalid_0's l2: 0.192285\n",
      "[57]\tvalid_0's l1: 0.322443\tvalid_0's l2: 0.19203\n",
      "[58]\tvalid_0's l1: 0.322549\tvalid_0's l2: 0.192346\n",
      "[59]\tvalid_0's l1: 0.322497\tvalid_0's l2: 0.192248\n",
      "[60]\tvalid_0's l1: 0.322098\tvalid_0's l2: 0.191838\n",
      "[61]\tvalid_0's l1: 0.322089\tvalid_0's l2: 0.191789\n",
      "[62]\tvalid_0's l1: 0.322091\tvalid_0's l2: 0.191935\n",
      "[63]\tvalid_0's l1: 0.321726\tvalid_0's l2: 0.191621\n",
      "[64]\tvalid_0's l1: 0.321798\tvalid_0's l2: 0.191792\n",
      "[65]\tvalid_0's l1: 0.321778\tvalid_0's l2: 0.191756\n",
      "[66]\tvalid_0's l1: 0.321459\tvalid_0's l2: 0.191414\n",
      "[67]\tvalid_0's l1: 0.321069\tvalid_0's l2: 0.191059\n",
      "[68]\tvalid_0's l1: 0.321046\tvalid_0's l2: 0.191061\n",
      "[69]\tvalid_0's l1: 0.321108\tvalid_0's l2: 0.191057\n",
      "[70]\tvalid_0's l1: 0.321049\tvalid_0's l2: 0.191086\n",
      "[71]\tvalid_0's l1: 0.320848\tvalid_0's l2: 0.190912\n",
      "[72]\tvalid_0's l1: 0.320758\tvalid_0's l2: 0.19081\n",
      "[73]\tvalid_0's l1: 0.32087\tvalid_0's l2: 0.191046\n",
      "[74]\tvalid_0's l1: 0.320751\tvalid_0's l2: 0.190951\n",
      "[75]\tvalid_0's l1: 0.320551\tvalid_0's l2: 0.190734\n",
      "[76]\tvalid_0's l1: 0.32025\tvalid_0's l2: 0.190518\n",
      "[77]\tvalid_0's l1: 0.320083\tvalid_0's l2: 0.190484\n",
      "[78]\tvalid_0's l1: 0.32014\tvalid_0's l2: 0.19049\n",
      "[79]\tvalid_0's l1: 0.320152\tvalid_0's l2: 0.190477\n",
      "[80]\tvalid_0's l1: 0.319994\tvalid_0's l2: 0.190354\n",
      "[81]\tvalid_0's l1: 0.319985\tvalid_0's l2: 0.190355\n",
      "[82]\tvalid_0's l1: 0.319879\tvalid_0's l2: 0.19023\n",
      "[83]\tvalid_0's l1: 0.319693\tvalid_0's l2: 0.189952\n",
      "[84]\tvalid_0's l1: 0.3196\tvalid_0's l2: 0.189929\n",
      "[85]\tvalid_0's l1: 0.319623\tvalid_0's l2: 0.189898\n",
      "[86]\tvalid_0's l1: 0.319427\tvalid_0's l2: 0.189678\n",
      "[87]\tvalid_0's l1: 0.319378\tvalid_0's l2: 0.189701\n",
      "[88]\tvalid_0's l1: 0.319374\tvalid_0's l2: 0.189687\n",
      "[89]\tvalid_0's l1: 0.319166\tvalid_0's l2: 0.189484\n",
      "[90]\tvalid_0's l1: 0.319007\tvalid_0's l2: 0.189425\n",
      "[91]\tvalid_0's l1: 0.318962\tvalid_0's l2: 0.189317\n",
      "[92]\tvalid_0's l1: 0.318987\tvalid_0's l2: 0.189288\n",
      "[93]\tvalid_0's l1: 0.319036\tvalid_0's l2: 0.189293\n",
      "[94]\tvalid_0's l1: 0.319029\tvalid_0's l2: 0.189293\n",
      "[95]\tvalid_0's l1: 0.318972\tvalid_0's l2: 0.189243\n",
      "[96]\tvalid_0's l1: 0.318833\tvalid_0's l2: 0.189047\n",
      "[97]\tvalid_0's l1: 0.318882\tvalid_0's l2: 0.189126\n",
      "[98]\tvalid_0's l1: 0.318765\tvalid_0's l2: 0.189035\n",
      "[99]\tvalid_0's l1: 0.31869\tvalid_0's l2: 0.188994\n",
      "[100]\tvalid_0's l1: 0.318675\tvalid_0's l2: 0.188989\n",
      "[LightGBM] [Warning] Unknown parameter: learnnig_rage\n",
      "[1]\tvalid_0's l1: 0.965828\tvalid_0's l2: 1.44315\n",
      "[2]\tvalid_0's l1: 0.899493\tvalid_0's l2: 1.25284\n",
      "[3]\tvalid_0's l1: 0.84111\tvalid_0's l2: 1.09883\n",
      "[4]\tvalid_0's l1: 0.786358\tvalid_0's l2: 0.961582\n",
      "[5]\tvalid_0's l1: 0.738876\tvalid_0's l2: 0.852219\n",
      "[6]\tvalid_0's l1: 0.695037\tvalid_0's l2: 0.754467\n",
      "[7]\tvalid_0's l1: 0.657344\tvalid_0's l2: 0.676748\n",
      "[8]\tvalid_0's l1: 0.623598\tvalid_0's l2: 0.61134\n",
      "[9]\tvalid_0's l1: 0.592178\tvalid_0's l2: 0.552154\n",
      "[10]\tvalid_0's l1: 0.564397\tvalid_0's l2: 0.500181\n",
      "[11]\tvalid_0's l1: 0.539941\tvalid_0's l2: 0.458786\n",
      "[12]\tvalid_0's l1: 0.517455\tvalid_0's l2: 0.422694\n",
      "[13]\tvalid_0's l1: 0.497334\tvalid_0's l2: 0.390485\n",
      "[14]\tvalid_0's l1: 0.479053\tvalid_0's l2: 0.362054\n",
      "[15]\tvalid_0's l1: 0.463763\tvalid_0's l2: 0.340702\n",
      "[16]\tvalid_0's l1: 0.44972\tvalid_0's l2: 0.322573\n",
      "[17]\tvalid_0's l1: 0.437213\tvalid_0's l2: 0.306256\n",
      "[18]\tvalid_0's l1: 0.424736\tvalid_0's l2: 0.290203\n",
      "[19]\tvalid_0's l1: 0.414166\tvalid_0's l2: 0.276561\n",
      "[20]\tvalid_0's l1: 0.404123\tvalid_0's l2: 0.265083\n",
      "[21]\tvalid_0's l1: 0.39626\tvalid_0's l2: 0.256531\n",
      "[22]\tvalid_0's l1: 0.387269\tvalid_0's l2: 0.246424\n",
      "[23]\tvalid_0's l1: 0.377954\tvalid_0's l2: 0.236555\n",
      "[24]\tvalid_0's l1: 0.370441\tvalid_0's l2: 0.228281\n",
      "[25]\tvalid_0's l1: 0.364494\tvalid_0's l2: 0.222152\n",
      "[26]\tvalid_0's l1: 0.360173\tvalid_0's l2: 0.218037\n",
      "[27]\tvalid_0's l1: 0.354294\tvalid_0's l2: 0.212621\n",
      "[28]\tvalid_0's l1: 0.349727\tvalid_0's l2: 0.20897\n",
      "[29]\tvalid_0's l1: 0.345259\tvalid_0's l2: 0.204848\n",
      "[30]\tvalid_0's l1: 0.339955\tvalid_0's l2: 0.200587\n",
      "[31]\tvalid_0's l1: 0.335833\tvalid_0's l2: 0.197015\n",
      "[32]\tvalid_0's l1: 0.331799\tvalid_0's l2: 0.193806\n",
      "[33]\tvalid_0's l1: 0.328149\tvalid_0's l2: 0.191409\n",
      "[34]\tvalid_0's l1: 0.324651\tvalid_0's l2: 0.18812\n",
      "[35]\tvalid_0's l1: 0.32176\tvalid_0's l2: 0.186137\n",
      "[36]\tvalid_0's l1: 0.319174\tvalid_0's l2: 0.184495\n",
      "[37]\tvalid_0's l1: 0.315732\tvalid_0's l2: 0.181244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:179: UserWarning: Converting column-vector to 1d array\n",
      "  _log_warning('Converting column-vector to 1d array')\n",
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:179: UserWarning: Converting column-vector to 1d array\n",
      "  _log_warning('Converting column-vector to 1d array')\n",
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:179: UserWarning: Converting column-vector to 1d array\n",
      "  _log_warning('Converting column-vector to 1d array')\n",
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:179: UserWarning: Converting column-vector to 1d array\n",
      "  _log_warning('Converting column-vector to 1d array')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[38]\tvalid_0's l1: 0.313753\tvalid_0's l2: 0.180087\n",
      "[39]\tvalid_0's l1: 0.311644\tvalid_0's l2: 0.178133\n",
      "[40]\tvalid_0's l1: 0.309021\tvalid_0's l2: 0.175517\n",
      "[41]\tvalid_0's l1: 0.306796\tvalid_0's l2: 0.173976\n",
      "[42]\tvalid_0's l1: 0.305281\tvalid_0's l2: 0.173361\n",
      "[43]\tvalid_0's l1: 0.303439\tvalid_0's l2: 0.171344\n",
      "[44]\tvalid_0's l1: 0.30253\tvalid_0's l2: 0.170433\n",
      "[45]\tvalid_0's l1: 0.30119\tvalid_0's l2: 0.169332\n",
      "[46]\tvalid_0's l1: 0.301058\tvalid_0's l2: 0.169264\n",
      "[47]\tvalid_0's l1: 0.299862\tvalid_0's l2: 0.168085\n",
      "[48]\tvalid_0's l1: 0.298438\tvalid_0's l2: 0.167115\n",
      "[49]\tvalid_0's l1: 0.298058\tvalid_0's l2: 0.166718\n",
      "[50]\tvalid_0's l1: 0.296903\tvalid_0's l2: 0.165734\n",
      "[51]\tvalid_0's l1: 0.296296\tvalid_0's l2: 0.165555\n",
      "[52]\tvalid_0's l1: 0.295022\tvalid_0's l2: 0.164759\n",
      "[53]\tvalid_0's l1: 0.293291\tvalid_0's l2: 0.163022\n",
      "[54]\tvalid_0's l1: 0.292907\tvalid_0's l2: 0.162878\n",
      "[55]\tvalid_0's l1: 0.292199\tvalid_0's l2: 0.162613\n",
      "[56]\tvalid_0's l1: 0.291696\tvalid_0's l2: 0.162237\n",
      "[57]\tvalid_0's l1: 0.291369\tvalid_0's l2: 0.162122\n",
      "[58]\tvalid_0's l1: 0.289931\tvalid_0's l2: 0.160841\n",
      "[59]\tvalid_0's l1: 0.289431\tvalid_0's l2: 0.160305\n",
      "[60]\tvalid_0's l1: 0.288536\tvalid_0's l2: 0.159486\n",
      "[61]\tvalid_0's l1: 0.288478\tvalid_0's l2: 0.159551\n",
      "[62]\tvalid_0's l1: 0.287625\tvalid_0's l2: 0.15887\n",
      "[63]\tvalid_0's l1: 0.287262\tvalid_0's l2: 0.158619\n",
      "[64]\tvalid_0's l1: 0.287337\tvalid_0's l2: 0.158788\n",
      "[65]\tvalid_0's l1: 0.286998\tvalid_0's l2: 0.158293\n",
      "[66]\tvalid_0's l1: 0.286467\tvalid_0's l2: 0.157871\n",
      "[67]\tvalid_0's l1: 0.286115\tvalid_0's l2: 0.157806\n",
      "[68]\tvalid_0's l1: 0.285848\tvalid_0's l2: 0.157478\n",
      "[69]\tvalid_0's l1: 0.285506\tvalid_0's l2: 0.157193\n",
      "[70]\tvalid_0's l1: 0.285608\tvalid_0's l2: 0.157378\n",
      "[71]\tvalid_0's l1: 0.28534\tvalid_0's l2: 0.157383\n",
      "[72]\tvalid_0's l1: 0.285246\tvalid_0's l2: 0.157329\n",
      "[73]\tvalid_0's l1: 0.285423\tvalid_0's l2: 0.157631\n",
      "[74]\tvalid_0's l1: 0.285436\tvalid_0's l2: 0.157713\n",
      "[75]\tvalid_0's l1: 0.285119\tvalid_0's l2: 0.157485\n",
      "[76]\tvalid_0's l1: 0.285662\tvalid_0's l2: 0.157894\n",
      "[77]\tvalid_0's l1: 0.285583\tvalid_0's l2: 0.157924\n",
      "[78]\tvalid_0's l1: 0.285276\tvalid_0's l2: 0.157675\n",
      "[79]\tvalid_0's l1: 0.284186\tvalid_0's l2: 0.156784\n",
      "[80]\tvalid_0's l1: 0.283986\tvalid_0's l2: 0.156694\n",
      "[81]\tvalid_0's l1: 0.283839\tvalid_0's l2: 0.156147\n",
      "[82]\tvalid_0's l1: 0.284018\tvalid_0's l2: 0.156463\n",
      "[83]\tvalid_0's l1: 0.284092\tvalid_0's l2: 0.156527\n",
      "[84]\tvalid_0's l1: 0.284066\tvalid_0's l2: 0.156548\n",
      "[85]\tvalid_0's l1: 0.283937\tvalid_0's l2: 0.15649\n",
      "[86]\tvalid_0's l1: 0.283657\tvalid_0's l2: 0.156378\n",
      "[87]\tvalid_0's l1: 0.281966\tvalid_0's l2: 0.155225\n",
      "[88]\tvalid_0's l1: 0.281975\tvalid_0's l2: 0.155284\n",
      "[89]\tvalid_0's l1: 0.281744\tvalid_0's l2: 0.155135\n",
      "[90]\tvalid_0's l1: 0.281564\tvalid_0's l2: 0.155059\n",
      "[91]\tvalid_0's l1: 0.281471\tvalid_0's l2: 0.155085\n",
      "[92]\tvalid_0's l1: 0.281511\tvalid_0's l2: 0.155122\n",
      "[93]\tvalid_0's l1: 0.281227\tvalid_0's l2: 0.154861\n",
      "[94]\tvalid_0's l1: 0.281267\tvalid_0's l2: 0.154758\n",
      "[95]\tvalid_0's l1: 0.281263\tvalid_0's l2: 0.154769\n",
      "[96]\tvalid_0's l1: 0.280863\tvalid_0's l2: 0.154482\n",
      "[97]\tvalid_0's l1: 0.280909\tvalid_0's l2: 0.154588\n",
      "[98]\tvalid_0's l1: 0.280744\tvalid_0's l2: 0.154375\n",
      "[99]\tvalid_0's l1: 0.280773\tvalid_0's l2: 0.154369\n",
      "[100]\tvalid_0's l1: 0.280723\tvalid_0's l2: 0.15431\n",
      "[LightGBM] [Warning] Unknown parameter: learnnig_rage\n",
      "[1]\tvalid_0's l1: 0.564179\tvalid_0's l2: 0.442711\n",
      "[2]\tvalid_0's l1: 0.502811\tvalid_0's l2: 0.352574\n",
      "[3]\tvalid_0's l1: 0.44918\tvalid_0's l2: 0.28253\n",
      "[4]\tvalid_0's l1: 0.40496\tvalid_0's l2: 0.229971\n",
      "[5]\tvalid_0's l1: 0.365622\tvalid_0's l2: 0.188251\n",
      "[6]\tvalid_0's l1: 0.334511\tvalid_0's l2: 0.158413\n",
      "[7]\tvalid_0's l1: 0.308734\tvalid_0's l2: 0.135367\n",
      "[8]\tvalid_0's l1: 0.288093\tvalid_0's l2: 0.119895\n",
      "[9]\tvalid_0's l1: 0.272503\tvalid_0's l2: 0.109257\n",
      "[10]\tvalid_0's l1: 0.259323\tvalid_0's l2: 0.101707\n",
      "[11]\tvalid_0's l1: 0.250236\tvalid_0's l2: 0.0969178\n",
      "[12]\tvalid_0's l1: 0.246153\tvalid_0's l2: 0.0954477\n",
      "[13]\tvalid_0's l1: 0.243035\tvalid_0's l2: 0.094498\n",
      "[14]\tvalid_0's l1: 0.242289\tvalid_0's l2: 0.0950322\n",
      "[15]\tvalid_0's l1: 0.244227\tvalid_0's l2: 0.0968301\n",
      "[16]\tvalid_0's l1: 0.247493\tvalid_0's l2: 0.0994731\n",
      "[17]\tvalid_0's l1: 0.251872\tvalid_0's l2: 0.102633\n",
      "[18]\tvalid_0's l1: 0.256635\tvalid_0's l2: 0.105867\n",
      "[19]\tvalid_0's l1: 0.260963\tvalid_0's l2: 0.108521\n",
      "[20]\tvalid_0's l1: 0.264825\tvalid_0's l2: 0.111192\n",
      "[21]\tvalid_0's l1: 0.268537\tvalid_0's l2: 0.113786\n",
      "[22]\tvalid_0's l1: 0.273611\tvalid_0's l2: 0.117201\n",
      "[23]\tvalid_0's l1: 0.277207\tvalid_0's l2: 0.119877\n",
      "[24]\tvalid_0's l1: 0.281901\tvalid_0's l2: 0.122951\n",
      "[25]\tvalid_0's l1: 0.285717\tvalid_0's l2: 0.125719\n",
      "[26]\tvalid_0's l1: 0.289469\tvalid_0's l2: 0.128165\n",
      "[27]\tvalid_0's l1: 0.293164\tvalid_0's l2: 0.130825\n",
      "[28]\tvalid_0's l1: 0.294899\tvalid_0's l2: 0.132067\n",
      "[29]\tvalid_0's l1: 0.297002\tvalid_0's l2: 0.133763\n",
      "[30]\tvalid_0's l1: 0.298615\tvalid_0's l2: 0.134842\n",
      "[31]\tvalid_0's l1: 0.30073\tvalid_0's l2: 0.136238\n",
      "[32]\tvalid_0's l1: 0.302744\tvalid_0's l2: 0.137899\n",
      "[33]\tvalid_0's l1: 0.304386\tvalid_0's l2: 0.13929\n",
      "[34]\tvalid_0's l1: 0.305989\tvalid_0's l2: 0.140839\n",
      "[35]\tvalid_0's l1: 0.306574\tvalid_0's l2: 0.141458\n",
      "[36]\tvalid_0's l1: 0.30804\tvalid_0's l2: 0.142728\n",
      "[37]\tvalid_0's l1: 0.309235\tvalid_0's l2: 0.143898\n",
      "[38]\tvalid_0's l1: 0.309582\tvalid_0's l2: 0.144086\n",
      "[39]\tvalid_0's l1: 0.311087\tvalid_0's l2: 0.14562\n",
      "[40]\tvalid_0's l1: 0.311967\tvalid_0's l2: 0.146589\n",
      "[41]\tvalid_0's l1: 0.312418\tvalid_0's l2: 0.147126\n",
      "[42]\tvalid_0's l1: 0.312878\tvalid_0's l2: 0.147606\n",
      "[43]\tvalid_0's l1: 0.31413\tvalid_0's l2: 0.148778\n",
      "[44]\tvalid_0's l1: 0.315243\tvalid_0's l2: 0.149528\n",
      "[45]\tvalid_0's l1: 0.315732\tvalid_0's l2: 0.149852\n",
      "[46]\tvalid_0's l1: 0.316399\tvalid_0's l2: 0.150403\n",
      "[47]\tvalid_0's l1: 0.316759\tvalid_0's l2: 0.150754\n",
      "[48]\tvalid_0's l1: 0.317166\tvalid_0's l2: 0.15098\n",
      "[49]\tvalid_0's l1: 0.318252\tvalid_0's l2: 0.151931\n",
      "[50]\tvalid_0's l1: 0.318656\tvalid_0's l2: 0.15236\n",
      "[51]\tvalid_0's l1: 0.318597\tvalid_0's l2: 0.152432\n",
      "[52]\tvalid_0's l1: 0.318837\tvalid_0's l2: 0.152609\n",
      "[53]\tvalid_0's l1: 0.31888\tvalid_0's l2: 0.152669\n",
      "[54]\tvalid_0's l1: 0.319072\tvalid_0's l2: 0.153091\n",
      "[55]\tvalid_0's l1: 0.319166\tvalid_0's l2: 0.153097\n",
      "[56]\tvalid_0's l1: 0.319623\tvalid_0's l2: 0.153639\n",
      "[57]\tvalid_0's l1: 0.319469\tvalid_0's l2: 0.153592\n",
      "[58]\tvalid_0's l1: 0.319388\tvalid_0's l2: 0.153569\n",
      "[59]\tvalid_0's l1: 0.319142\tvalid_0's l2: 0.153462\n",
      "[60]\tvalid_0's l1: 0.319094\tvalid_0's l2: 0.153653\n",
      "[61]\tvalid_0's l1: 0.318991\tvalid_0's l2: 0.153659\n",
      "[62]\tvalid_0's l1: 0.318995\tvalid_0's l2: 0.153699\n",
      "[63]\tvalid_0's l1: 0.319054\tvalid_0's l2: 0.153895\n",
      "[64]\tvalid_0's l1: 0.318934\tvalid_0's l2: 0.153783\n",
      "[65]\tvalid_0's l1: 0.318916\tvalid_0's l2: 0.153776\n",
      "[66]\tvalid_0's l1: 0.319236\tvalid_0's l2: 0.15412\n",
      "[67]\tvalid_0's l1: 0.319414\tvalid_0's l2: 0.154371\n",
      "[68]\tvalid_0's l1: 0.319453\tvalid_0's l2: 0.154386\n",
      "[69]\tvalid_0's l1: 0.31942\tvalid_0's l2: 0.154357\n",
      "[70]\tvalid_0's l1: 0.319238\tvalid_0's l2: 0.154278\n",
      "[71]\tvalid_0's l1: 0.319116\tvalid_0's l2: 0.154284\n",
      "[72]\tvalid_0's l1: 0.319277\tvalid_0's l2: 0.1544\n",
      "[73]\tvalid_0's l1: 0.319226\tvalid_0's l2: 0.154401\n",
      "[74]\tvalid_0's l1: 0.319181\tvalid_0's l2: 0.154352\n",
      "[75]\tvalid_0's l1: 0.319353\tvalid_0's l2: 0.154474\n",
      "[76]\tvalid_0's l1: 0.319753\tvalid_0's l2: 0.154774\n",
      "[77]\tvalid_0's l1: 0.319614\tvalid_0's l2: 0.154715\n",
      "[78]\tvalid_0's l1: 0.319598\tvalid_0's l2: 0.15471\n",
      "[79]\tvalid_0's l1: 0.319605\tvalid_0's l2: 0.154746\n",
      "[80]\tvalid_0's l1: 0.319635\tvalid_0's l2: 0.154673\n",
      "[81]\tvalid_0's l1: 0.319649\tvalid_0's l2: 0.154679\n",
      "[82]\tvalid_0's l1: 0.319371\tvalid_0's l2: 0.15444\n",
      "[83]\tvalid_0's l1: 0.319657\tvalid_0's l2: 0.154727\n",
      "[84]\tvalid_0's l1: 0.319641\tvalid_0's l2: 0.15471\n",
      "[85]\tvalid_0's l1: 0.319626\tvalid_0's l2: 0.154729\n",
      "[86]\tvalid_0's l1: 0.319772\tvalid_0's l2: 0.154937\n",
      "[87]\tvalid_0's l1: 0.319711\tvalid_0's l2: 0.154892\n",
      "[88]\tvalid_0's l1: 0.319793\tvalid_0's l2: 0.154973\n",
      "[89]\tvalid_0's l1: 0.319848\tvalid_0's l2: 0.15511\n",
      "[90]\tvalid_0's l1: 0.319864\tvalid_0's l2: 0.155188\n",
      "[91]\tvalid_0's l1: 0.31961\tvalid_0's l2: 0.155021\n",
      "[92]\tvalid_0's l1: 0.319576\tvalid_0's l2: 0.154999\n",
      "[93]\tvalid_0's l1: 0.31957\tvalid_0's l2: 0.154996\n",
      "[94]\tvalid_0's l1: 0.319583\tvalid_0's l2: 0.155001\n",
      "[95]\tvalid_0's l1: 0.319577\tvalid_0's l2: 0.155133\n",
      "[96]\tvalid_0's l1: 0.319533\tvalid_0's l2: 0.155115\n",
      "[97]\tvalid_0's l1: 0.319444\tvalid_0's l2: 0.155018\n",
      "[98]\tvalid_0's l1: 0.319334\tvalid_0's l2: 0.154967\n",
      "[99]\tvalid_0's l1: 0.31905\tvalid_0's l2: 0.154858\n",
      "[100]\tvalid_0's l1: 0.319043\tvalid_0's l2: 0.154839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:179: UserWarning: Converting column-vector to 1d array\n",
      "  _log_warning('Converting column-vector to 1d array')\n",
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:179: UserWarning: Converting column-vector to 1d array\n",
      "  _log_warning('Converting column-vector to 1d array')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: learnnig_rage\n",
      "[1]\tvalid_0's l1: 0.662224\tvalid_0's l2: 0.777368\n",
      "[2]\tvalid_0's l1: 0.605572\tvalid_0's l2: 0.659376\n",
      "[3]\tvalid_0's l1: 0.556619\tvalid_0's l2: 0.564761\n",
      "[4]\tvalid_0's l1: 0.515333\tvalid_0's l2: 0.48965\n",
      "[5]\tvalid_0's l1: 0.476143\tvalid_0's l2: 0.423122\n",
      "[6]\tvalid_0's l1: 0.441502\tvalid_0's l2: 0.369206\n",
      "[7]\tvalid_0's l1: 0.413345\tvalid_0's l2: 0.327732\n",
      "[8]\tvalid_0's l1: 0.387812\tvalid_0's l2: 0.292015\n",
      "[9]\tvalid_0's l1: 0.366759\tvalid_0's l2: 0.264071\n",
      "[10]\tvalid_0's l1: 0.346301\tvalid_0's l2: 0.238659\n",
      "[11]\tvalid_0's l1: 0.329697\tvalid_0's l2: 0.219286\n",
      "[12]\tvalid_0's l1: 0.315467\tvalid_0's l2: 0.202518\n",
      "[13]\tvalid_0's l1: 0.303382\tvalid_0's l2: 0.189221\n",
      "[14]\tvalid_0's l1: 0.293424\tvalid_0's l2: 0.178068\n",
      "[15]\tvalid_0's l1: 0.28494\tvalid_0's l2: 0.169005\n",
      "[16]\tvalid_0's l1: 0.277398\tvalid_0's l2: 0.161519\n",
      "[17]\tvalid_0's l1: 0.271229\tvalid_0's l2: 0.155203\n",
      "[18]\tvalid_0's l1: 0.265048\tvalid_0's l2: 0.149226\n",
      "[19]\tvalid_0's l1: 0.260568\tvalid_0's l2: 0.144818\n",
      "[20]\tvalid_0's l1: 0.256134\tvalid_0's l2: 0.141059\n",
      "[21]\tvalid_0's l1: 0.25279\tvalid_0's l2: 0.137889\n",
      "[22]\tvalid_0's l1: 0.250587\tvalid_0's l2: 0.13554\n",
      "[23]\tvalid_0's l1: 0.248546\tvalid_0's l2: 0.133633\n",
      "[24]\tvalid_0's l1: 0.246606\tvalid_0's l2: 0.131747\n",
      "[25]\tvalid_0's l1: 0.245515\tvalid_0's l2: 0.130682\n",
      "[26]\tvalid_0's l1: 0.244159\tvalid_0's l2: 0.129376\n",
      "[27]\tvalid_0's l1: 0.242595\tvalid_0's l2: 0.128078\n",
      "[28]\tvalid_0's l1: 0.241738\tvalid_0's l2: 0.126825\n",
      "[29]\tvalid_0's l1: 0.240785\tvalid_0's l2: 0.12585\n",
      "[30]\tvalid_0's l1: 0.240338\tvalid_0's l2: 0.125457\n",
      "[31]\tvalid_0's l1: 0.23963\tvalid_0's l2: 0.12469\n",
      "[32]\tvalid_0's l1: 0.239399\tvalid_0's l2: 0.124518\n",
      "[33]\tvalid_0's l1: 0.238964\tvalid_0's l2: 0.124253\n",
      "[34]\tvalid_0's l1: 0.238717\tvalid_0's l2: 0.123857\n",
      "[35]\tvalid_0's l1: 0.238845\tvalid_0's l2: 0.123964\n",
      "[36]\tvalid_0's l1: 0.238852\tvalid_0's l2: 0.123735\n",
      "[37]\tvalid_0's l1: 0.238738\tvalid_0's l2: 0.123582\n",
      "[38]\tvalid_0's l1: 0.238594\tvalid_0's l2: 0.123218\n",
      "[39]\tvalid_0's l1: 0.238298\tvalid_0's l2: 0.122936\n",
      "[40]\tvalid_0's l1: 0.238149\tvalid_0's l2: 0.122641\n",
      "[41]\tvalid_0's l1: 0.23793\tvalid_0's l2: 0.122465\n",
      "[42]\tvalid_0's l1: 0.237964\tvalid_0's l2: 0.122334\n",
      "[43]\tvalid_0's l1: 0.237821\tvalid_0's l2: 0.122186\n",
      "[44]\tvalid_0's l1: 0.238009\tvalid_0's l2: 0.122233\n",
      "[45]\tvalid_0's l1: 0.238003\tvalid_0's l2: 0.122037\n",
      "[46]\tvalid_0's l1: 0.237979\tvalid_0's l2: 0.121953\n",
      "[47]\tvalid_0's l1: 0.237925\tvalid_0's l2: 0.121683\n",
      "[48]\tvalid_0's l1: 0.237939\tvalid_0's l2: 0.121544\n",
      "[49]\tvalid_0's l1: 0.237587\tvalid_0's l2: 0.121213\n",
      "[50]\tvalid_0's l1: 0.237506\tvalid_0's l2: 0.121094\n",
      "[51]\tvalid_0's l1: 0.237458\tvalid_0's l2: 0.121085\n",
      "[52]\tvalid_0's l1: 0.237375\tvalid_0's l2: 0.12107\n",
      "[53]\tvalid_0's l1: 0.237169\tvalid_0's l2: 0.120813\n",
      "[54]\tvalid_0's l1: 0.236946\tvalid_0's l2: 0.120659\n",
      "[55]\tvalid_0's l1: 0.237338\tvalid_0's l2: 0.120827\n",
      "[56]\tvalid_0's l1: 0.237226\tvalid_0's l2: 0.12078\n",
      "[57]\tvalid_0's l1: 0.237212\tvalid_0's l2: 0.120715\n",
      "[58]\tvalid_0's l1: 0.237144\tvalid_0's l2: 0.120704\n",
      "[59]\tvalid_0's l1: 0.237264\tvalid_0's l2: 0.12071\n",
      "[60]\tvalid_0's l1: 0.237507\tvalid_0's l2: 0.120757\n",
      "[61]\tvalid_0's l1: 0.237467\tvalid_0's l2: 0.120742\n",
      "[62]\tvalid_0's l1: 0.237441\tvalid_0's l2: 0.120736\n",
      "[63]\tvalid_0's l1: 0.237323\tvalid_0's l2: 0.120612\n",
      "[64]\tvalid_0's l1: 0.237201\tvalid_0's l2: 0.120521\n",
      "[65]\tvalid_0's l1: 0.237122\tvalid_0's l2: 0.120391\n",
      "[66]\tvalid_0's l1: 0.236972\tvalid_0's l2: 0.120316\n",
      "[67]\tvalid_0's l1: 0.236974\tvalid_0's l2: 0.120314\n",
      "[68]\tvalid_0's l1: 0.23694\tvalid_0's l2: 0.120308\n",
      "[69]\tvalid_0's l1: 0.236896\tvalid_0's l2: 0.120312\n",
      "[70]\tvalid_0's l1: 0.237087\tvalid_0's l2: 0.120181\n",
      "[71]\tvalid_0's l1: 0.236968\tvalid_0's l2: 0.120003\n",
      "[72]\tvalid_0's l1: 0.236792\tvalid_0's l2: 0.119801\n",
      "[73]\tvalid_0's l1: 0.236807\tvalid_0's l2: 0.11981\n",
      "[74]\tvalid_0's l1: 0.236823\tvalid_0's l2: 0.119816\n",
      "[75]\tvalid_0's l1: 0.236823\tvalid_0's l2: 0.119758\n",
      "[76]\tvalid_0's l1: 0.236831\tvalid_0's l2: 0.119752\n",
      "[77]\tvalid_0's l1: 0.236802\tvalid_0's l2: 0.119642\n",
      "[78]\tvalid_0's l1: 0.236473\tvalid_0's l2: 0.119472\n",
      "[79]\tvalid_0's l1: 0.23647\tvalid_0's l2: 0.119468\n",
      "[80]\tvalid_0's l1: 0.236445\tvalid_0's l2: 0.119425\n",
      "[81]\tvalid_0's l1: 0.236416\tvalid_0's l2: 0.11942\n",
      "[82]\tvalid_0's l1: 0.236364\tvalid_0's l2: 0.119323\n",
      "[83]\tvalid_0's l1: 0.236328\tvalid_0's l2: 0.119321\n",
      "[84]\tvalid_0's l1: 0.236301\tvalid_0's l2: 0.119308\n",
      "[85]\tvalid_0's l1: 0.236285\tvalid_0's l2: 0.119294\n",
      "[86]\tvalid_0's l1: 0.236251\tvalid_0's l2: 0.119288\n",
      "[87]\tvalid_0's l1: 0.236249\tvalid_0's l2: 0.119281\n",
      "[88]\tvalid_0's l1: 0.23621\tvalid_0's l2: 0.119277\n",
      "[89]\tvalid_0's l1: 0.23622\tvalid_0's l2: 0.119289\n",
      "[90]\tvalid_0's l1: 0.236184\tvalid_0's l2: 0.119252\n",
      "[91]\tvalid_0's l1: 0.236351\tvalid_0's l2: 0.11934\n",
      "[92]\tvalid_0's l1: 0.236246\tvalid_0's l2: 0.119304\n",
      "[93]\tvalid_0's l1: 0.236151\tvalid_0's l2: 0.119195\n",
      "[94]\tvalid_0's l1: 0.236174\tvalid_0's l2: 0.119237\n",
      "[95]\tvalid_0's l1: 0.236001\tvalid_0's l2: 0.119063\n",
      "[96]\tvalid_0's l1: 0.235991\tvalid_0's l2: 0.119064\n",
      "[97]\tvalid_0's l1: 0.23601\tvalid_0's l2: 0.119095\n",
      "[98]\tvalid_0's l1: 0.235952\tvalid_0's l2: 0.118983\n",
      "[99]\tvalid_0's l1: 0.235862\tvalid_0's l2: 0.11895\n",
      "[100]\tvalid_0's l1: 0.235819\tvalid_0's l2: 0.118906\n",
      "[LightGBM] [Warning] Unknown parameter: learnnig_rage\n",
      "[1]\tvalid_0's l1: 0.787113\tvalid_0's l2: 1.01285\n",
      "[2]\tvalid_0's l1: 0.726279\tvalid_0's l2: 0.86942\n",
      "[3]\tvalid_0's l1: 0.671557\tvalid_0's l2: 0.75127\n",
      "[4]\tvalid_0's l1: 0.623366\tvalid_0's l2: 0.653296\n",
      "[5]\tvalid_0's l1: 0.580794\tvalid_0's l2: 0.572464\n",
      "[6]\tvalid_0's l1: 0.543161\tvalid_0's l2: 0.507253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:179: UserWarning: Converting column-vector to 1d array\n",
      "  _log_warning('Converting column-vector to 1d array')\n",
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:179: UserWarning: Converting column-vector to 1d array\n",
      "  _log_warning('Converting column-vector to 1d array')\n",
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:179: UserWarning: Converting column-vector to 1d array\n",
      "  _log_warning('Converting column-vector to 1d array')\n",
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:179: UserWarning: Converting column-vector to 1d array\n",
      "  _log_warning('Converting column-vector to 1d array')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7]\tvalid_0's l1: 0.50983\tvalid_0's l2: 0.450563\n",
      "[8]\tvalid_0's l1: 0.480401\tvalid_0's l2: 0.403629\n",
      "[9]\tvalid_0's l1: 0.456032\tvalid_0's l2: 0.366477\n",
      "[10]\tvalid_0's l1: 0.433741\tvalid_0's l2: 0.334629\n",
      "[11]\tvalid_0's l1: 0.413425\tvalid_0's l2: 0.30608\n",
      "[12]\tvalid_0's l1: 0.396005\tvalid_0's l2: 0.282798\n",
      "[13]\tvalid_0's l1: 0.380367\tvalid_0's l2: 0.263629\n",
      "[14]\tvalid_0's l1: 0.366306\tvalid_0's l2: 0.246299\n",
      "[15]\tvalid_0's l1: 0.354737\tvalid_0's l2: 0.232838\n",
      "[16]\tvalid_0's l1: 0.343744\tvalid_0's l2: 0.221509\n",
      "[17]\tvalid_0's l1: 0.334583\tvalid_0's l2: 0.211974\n",
      "[18]\tvalid_0's l1: 0.325568\tvalid_0's l2: 0.202843\n",
      "[19]\tvalid_0's l1: 0.318311\tvalid_0's l2: 0.19592\n",
      "[20]\tvalid_0's l1: 0.310524\tvalid_0's l2: 0.188346\n",
      "[21]\tvalid_0's l1: 0.305447\tvalid_0's l2: 0.184369\n",
      "[22]\tvalid_0's l1: 0.301242\tvalid_0's l2: 0.181282\n",
      "[23]\tvalid_0's l1: 0.296737\tvalid_0's l2: 0.177274\n",
      "[24]\tvalid_0's l1: 0.292766\tvalid_0's l2: 0.173805\n",
      "[25]\tvalid_0's l1: 0.289352\tvalid_0's l2: 0.171278\n",
      "[26]\tvalid_0's l1: 0.285988\tvalid_0's l2: 0.168446\n",
      "[27]\tvalid_0's l1: 0.281451\tvalid_0's l2: 0.164279\n",
      "[28]\tvalid_0's l1: 0.279102\tvalid_0's l2: 0.162022\n",
      "[29]\tvalid_0's l1: 0.277127\tvalid_0's l2: 0.160639\n",
      "[30]\tvalid_0's l1: 0.275647\tvalid_0's l2: 0.160301\n",
      "[31]\tvalid_0's l1: 0.273622\tvalid_0's l2: 0.159296\n",
      "[32]\tvalid_0's l1: 0.272319\tvalid_0's l2: 0.159025\n",
      "[33]\tvalid_0's l1: 0.270942\tvalid_0's l2: 0.158044\n",
      "[34]\tvalid_0's l1: 0.269178\tvalid_0's l2: 0.156689\n",
      "[35]\tvalid_0's l1: 0.267839\tvalid_0's l2: 0.155834\n",
      "[36]\tvalid_0's l1: 0.265807\tvalid_0's l2: 0.15408\n",
      "[37]\tvalid_0's l1: 0.265099\tvalid_0's l2: 0.154026\n",
      "[38]\tvalid_0's l1: 0.264129\tvalid_0's l2: 0.153397\n",
      "[39]\tvalid_0's l1: 0.263732\tvalid_0's l2: 0.153478\n",
      "[40]\tvalid_0's l1: 0.262653\tvalid_0's l2: 0.152576\n",
      "[41]\tvalid_0's l1: 0.262478\tvalid_0's l2: 0.152672\n",
      "[42]\tvalid_0's l1: 0.261603\tvalid_0's l2: 0.151995\n",
      "[43]\tvalid_0's l1: 0.260861\tvalid_0's l2: 0.151336\n",
      "[44]\tvalid_0's l1: 0.260311\tvalid_0's l2: 0.151116\n",
      "[45]\tvalid_0's l1: 0.260117\tvalid_0's l2: 0.150568\n",
      "[46]\tvalid_0's l1: 0.259496\tvalid_0's l2: 0.150274\n",
      "[47]\tvalid_0's l1: 0.259815\tvalid_0's l2: 0.15043\n",
      "[48]\tvalid_0's l1: 0.259887\tvalid_0's l2: 0.150597\n",
      "[49]\tvalid_0's l1: 0.259329\tvalid_0's l2: 0.15008\n",
      "[50]\tvalid_0's l1: 0.259644\tvalid_0's l2: 0.150643\n",
      "[51]\tvalid_0's l1: 0.259562\tvalid_0's l2: 0.150486\n",
      "[52]\tvalid_0's l1: 0.26026\tvalid_0's l2: 0.151444\n",
      "[53]\tvalid_0's l1: 0.259417\tvalid_0's l2: 0.150633\n",
      "[54]\tvalid_0's l1: 0.25979\tvalid_0's l2: 0.151249\n",
      "[55]\tvalid_0's l1: 0.259608\tvalid_0's l2: 0.15094\n",
      "[56]\tvalid_0's l1: 0.259912\tvalid_0's l2: 0.150596\n",
      "[57]\tvalid_0's l1: 0.259641\tvalid_0's l2: 0.150253\n",
      "[58]\tvalid_0's l1: 0.259778\tvalid_0's l2: 0.150383\n",
      "[59]\tvalid_0's l1: 0.259735\tvalid_0's l2: 0.150303\n",
      "[60]\tvalid_0's l1: 0.259661\tvalid_0's l2: 0.150065\n",
      "[61]\tvalid_0's l1: 0.260726\tvalid_0's l2: 0.151396\n",
      "[62]\tvalid_0's l1: 0.260587\tvalid_0's l2: 0.151352\n",
      "[63]\tvalid_0's l1: 0.260706\tvalid_0's l2: 0.151543\n",
      "[64]\tvalid_0's l1: 0.260668\tvalid_0's l2: 0.151441\n",
      "[65]\tvalid_0's l1: 0.260647\tvalid_0's l2: 0.151345\n",
      "[66]\tvalid_0's l1: 0.260315\tvalid_0's l2: 0.151125\n",
      "[67]\tvalid_0's l1: 0.26039\tvalid_0's l2: 0.151122\n",
      "[68]\tvalid_0's l1: 0.260892\tvalid_0's l2: 0.151363\n",
      "[69]\tvalid_0's l1: 0.26132\tvalid_0's l2: 0.151655\n",
      "[70]\tvalid_0's l1: 0.261104\tvalid_0's l2: 0.151621\n",
      "[71]\tvalid_0's l1: 0.260913\tvalid_0's l2: 0.151223\n",
      "[72]\tvalid_0's l1: 0.260878\tvalid_0's l2: 0.151304\n",
      "[73]\tvalid_0's l1: 0.260801\tvalid_0's l2: 0.151167\n",
      "[74]\tvalid_0's l1: 0.260685\tvalid_0's l2: 0.151372\n",
      "[75]\tvalid_0's l1: 0.260648\tvalid_0's l2: 0.151333\n",
      "[76]\tvalid_0's l1: 0.260553\tvalid_0's l2: 0.151298\n",
      "[77]\tvalid_0's l1: 0.260575\tvalid_0's l2: 0.151296\n",
      "[78]\tvalid_0's l1: 0.260438\tvalid_0's l2: 0.151014\n",
      "[79]\tvalid_0's l1: 0.260456\tvalid_0's l2: 0.151006\n",
      "[80]\tvalid_0's l1: 0.260521\tvalid_0's l2: 0.151\n",
      "[81]\tvalid_0's l1: 0.260573\tvalid_0's l2: 0.151048\n",
      "[82]\tvalid_0's l1: 0.260487\tvalid_0's l2: 0.150859\n",
      "[83]\tvalid_0's l1: 0.260437\tvalid_0's l2: 0.150969\n",
      "[84]\tvalid_0's l1: 0.260432\tvalid_0's l2: 0.150997\n",
      "[85]\tvalid_0's l1: 0.260329\tvalid_0's l2: 0.151194\n",
      "[86]\tvalid_0's l1: 0.260426\tvalid_0's l2: 0.15131\n",
      "[87]\tvalid_0's l1: 0.260578\tvalid_0's l2: 0.151405\n",
      "[88]\tvalid_0's l1: 0.260682\tvalid_0's l2: 0.151574\n",
      "[89]\tvalid_0's l1: 0.260812\tvalid_0's l2: 0.151642\n",
      "[90]\tvalid_0's l1: 0.260759\tvalid_0's l2: 0.151613\n",
      "[91]\tvalid_0's l1: 0.260634\tvalid_0's l2: 0.151589\n",
      "[92]\tvalid_0's l1: 0.260445\tvalid_0's l2: 0.151646\n",
      "[93]\tvalid_0's l1: 0.260448\tvalid_0's l2: 0.151556\n",
      "[94]\tvalid_0's l1: 0.260556\tvalid_0's l2: 0.151617\n",
      "[95]\tvalid_0's l1: 0.260431\tvalid_0's l2: 0.151343\n",
      "[96]\tvalid_0's l1: 0.260407\tvalid_0's l2: 0.151342\n",
      "[97]\tvalid_0's l1: 0.260289\tvalid_0's l2: 0.151366\n",
      "[98]\tvalid_0's l1: 0.26025\tvalid_0's l2: 0.151272\n",
      "[99]\tvalid_0's l1: 0.260479\tvalid_0's l2: 0.151361\n",
      "[100]\tvalid_0's l1: 0.260624\tvalid_0's l2: 0.151411\n",
      "[LightGBM] [Warning] Unknown parameter: learnnig_rage\n",
      "[1]\tvalid_0's l1: 0.629119\tvalid_0's l2: 0.732705\n",
      "[2]\tvalid_0's l1: 0.570392\tvalid_0's l2: 0.619146\n",
      "[3]\tvalid_0's l1: 0.519703\tvalid_0's l2: 0.530854\n",
      "[4]\tvalid_0's l1: 0.47641\tvalid_0's l2: 0.46048\n",
      "[5]\tvalid_0's l1: 0.437159\tvalid_0's l2: 0.399967\n",
      "[6]\tvalid_0's l1: 0.403583\tvalid_0's l2: 0.350365\n",
      "[7]\tvalid_0's l1: 0.37619\tvalid_0's l2: 0.313481\n",
      "[8]\tvalid_0's l1: 0.352941\tvalid_0's l2: 0.283333\n",
      "[9]\tvalid_0's l1: 0.334519\tvalid_0's l2: 0.258858\n",
      "[10]\tvalid_0's l1: 0.318641\tvalid_0's l2: 0.236991\n",
      "[11]\tvalid_0's l1: 0.307894\tvalid_0's l2: 0.220679\n",
      "[12]\tvalid_0's l1: 0.300285\tvalid_0's l2: 0.207797\n",
      "[13]\tvalid_0's l1: 0.295214\tvalid_0's l2: 0.197466\n",
      "[14]\tvalid_0's l1: 0.291723\tvalid_0's l2: 0.189949\n",
      "[15]\tvalid_0's l1: 0.28992\tvalid_0's l2: 0.184208\n",
      "[16]\tvalid_0's l1: 0.288396\tvalid_0's l2: 0.179129\n",
      "[17]\tvalid_0's l1: 0.288036\tvalid_0's l2: 0.175161\n",
      "[18]\tvalid_0's l1: 0.288312\tvalid_0's l2: 0.172008\n",
      "[19]\tvalid_0's l1: 0.288191\tvalid_0's l2: 0.169376\n",
      "[20]\tvalid_0's l1: 0.288986\tvalid_0's l2: 0.167624\n",
      "[21]\tvalid_0's l1: 0.290242\tvalid_0's l2: 0.16639\n",
      "[22]\tvalid_0's l1: 0.291185\tvalid_0's l2: 0.165374\n",
      "[23]\tvalid_0's l1: 0.291745\tvalid_0's l2: 0.164873\n",
      "[24]\tvalid_0's l1: 0.293357\tvalid_0's l2: 0.164755\n",
      "[25]\tvalid_0's l1: 0.293868\tvalid_0's l2: 0.164325\n",
      "[26]\tvalid_0's l1: 0.294505\tvalid_0's l2: 0.164199\n",
      "[27]\tvalid_0's l1: 0.295343\tvalid_0's l2: 0.164164\n",
      "[28]\tvalid_0's l1: 0.295915\tvalid_0's l2: 0.163722\n",
      "[29]\tvalid_0's l1: 0.296406\tvalid_0's l2: 0.163688\n",
      "[30]\tvalid_0's l1: 0.296898\tvalid_0's l2: 0.163886\n",
      "[31]\tvalid_0's l1: 0.297954\tvalid_0's l2: 0.164241\n",
      "[32]\tvalid_0's l1: 0.298622\tvalid_0's l2: 0.164698\n",
      "[33]\tvalid_0's l1: 0.299126\tvalid_0's l2: 0.164755\n",
      "[34]\tvalid_0's l1: 0.300134\tvalid_0's l2: 0.165406\n",
      "[35]\tvalid_0's l1: 0.300681\tvalid_0's l2: 0.16583\n",
      "[36]\tvalid_0's l1: 0.301221\tvalid_0's l2: 0.16607\n",
      "[37]\tvalid_0's l1: 0.301644\tvalid_0's l2: 0.166099\n",
      "[38]\tvalid_0's l1: 0.302121\tvalid_0's l2: 0.166495\n",
      "[39]\tvalid_0's l1: 0.301923\tvalid_0's l2: 0.16599\n",
      "[40]\tvalid_0's l1: 0.302081\tvalid_0's l2: 0.166085\n",
      "[41]\tvalid_0's l1: 0.30209\tvalid_0's l2: 0.166088\n",
      "[42]\tvalid_0's l1: 0.302486\tvalid_0's l2: 0.166519\n",
      "[43]\tvalid_0's l1: 0.302926\tvalid_0's l2: 0.166849\n",
      "[44]\tvalid_0's l1: 0.303369\tvalid_0's l2: 0.167178\n",
      "[45]\tvalid_0's l1: 0.303543\tvalid_0's l2: 0.167367\n",
      "[46]\tvalid_0's l1: 0.303617\tvalid_0's l2: 0.167411\n",
      "[47]\tvalid_0's l1: 0.303651\tvalid_0's l2: 0.167381\n",
      "[48]\tvalid_0's l1: 0.303665\tvalid_0's l2: 0.167396\n",
      "[49]\tvalid_0's l1: 0.303771\tvalid_0's l2: 0.167407\n",
      "[50]\tvalid_0's l1: 0.304329\tvalid_0's l2: 0.167725\n",
      "[51]\tvalid_0's l1: 0.304373\tvalid_0's l2: 0.167822\n",
      "[52]\tvalid_0's l1: 0.304378\tvalid_0's l2: 0.167893\n",
      "[53]\tvalid_0's l1: 0.304483\tvalid_0's l2: 0.1679\n",
      "[54]\tvalid_0's l1: 0.304508\tvalid_0's l2: 0.167899\n",
      "[55]\tvalid_0's l1: 0.305051\tvalid_0's l2: 0.168345\n",
      "[56]\tvalid_0's l1: 0.305011\tvalid_0's l2: 0.168305\n",
      "[57]\tvalid_0's l1: 0.305096\tvalid_0's l2: 0.168405\n",
      "[58]\tvalid_0's l1: 0.305098\tvalid_0's l2: 0.168463\n",
      "[59]\tvalid_0's l1: 0.305229\tvalid_0's l2: 0.168606\n",
      "[60]\tvalid_0's l1: 0.305464\tvalid_0's l2: 0.168848\n",
      "[61]\tvalid_0's l1: 0.305473\tvalid_0's l2: 0.168878\n",
      "[62]\tvalid_0's l1: 0.305489\tvalid_0's l2: 0.168913\n",
      "[63]\tvalid_0's l1: 0.305519\tvalid_0's l2: 0.168903\n",
      "[64]\tvalid_0's l1: 0.30541\tvalid_0's l2: 0.168895\n",
      "[65]\tvalid_0's l1: 0.304935\tvalid_0's l2: 0.168537\n",
      "[66]\tvalid_0's l1: 0.304997\tvalid_0's l2: 0.168639\n",
      "[67]\tvalid_0's l1: 0.304957\tvalid_0's l2: 0.168536\n",
      "[68]\tvalid_0's l1: 0.304953\tvalid_0's l2: 0.168572\n",
      "[69]\tvalid_0's l1: 0.304949\tvalid_0's l2: 0.168623\n",
      "[70]\tvalid_0's l1: 0.304633\tvalid_0's l2: 0.168317\n",
      "[71]\tvalid_0's l1: 0.304686\tvalid_0's l2: 0.168328\n",
      "[72]\tvalid_0's l1: 0.304693\tvalid_0's l2: 0.16829\n",
      "[73]\tvalid_0's l1: 0.304409\tvalid_0's l2: 0.168142\n",
      "[74]\tvalid_0's l1: 0.304633\tvalid_0's l2: 0.168232\n",
      "[75]\tvalid_0's l1: 0.304754\tvalid_0's l2: 0.168314\n",
      "[76]\tvalid_0's l1: 0.304872\tvalid_0's l2: 0.168399\n",
      "[77]\tvalid_0's l1: 0.304355\tvalid_0's l2: 0.167959\n",
      "[78]\tvalid_0's l1: 0.304515\tvalid_0's l2: 0.168268\n",
      "[79]\tvalid_0's l1: 0.304462\tvalid_0's l2: 0.168186\n",
      "[80]\tvalid_0's l1: 0.304521\tvalid_0's l2: 0.168315\n",
      "[81]\tvalid_0's l1: 0.304521\tvalid_0's l2: 0.168344\n",
      "[82]\tvalid_0's l1: 0.30425\tvalid_0's l2: 0.168091\n",
      "[83]\tvalid_0's l1: 0.304227\tvalid_0's l2: 0.168027\n",
      "[84]\tvalid_0's l1: 0.304251\tvalid_0's l2: 0.168056\n",
      "[85]\tvalid_0's l1: 0.304494\tvalid_0's l2: 0.16823\n",
      "[86]\tvalid_0's l1: 0.304497\tvalid_0's l2: 0.168265\n",
      "[87]\tvalid_0's l1: 0.304331\tvalid_0's l2: 0.168171\n",
      "[88]\tvalid_0's l1: 0.304335\tvalid_0's l2: 0.168212\n",
      "[89]\tvalid_0's l1: 0.304292\tvalid_0's l2: 0.168133\n",
      "[90]\tvalid_0's l1: 0.304038\tvalid_0's l2: 0.16798\n",
      "[91]\tvalid_0's l1: 0.30423\tvalid_0's l2: 0.168199\n",
      "[92]\tvalid_0's l1: 0.30437\tvalid_0's l2: 0.168242\n",
      "[93]\tvalid_0's l1: 0.304004\tvalid_0's l2: 0.167986\n",
      "[94]\tvalid_0's l1: 0.303982\tvalid_0's l2: 0.167944\n",
      "[95]\tvalid_0's l1: 0.303795\tvalid_0's l2: 0.1678\n",
      "[96]\tvalid_0's l1: 0.303796\tvalid_0's l2: 0.16781\n",
      "[97]\tvalid_0's l1: 0.303923\tvalid_0's l2: 0.168015\n",
      "[98]\tvalid_0's l1: 0.303586\tvalid_0's l2: 0.167721\n",
      "[99]\tvalid_0's l1: 0.303561\tvalid_0's l2: 0.16776\n",
      "[100]\tvalid_0's l1: 0.303695\tvalid_0's l2: 0.167897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:179: UserWarning: Converting column-vector to 1d array\n",
      "  _log_warning('Converting column-vector to 1d array')\n",
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:179: UserWarning: Converting column-vector to 1d array\n",
      "  _log_warning('Converting column-vector to 1d array')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: learnnig_rage\n",
      "[1]\tvalid_0's l1: 0.592885\tvalid_0's l2: 0.556095\n",
      "[2]\tvalid_0's l1: 0.533309\tvalid_0's l2: 0.452387\n",
      "[3]\tvalid_0's l1: 0.480388\tvalid_0's l2: 0.370371\n",
      "[4]\tvalid_0's l1: 0.434362\tvalid_0's l2: 0.30518\n",
      "[5]\tvalid_0's l1: 0.392444\tvalid_0's l2: 0.250929\n",
      "[6]\tvalid_0's l1: 0.355933\tvalid_0's l2: 0.207676\n",
      "[7]\tvalid_0's l1: 0.32418\tvalid_0's l2: 0.173877\n",
      "[8]\tvalid_0's l1: 0.296037\tvalid_0's l2: 0.145637\n",
      "[9]\tvalid_0's l1: 0.273958\tvalid_0's l2: 0.124618\n",
      "[10]\tvalid_0's l1: 0.254224\tvalid_0's l2: 0.107486\n",
      "[11]\tvalid_0's l1: 0.235897\tvalid_0's l2: 0.0930824\n",
      "[12]\tvalid_0's l1: 0.222049\tvalid_0's l2: 0.0830536\n",
      "[13]\tvalid_0's l1: 0.21016\tvalid_0's l2: 0.0748641\n",
      "[14]\tvalid_0's l1: 0.199467\tvalid_0's l2: 0.0680517\n",
      "[15]\tvalid_0's l1: 0.191172\tvalid_0's l2: 0.062831\n",
      "[16]\tvalid_0's l1: 0.18474\tvalid_0's l2: 0.0590722\n",
      "[17]\tvalid_0's l1: 0.178888\tvalid_0's l2: 0.0560104\n",
      "[18]\tvalid_0's l1: 0.174416\tvalid_0's l2: 0.0534581\n",
      "[19]\tvalid_0's l1: 0.171188\tvalid_0's l2: 0.0518873\n",
      "[20]\tvalid_0's l1: 0.168031\tvalid_0's l2: 0.0502457\n",
      "[21]\tvalid_0's l1: 0.165822\tvalid_0's l2: 0.0492938\n",
      "[22]\tvalid_0's l1: 0.163734\tvalid_0's l2: 0.0483968\n",
      "[23]\tvalid_0's l1: 0.162594\tvalid_0's l2: 0.0478595\n",
      "[24]\tvalid_0's l1: 0.161124\tvalid_0's l2: 0.047367\n",
      "[25]\tvalid_0's l1: 0.160564\tvalid_0's l2: 0.0470883\n",
      "[26]\tvalid_0's l1: 0.159855\tvalid_0's l2: 0.0468626\n",
      "[27]\tvalid_0's l1: 0.159321\tvalid_0's l2: 0.0467516\n",
      "[28]\tvalid_0's l1: 0.158777\tvalid_0's l2: 0.0467008\n",
      "[29]\tvalid_0's l1: 0.159019\tvalid_0's l2: 0.0469498\n",
      "[30]\tvalid_0's l1: 0.159518\tvalid_0's l2: 0.0472709\n",
      "[31]\tvalid_0's l1: 0.160065\tvalid_0's l2: 0.0476535\n",
      "[32]\tvalid_0's l1: 0.160831\tvalid_0's l2: 0.0480808\n",
      "[33]\tvalid_0's l1: 0.161166\tvalid_0's l2: 0.0483285\n",
      "[34]\tvalid_0's l1: 0.161401\tvalid_0's l2: 0.0484061\n",
      "[35]\tvalid_0's l1: 0.161367\tvalid_0's l2: 0.0483742\n",
      "[36]\tvalid_0's l1: 0.161883\tvalid_0's l2: 0.0486017\n",
      "[37]\tvalid_0's l1: 0.161874\tvalid_0's l2: 0.0486121\n",
      "[38]\tvalid_0's l1: 0.162143\tvalid_0's l2: 0.0487183\n",
      "[39]\tvalid_0's l1: 0.162124\tvalid_0's l2: 0.0486893\n",
      "[40]\tvalid_0's l1: 0.162156\tvalid_0's l2: 0.0486959\n",
      "[41]\tvalid_0's l1: 0.162362\tvalid_0's l2: 0.0488578\n",
      "[42]\tvalid_0's l1: 0.162591\tvalid_0's l2: 0.0489328\n",
      "[43]\tvalid_0's l1: 0.16298\tvalid_0's l2: 0.0492151\n",
      "[44]\tvalid_0's l1: 0.163449\tvalid_0's l2: 0.049491\n",
      "[45]\tvalid_0's l1: 0.163743\tvalid_0's l2: 0.0496252\n",
      "[46]\tvalid_0's l1: 0.164338\tvalid_0's l2: 0.0499941\n",
      "[47]\tvalid_0's l1: 0.164383\tvalid_0's l2: 0.0500606\n",
      "[48]\tvalid_0's l1: 0.164493\tvalid_0's l2: 0.0500816\n",
      "[49]\tvalid_0's l1: 0.164762\tvalid_0's l2: 0.050214\n",
      "[50]\tvalid_0's l1: 0.164696\tvalid_0's l2: 0.0501667\n",
      "[51]\tvalid_0's l1: 0.164708\tvalid_0's l2: 0.0501414\n",
      "[52]\tvalid_0's l1: 0.16489\tvalid_0's l2: 0.0502443\n",
      "[53]\tvalid_0's l1: 0.164891\tvalid_0's l2: 0.0502251\n",
      "[54]\tvalid_0's l1: 0.164967\tvalid_0's l2: 0.050244\n",
      "[55]\tvalid_0's l1: 0.164945\tvalid_0's l2: 0.0502129\n",
      "[56]\tvalid_0's l1: 0.165479\tvalid_0's l2: 0.0506088\n",
      "[57]\tvalid_0's l1: 0.165638\tvalid_0's l2: 0.0507106\n",
      "[58]\tvalid_0's l1: 0.165844\tvalid_0's l2: 0.0507764\n",
      "[59]\tvalid_0's l1: 0.166022\tvalid_0's l2: 0.0508919\n",
      "[60]\tvalid_0's l1: 0.166188\tvalid_0's l2: 0.0509772\n",
      "[61]\tvalid_0's l1: 0.166176\tvalid_0's l2: 0.0509496\n",
      "[62]\tvalid_0's l1: 0.166252\tvalid_0's l2: 0.0509787\n",
      "[63]\tvalid_0's l1: 0.166255\tvalid_0's l2: 0.0509525\n",
      "[64]\tvalid_0's l1: 0.166384\tvalid_0's l2: 0.0509842\n",
      "[65]\tvalid_0's l1: 0.166473\tvalid_0's l2: 0.0509613\n",
      "[66]\tvalid_0's l1: 0.166371\tvalid_0's l2: 0.0508573\n",
      "[67]\tvalid_0's l1: 0.166341\tvalid_0's l2: 0.050819\n",
      "[68]\tvalid_0's l1: 0.166418\tvalid_0's l2: 0.0508633\n",
      "[69]\tvalid_0's l1: 0.166724\tvalid_0's l2: 0.0510916\n",
      "[70]\tvalid_0's l1: 0.166728\tvalid_0's l2: 0.0510878\n",
      "[71]\tvalid_0's l1: 0.166727\tvalid_0's l2: 0.0510846\n",
      "[72]\tvalid_0's l1: 0.166814\tvalid_0's l2: 0.0510378\n",
      "[73]\tvalid_0's l1: 0.166786\tvalid_0's l2: 0.0510461\n",
      "[74]\tvalid_0's l1: 0.166879\tvalid_0's l2: 0.0511211\n",
      "[75]\tvalid_0's l1: 0.1669\tvalid_0's l2: 0.0511266\n",
      "[76]\tvalid_0's l1: 0.167203\tvalid_0's l2: 0.0513403\n",
      "[77]\tvalid_0's l1: 0.167234\tvalid_0's l2: 0.0513175\n",
      "[78]\tvalid_0's l1: 0.166988\tvalid_0's l2: 0.051159\n",
      "[79]\tvalid_0's l1: 0.166988\tvalid_0's l2: 0.0511557\n",
      "[80]\tvalid_0's l1: 0.167328\tvalid_0's l2: 0.0514102\n",
      "[81]\tvalid_0's l1: 0.16747\tvalid_0's l2: 0.0514915\n",
      "[82]\tvalid_0's l1: 0.16747\tvalid_0's l2: 0.0514894\n",
      "[83]\tvalid_0's l1: 0.167477\tvalid_0's l2: 0.0514282\n",
      "[84]\tvalid_0's l1: 0.167337\tvalid_0's l2: 0.0513247\n",
      "[85]\tvalid_0's l1: 0.167342\tvalid_0's l2: 0.0513106\n",
      "[86]\tvalid_0's l1: 0.167305\tvalid_0's l2: 0.0513071\n",
      "[87]\tvalid_0's l1: 0.167297\tvalid_0's l2: 0.051317\n",
      "[88]\tvalid_0's l1: 0.167454\tvalid_0's l2: 0.0513523\n",
      "[89]\tvalid_0's l1: 0.167551\tvalid_0's l2: 0.0513689\n",
      "[90]\tvalid_0's l1: 0.167581\tvalid_0's l2: 0.051326\n",
      "[91]\tvalid_0's l1: 0.167581\tvalid_0's l2: 0.0513248\n",
      "[92]\tvalid_0's l1: 0.167524\tvalid_0's l2: 0.0513039\n",
      "[93]\tvalid_0's l1: 0.167526\tvalid_0's l2: 0.0512928\n",
      "[94]\tvalid_0's l1: 0.167529\tvalid_0's l2: 0.0512899\n",
      "[95]\tvalid_0's l1: 0.167657\tvalid_0's l2: 0.0514842\n",
      "[96]\tvalid_0's l1: 0.167623\tvalid_0's l2: 0.0514451\n",
      "[97]\tvalid_0's l1: 0.1676\tvalid_0's l2: 0.0514375\n",
      "[98]\tvalid_0's l1: 0.1676\tvalid_0's l2: 0.0514365\n",
      "[99]\tvalid_0's l1: 0.167633\tvalid_0's l2: 0.0514193\n",
      "[100]\tvalid_0's l1: 0.167667\tvalid_0's l2: 0.0514319\n",
      "[LightGBM] [Warning] Unknown parameter: learnnig_rage\n",
      "[1]\tvalid_0's l1: 0.743024\tvalid_0's l2: 0.898582\n",
      "[2]\tvalid_0's l1: 0.682703\tvalid_0's l2: 0.765401\n",
      "[3]\tvalid_0's l1: 0.626523\tvalid_0's l2: 0.651108\n",
      "[4]\tvalid_0's l1: 0.577948\tvalid_0's l2: 0.558453\n",
      "[5]\tvalid_0's l1: 0.533608\tvalid_0's l2: 0.481695\n",
      "[6]\tvalid_0's l1: 0.494199\tvalid_0's l2: 0.41821\n",
      "[7]\tvalid_0's l1: 0.459395\tvalid_0's l2: 0.367108\n",
      "[8]\tvalid_0's l1: 0.430053\tvalid_0's l2: 0.326108\n",
      "[9]\tvalid_0's l1: 0.4025\tvalid_0's l2: 0.290048\n",
      "[10]\tvalid_0's l1: 0.379171\tvalid_0's l2: 0.261614\n",
      "[11]\tvalid_0's l1: 0.358431\tvalid_0's l2: 0.238038\n",
      "[12]\tvalid_0's l1: 0.341003\tvalid_0's l2: 0.218071\n",
      "[13]\tvalid_0's l1: 0.325053\tvalid_0's l2: 0.20126\n",
      "[14]\tvalid_0's l1: 0.311007\tvalid_0's l2: 0.18676\n",
      "[15]\tvalid_0's l1: 0.299174\tvalid_0's l2: 0.174811\n",
      "[16]\tvalid_0's l1: 0.288641\tvalid_0's l2: 0.164963\n",
      "[17]\tvalid_0's l1: 0.27928\tvalid_0's l2: 0.156604\n",
      "[18]\tvalid_0's l1: 0.271928\tvalid_0's l2: 0.150264\n",
      "[19]\tvalid_0's l1: 0.264712\tvalid_0's l2: 0.144161\n",
      "[20]\tvalid_0's l1: 0.259114\tvalid_0's l2: 0.139316\n",
      "[21]\tvalid_0's l1: 0.25327\tvalid_0's l2: 0.134687\n",
      "[22]\tvalid_0's l1: 0.249114\tvalid_0's l2: 0.131258\n",
      "[23]\tvalid_0's l1: 0.245498\tvalid_0's l2: 0.128307\n",
      "[24]\tvalid_0's l1: 0.238409\tvalid_0's l2: 0.121293\n",
      "[25]\tvalid_0's l1: 0.234583\tvalid_0's l2: 0.11794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:179: UserWarning: Converting column-vector to 1d array\n",
      "  _log_warning('Converting column-vector to 1d array')\n",
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:179: UserWarning: Converting column-vector to 1d array\n",
      "  _log_warning('Converting column-vector to 1d array')\n",
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:179: UserWarning: Converting column-vector to 1d array\n",
      "  _log_warning('Converting column-vector to 1d array')\n",
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:179: UserWarning: Converting column-vector to 1d array\n",
      "  _log_warning('Converting column-vector to 1d array')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26]\tvalid_0's l1: 0.231763\tvalid_0's l2: 0.116122\n",
      "[27]\tvalid_0's l1: 0.229649\tvalid_0's l2: 0.114944\n",
      "[28]\tvalid_0's l1: 0.227764\tvalid_0's l2: 0.113828\n",
      "[29]\tvalid_0's l1: 0.225708\tvalid_0's l2: 0.112201\n",
      "[30]\tvalid_0's l1: 0.222743\tvalid_0's l2: 0.109872\n",
      "[31]\tvalid_0's l1: 0.221322\tvalid_0's l2: 0.109032\n",
      "[32]\tvalid_0's l1: 0.220211\tvalid_0's l2: 0.108431\n",
      "[33]\tvalid_0's l1: 0.218749\tvalid_0's l2: 0.107386\n",
      "[34]\tvalid_0's l1: 0.217138\tvalid_0's l2: 0.106283\n",
      "[35]\tvalid_0's l1: 0.215607\tvalid_0's l2: 0.10456\n",
      "[36]\tvalid_0's l1: 0.21558\tvalid_0's l2: 0.104615\n",
      "[37]\tvalid_0's l1: 0.216622\tvalid_0's l2: 0.106145\n",
      "[38]\tvalid_0's l1: 0.215819\tvalid_0's l2: 0.105719\n",
      "[39]\tvalid_0's l1: 0.215605\tvalid_0's l2: 0.105744\n",
      "[40]\tvalid_0's l1: 0.214986\tvalid_0's l2: 0.105327\n",
      "[41]\tvalid_0's l1: 0.216786\tvalid_0's l2: 0.107417\n",
      "[42]\tvalid_0's l1: 0.216085\tvalid_0's l2: 0.107082\n",
      "[43]\tvalid_0's l1: 0.216018\tvalid_0's l2: 0.10737\n",
      "[44]\tvalid_0's l1: 0.21709\tvalid_0's l2: 0.108667\n",
      "[45]\tvalid_0's l1: 0.216683\tvalid_0's l2: 0.108387\n",
      "[46]\tvalid_0's l1: 0.216596\tvalid_0's l2: 0.108376\n",
      "[47]\tvalid_0's l1: 0.216327\tvalid_0's l2: 0.108194\n",
      "[48]\tvalid_0's l1: 0.216947\tvalid_0's l2: 0.108543\n",
      "[49]\tvalid_0's l1: 0.216738\tvalid_0's l2: 0.108127\n",
      "[50]\tvalid_0's l1: 0.216729\tvalid_0's l2: 0.108043\n",
      "[51]\tvalid_0's l1: 0.216702\tvalid_0's l2: 0.107963\n",
      "[52]\tvalid_0's l1: 0.217417\tvalid_0's l2: 0.108711\n",
      "[53]\tvalid_0's l1: 0.217531\tvalid_0's l2: 0.108808\n",
      "[54]\tvalid_0's l1: 0.217629\tvalid_0's l2: 0.108902\n",
      "[55]\tvalid_0's l1: 0.217595\tvalid_0's l2: 0.109085\n",
      "[56]\tvalid_0's l1: 0.217626\tvalid_0's l2: 0.109049\n",
      "[57]\tvalid_0's l1: 0.217459\tvalid_0's l2: 0.108888\n",
      "[58]\tvalid_0's l1: 0.2194\tvalid_0's l2: 0.111499\n",
      "[59]\tvalid_0's l1: 0.219293\tvalid_0's l2: 0.111436\n",
      "[60]\tvalid_0's l1: 0.219383\tvalid_0's l2: 0.111587\n",
      "[61]\tvalid_0's l1: 0.219399\tvalid_0's l2: 0.111732\n",
      "[62]\tvalid_0's l1: 0.219299\tvalid_0's l2: 0.111675\n",
      "[63]\tvalid_0's l1: 0.219176\tvalid_0's l2: 0.111594\n",
      "[64]\tvalid_0's l1: 0.219359\tvalid_0's l2: 0.111697\n",
      "[65]\tvalid_0's l1: 0.219373\tvalid_0's l2: 0.111748\n",
      "[66]\tvalid_0's l1: 0.219294\tvalid_0's l2: 0.111743\n",
      "[67]\tvalid_0's l1: 0.219912\tvalid_0's l2: 0.112461\n",
      "[68]\tvalid_0's l1: 0.219814\tvalid_0's l2: 0.112432\n",
      "[69]\tvalid_0's l1: 0.220182\tvalid_0's l2: 0.112737\n",
      "[70]\tvalid_0's l1: 0.220153\tvalid_0's l2: 0.112729\n",
      "[71]\tvalid_0's l1: 0.221572\tvalid_0's l2: 0.114343\n",
      "[72]\tvalid_0's l1: 0.221524\tvalid_0's l2: 0.114202\n",
      "[73]\tvalid_0's l1: 0.221382\tvalid_0's l2: 0.114222\n",
      "[74]\tvalid_0's l1: 0.221217\tvalid_0's l2: 0.114143\n",
      "[75]\tvalid_0's l1: 0.221191\tvalid_0's l2: 0.114135\n",
      "[76]\tvalid_0's l1: 0.2225\tvalid_0's l2: 0.115559\n",
      "[77]\tvalid_0's l1: 0.22277\tvalid_0's l2: 0.115767\n",
      "[78]\tvalid_0's l1: 0.222893\tvalid_0's l2: 0.115886\n",
      "[79]\tvalid_0's l1: 0.224793\tvalid_0's l2: 0.118164\n",
      "[80]\tvalid_0's l1: 0.225078\tvalid_0's l2: 0.118383\n",
      "[81]\tvalid_0's l1: 0.225094\tvalid_0's l2: 0.118431\n",
      "[82]\tvalid_0's l1: 0.22598\tvalid_0's l2: 0.119853\n",
      "[83]\tvalid_0's l1: 0.226218\tvalid_0's l2: 0.120042\n",
      "[84]\tvalid_0's l1: 0.22605\tvalid_0's l2: 0.119905\n",
      "[85]\tvalid_0's l1: 0.226988\tvalid_0's l2: 0.121115\n",
      "[86]\tvalid_0's l1: 0.226891\tvalid_0's l2: 0.12109\n",
      "[87]\tvalid_0's l1: 0.226951\tvalid_0's l2: 0.121104\n",
      "[88]\tvalid_0's l1: 0.22696\tvalid_0's l2: 0.121098\n",
      "[89]\tvalid_0's l1: 0.227033\tvalid_0's l2: 0.121261\n",
      "[90]\tvalid_0's l1: 0.227218\tvalid_0's l2: 0.121308\n",
      "[91]\tvalid_0's l1: 0.227569\tvalid_0's l2: 0.121889\n",
      "[92]\tvalid_0's l1: 0.227582\tvalid_0's l2: 0.121889\n",
      "[93]\tvalid_0's l1: 0.228391\tvalid_0's l2: 0.122886\n",
      "[94]\tvalid_0's l1: 0.22837\tvalid_0's l2: 0.122877\n",
      "[95]\tvalid_0's l1: 0.228529\tvalid_0's l2: 0.123001\n",
      "[96]\tvalid_0's l1: 0.228718\tvalid_0's l2: 0.123101\n",
      "[97]\tvalid_0's l1: 0.228662\tvalid_0's l2: 0.123085\n",
      "[98]\tvalid_0's l1: 0.230728\tvalid_0's l2: 0.125476\n",
      "[99]\tvalid_0's l1: 0.230859\tvalid_0's l2: 0.125569\n",
      "[100]\tvalid_0's l1: 0.230836\tvalid_0's l2: 0.12556\n",
      "[LightGBM] [Warning] Unknown parameter: learnnig_rage\n",
      "[1]\tvalid_0's l1: 0.743101\tvalid_0's l2: 0.897581\n",
      "[2]\tvalid_0's l1: 0.68497\tvalid_0's l2: 0.771054\n",
      "[3]\tvalid_0's l1: 0.632245\tvalid_0's l2: 0.666487\n",
      "[4]\tvalid_0's l1: 0.585247\tvalid_0's l2: 0.580295\n",
      "[5]\tvalid_0's l1: 0.541542\tvalid_0's l2: 0.506882\n",
      "[6]\tvalid_0's l1: 0.503981\tvalid_0's l2: 0.448703\n",
      "[7]\tvalid_0's l1: 0.470027\tvalid_0's l2: 0.398781\n",
      "[8]\tvalid_0's l1: 0.443005\tvalid_0's l2: 0.360976\n",
      "[9]\tvalid_0's l1: 0.418485\tvalid_0's l2: 0.328054\n",
      "[10]\tvalid_0's l1: 0.396915\tvalid_0's l2: 0.299945\n",
      "[11]\tvalid_0's l1: 0.377927\tvalid_0's l2: 0.277034\n",
      "[12]\tvalid_0's l1: 0.361817\tvalid_0's l2: 0.257307\n",
      "[13]\tvalid_0's l1: 0.347805\tvalid_0's l2: 0.24116\n",
      "[14]\tvalid_0's l1: 0.33569\tvalid_0's l2: 0.226953\n",
      "[15]\tvalid_0's l1: 0.32483\tvalid_0's l2: 0.214916\n",
      "[16]\tvalid_0's l1: 0.315913\tvalid_0's l2: 0.205291\n",
      "[17]\tvalid_0's l1: 0.30809\tvalid_0's l2: 0.196752\n",
      "[18]\tvalid_0's l1: 0.301346\tvalid_0's l2: 0.189799\n",
      "[19]\tvalid_0's l1: 0.295331\tvalid_0's l2: 0.183861\n",
      "[20]\tvalid_0's l1: 0.290008\tvalid_0's l2: 0.178599\n",
      "[21]\tvalid_0's l1: 0.285751\tvalid_0's l2: 0.174496\n",
      "[22]\tvalid_0's l1: 0.281974\tvalid_0's l2: 0.170808\n",
      "[23]\tvalid_0's l1: 0.278681\tvalid_0's l2: 0.168005\n",
      "[24]\tvalid_0's l1: 0.275434\tvalid_0's l2: 0.164917\n",
      "[25]\tvalid_0's l1: 0.272993\tvalid_0's l2: 0.163065\n",
      "[26]\tvalid_0's l1: 0.27077\tvalid_0's l2: 0.161319\n",
      "[27]\tvalid_0's l1: 0.268774\tvalid_0's l2: 0.159686\n",
      "[28]\tvalid_0's l1: 0.266099\tvalid_0's l2: 0.157447\n",
      "[29]\tvalid_0's l1: 0.26444\tvalid_0's l2: 0.156144\n",
      "[30]\tvalid_0's l1: 0.262922\tvalid_0's l2: 0.15443\n",
      "[31]\tvalid_0's l1: 0.261281\tvalid_0's l2: 0.15279\n",
      "[32]\tvalid_0's l1: 0.260048\tvalid_0's l2: 0.151486\n",
      "[33]\tvalid_0's l1: 0.258954\tvalid_0's l2: 0.150476\n",
      "[34]\tvalid_0's l1: 0.257687\tvalid_0's l2: 0.149377\n",
      "[35]\tvalid_0's l1: 0.256537\tvalid_0's l2: 0.148523\n",
      "[36]\tvalid_0's l1: 0.255763\tvalid_0's l2: 0.147923\n",
      "[37]\tvalid_0's l1: 0.255111\tvalid_0's l2: 0.147394\n",
      "[38]\tvalid_0's l1: 0.254041\tvalid_0's l2: 0.146156\n",
      "[39]\tvalid_0's l1: 0.252967\tvalid_0's l2: 0.145345\n",
      "[40]\tvalid_0's l1: 0.251838\tvalid_0's l2: 0.144214\n",
      "[41]\tvalid_0's l1: 0.251509\tvalid_0's l2: 0.143934\n",
      "[42]\tvalid_0's l1: 0.251317\tvalid_0's l2: 0.143849\n",
      "[43]\tvalid_0's l1: 0.250982\tvalid_0's l2: 0.14355\n",
      "[44]\tvalid_0's l1: 0.250536\tvalid_0's l2: 0.143145\n",
      "[45]\tvalid_0's l1: 0.249851\tvalid_0's l2: 0.142382\n",
      "[46]\tvalid_0's l1: 0.250027\tvalid_0's l2: 0.142548\n",
      "[47]\tvalid_0's l1: 0.249532\tvalid_0's l2: 0.141957\n",
      "[48]\tvalid_0's l1: 0.24912\tvalid_0's l2: 0.141723\n",
      "[49]\tvalid_0's l1: 0.248769\tvalid_0's l2: 0.141283\n",
      "[50]\tvalid_0's l1: 0.24866\tvalid_0's l2: 0.141262\n",
      "[51]\tvalid_0's l1: 0.24795\tvalid_0's l2: 0.140618\n",
      "[52]\tvalid_0's l1: 0.24772\tvalid_0's l2: 0.140281\n",
      "[53]\tvalid_0's l1: 0.247669\tvalid_0's l2: 0.140292\n",
      "[54]\tvalid_0's l1: 0.247316\tvalid_0's l2: 0.140061\n",
      "[55]\tvalid_0's l1: 0.247218\tvalid_0's l2: 0.140057\n",
      "[56]\tvalid_0's l1: 0.246683\tvalid_0's l2: 0.139495\n",
      "[57]\tvalid_0's l1: 0.246582\tvalid_0's l2: 0.139299\n",
      "[58]\tvalid_0's l1: 0.24659\tvalid_0's l2: 0.139386\n",
      "[59]\tvalid_0's l1: 0.246293\tvalid_0's l2: 0.138969\n",
      "[60]\tvalid_0's l1: 0.246177\tvalid_0's l2: 0.138857\n",
      "[61]\tvalid_0's l1: 0.24612\tvalid_0's l2: 0.138873\n",
      "[62]\tvalid_0's l1: 0.245951\tvalid_0's l2: 0.138683\n",
      "[63]\tvalid_0's l1: 0.245821\tvalid_0's l2: 0.138655\n",
      "[64]\tvalid_0's l1: 0.245391\tvalid_0's l2: 0.138372\n",
      "[65]\tvalid_0's l1: 0.245294\tvalid_0's l2: 0.138355\n",
      "[66]\tvalid_0's l1: 0.24521\tvalid_0's l2: 0.138378\n",
      "[67]\tvalid_0's l1: 0.245208\tvalid_0's l2: 0.138398\n",
      "[68]\tvalid_0's l1: 0.245102\tvalid_0's l2: 0.138203\n",
      "[69]\tvalid_0's l1: 0.244626\tvalid_0's l2: 0.137849\n",
      "[70]\tvalid_0's l1: 0.24461\tvalid_0's l2: 0.137854\n",
      "[71]\tvalid_0's l1: 0.244603\tvalid_0's l2: 0.137857\n",
      "[72]\tvalid_0's l1: 0.244226\tvalid_0's l2: 0.137601\n",
      "[73]\tvalid_0's l1: 0.244104\tvalid_0's l2: 0.13756\n",
      "[74]\tvalid_0's l1: 0.244015\tvalid_0's l2: 0.137369\n",
      "[75]\tvalid_0's l1: 0.244\tvalid_0's l2: 0.137374\n",
      "[76]\tvalid_0's l1: 0.243615\tvalid_0's l2: 0.137087\n",
      "[77]\tvalid_0's l1: 0.243598\tvalid_0's l2: 0.137116\n",
      "[78]\tvalid_0's l1: 0.243583\tvalid_0's l2: 0.137158\n",
      "[79]\tvalid_0's l1: 0.243576\tvalid_0's l2: 0.137161\n",
      "[80]\tvalid_0's l1: 0.243164\tvalid_0's l2: 0.1368\n",
      "[81]\tvalid_0's l1: 0.242942\tvalid_0's l2: 0.136633\n",
      "[82]\tvalid_0's l1: 0.242937\tvalid_0's l2: 0.136635\n",
      "[83]\tvalid_0's l1: 0.242756\tvalid_0's l2: 0.136599\n",
      "[84]\tvalid_0's l1: 0.24287\tvalid_0's l2: 0.136786\n",
      "[85]\tvalid_0's l1: 0.242828\tvalid_0's l2: 0.136788\n",
      "[86]\tvalid_0's l1: 0.242768\tvalid_0's l2: 0.136652\n",
      "[87]\tvalid_0's l1: 0.242797\tvalid_0's l2: 0.13664\n",
      "[88]\tvalid_0's l1: 0.242682\tvalid_0's l2: 0.136642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:179: UserWarning: Converting column-vector to 1d array\n",
      "  _log_warning('Converting column-vector to 1d array')\n",
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:179: UserWarning: Converting column-vector to 1d array\n",
      "  _log_warning('Converting column-vector to 1d array')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[89]\tvalid_0's l1: 0.242689\tvalid_0's l2: 0.136698\n",
      "[90]\tvalid_0's l1: 0.242564\tvalid_0's l2: 0.136687\n",
      "[91]\tvalid_0's l1: 0.242561\tvalid_0's l2: 0.136688\n",
      "[92]\tvalid_0's l1: 0.242594\tvalid_0's l2: 0.136701\n",
      "[93]\tvalid_0's l1: 0.242568\tvalid_0's l2: 0.136712\n",
      "[94]\tvalid_0's l1: 0.242558\tvalid_0's l2: 0.136716\n",
      "[95]\tvalid_0's l1: 0.242615\tvalid_0's l2: 0.13686\n",
      "[96]\tvalid_0's l1: 0.242581\tvalid_0's l2: 0.136881\n",
      "[97]\tvalid_0's l1: 0.242545\tvalid_0's l2: 0.136804\n",
      "[98]\tvalid_0's l1: 0.242543\tvalid_0's l2: 0.136805\n",
      "[99]\tvalid_0's l1: 0.242473\tvalid_0's l2: 0.13676\n",
      "[100]\tvalid_0's l1: 0.242478\tvalid_0's l2: 0.136778\n",
      "[LightGBM] [Warning] Unknown parameter: learnnig_rage\n",
      "[1]\tvalid_0's l1: 0.624498\tvalid_0's l2: 0.661976\n",
      "[2]\tvalid_0's l1: 0.557234\tvalid_0's l2: 0.538172\n",
      "[3]\tvalid_0's l1: 0.499329\tvalid_0's l2: 0.441484\n",
      "[4]\tvalid_0's l1: 0.451058\tvalid_0's l2: 0.365043\n",
      "[5]\tvalid_0's l1: 0.410165\tvalid_0's l2: 0.304516\n",
      "[6]\tvalid_0's l1: 0.377003\tvalid_0's l2: 0.258641\n",
      "[7]\tvalid_0's l1: 0.349958\tvalid_0's l2: 0.223052\n",
      "[8]\tvalid_0's l1: 0.326624\tvalid_0's l2: 0.195029\n",
      "[9]\tvalid_0's l1: 0.306497\tvalid_0's l2: 0.172227\n",
      "[10]\tvalid_0's l1: 0.290014\tvalid_0's l2: 0.154864\n",
      "[11]\tvalid_0's l1: 0.27745\tvalid_0's l2: 0.141098\n",
      "[12]\tvalid_0's l1: 0.267308\tvalid_0's l2: 0.131634\n",
      "[13]\tvalid_0's l1: 0.260167\tvalid_0's l2: 0.124629\n",
      "[14]\tvalid_0's l1: 0.255299\tvalid_0's l2: 0.119615\n",
      "[15]\tvalid_0's l1: 0.250533\tvalid_0's l2: 0.114563\n",
      "[16]\tvalid_0's l1: 0.246926\tvalid_0's l2: 0.110782\n",
      "[17]\tvalid_0's l1: 0.245393\tvalid_0's l2: 0.108804\n",
      "[18]\tvalid_0's l1: 0.244046\tvalid_0's l2: 0.107662\n",
      "[19]\tvalid_0's l1: 0.243181\tvalid_0's l2: 0.106657\n",
      "[20]\tvalid_0's l1: 0.243181\tvalid_0's l2: 0.106431\n",
      "[21]\tvalid_0's l1: 0.242773\tvalid_0's l2: 0.106117\n",
      "[22]\tvalid_0's l1: 0.242013\tvalid_0's l2: 0.105366\n",
      "[23]\tvalid_0's l1: 0.242171\tvalid_0's l2: 0.105383\n",
      "[24]\tvalid_0's l1: 0.241549\tvalid_0's l2: 0.104995\n",
      "[25]\tvalid_0's l1: 0.241333\tvalid_0's l2: 0.104938\n",
      "[26]\tvalid_0's l1: 0.240859\tvalid_0's l2: 0.104843\n",
      "[27]\tvalid_0's l1: 0.241404\tvalid_0's l2: 0.105064\n",
      "[28]\tvalid_0's l1: 0.241877\tvalid_0's l2: 0.105462\n",
      "[29]\tvalid_0's l1: 0.24289\tvalid_0's l2: 0.106402\n",
      "[30]\tvalid_0's l1: 0.243757\tvalid_0's l2: 0.107145\n",
      "[31]\tvalid_0's l1: 0.244006\tvalid_0's l2: 0.107481\n",
      "[32]\tvalid_0's l1: 0.244475\tvalid_0's l2: 0.10817\n",
      "[33]\tvalid_0's l1: 0.245544\tvalid_0's l2: 0.108995\n",
      "[34]\tvalid_0's l1: 0.246052\tvalid_0's l2: 0.109342\n",
      "[35]\tvalid_0's l1: 0.24694\tvalid_0's l2: 0.110105\n",
      "[36]\tvalid_0's l1: 0.247645\tvalid_0's l2: 0.110697\n",
      "[37]\tvalid_0's l1: 0.248401\tvalid_0's l2: 0.111132\n",
      "[38]\tvalid_0's l1: 0.248245\tvalid_0's l2: 0.111229\n",
      "[39]\tvalid_0's l1: 0.248769\tvalid_0's l2: 0.111784\n",
      "[40]\tvalid_0's l1: 0.249435\tvalid_0's l2: 0.112091\n",
      "[41]\tvalid_0's l1: 0.249212\tvalid_0's l2: 0.112015\n",
      "[42]\tvalid_0's l1: 0.249938\tvalid_0's l2: 0.112645\n",
      "[43]\tvalid_0's l1: 0.25057\tvalid_0's l2: 0.1128\n",
      "[44]\tvalid_0's l1: 0.250662\tvalid_0's l2: 0.112951\n",
      "[45]\tvalid_0's l1: 0.251448\tvalid_0's l2: 0.113419\n",
      "[46]\tvalid_0's l1: 0.251449\tvalid_0's l2: 0.113544\n",
      "[47]\tvalid_0's l1: 0.252289\tvalid_0's l2: 0.114219\n",
      "[48]\tvalid_0's l1: 0.25314\tvalid_0's l2: 0.114776\n",
      "[49]\tvalid_0's l1: 0.253151\tvalid_0's l2: 0.114879\n",
      "[50]\tvalid_0's l1: 0.25351\tvalid_0's l2: 0.115031\n",
      "[51]\tvalid_0's l1: 0.253761\tvalid_0's l2: 0.115239\n",
      "[52]\tvalid_0's l1: 0.253788\tvalid_0's l2: 0.115265\n",
      "[53]\tvalid_0's l1: 0.253833\tvalid_0's l2: 0.115386\n",
      "[54]\tvalid_0's l1: 0.253777\tvalid_0's l2: 0.115435\n",
      "[55]\tvalid_0's l1: 0.254183\tvalid_0's l2: 0.115734\n",
      "[56]\tvalid_0's l1: 0.254554\tvalid_0's l2: 0.115996\n",
      "[57]\tvalid_0's l1: 0.25446\tvalid_0's l2: 0.115986\n",
      "[58]\tvalid_0's l1: 0.25492\tvalid_0's l2: 0.116353\n",
      "[59]\tvalid_0's l1: 0.255057\tvalid_0's l2: 0.116468\n",
      "[60]\tvalid_0's l1: 0.254868\tvalid_0's l2: 0.116387\n",
      "[61]\tvalid_0's l1: 0.254783\tvalid_0's l2: 0.116433\n",
      "[62]\tvalid_0's l1: 0.25477\tvalid_0's l2: 0.11646\n",
      "[63]\tvalid_0's l1: 0.254723\tvalid_0's l2: 0.116312\n",
      "[64]\tvalid_0's l1: 0.254767\tvalid_0's l2: 0.116404\n",
      "[65]\tvalid_0's l1: 0.255244\tvalid_0's l2: 0.116828\n",
      "[66]\tvalid_0's l1: 0.255157\tvalid_0's l2: 0.116658\n",
      "[67]\tvalid_0's l1: 0.255913\tvalid_0's l2: 0.117211\n",
      "[68]\tvalid_0's l1: 0.256274\tvalid_0's l2: 0.117297\n",
      "[69]\tvalid_0's l1: 0.256018\tvalid_0's l2: 0.117059\n",
      "[70]\tvalid_0's l1: 0.256189\tvalid_0's l2: 0.117119\n",
      "[71]\tvalid_0's l1: 0.256254\tvalid_0's l2: 0.117112\n",
      "[72]\tvalid_0's l1: 0.25633\tvalid_0's l2: 0.117143\n",
      "[73]\tvalid_0's l1: 0.256492\tvalid_0's l2: 0.117289\n",
      "[74]\tvalid_0's l1: 0.25675\tvalid_0's l2: 0.117459\n",
      "[75]\tvalid_0's l1: 0.256818\tvalid_0's l2: 0.117489\n",
      "[76]\tvalid_0's l1: 0.25645\tvalid_0's l2: 0.117167\n",
      "[77]\tvalid_0's l1: 0.256427\tvalid_0's l2: 0.117141\n",
      "[78]\tvalid_0's l1: 0.256201\tvalid_0's l2: 0.116783\n",
      "[79]\tvalid_0's l1: 0.255919\tvalid_0's l2: 0.116476\n",
      "[80]\tvalid_0's l1: 0.256229\tvalid_0's l2: 0.116759\n",
      "[81]\tvalid_0's l1: 0.255958\tvalid_0's l2: 0.116555\n",
      "[82]\tvalid_0's l1: 0.255876\tvalid_0's l2: 0.116482\n",
      "[83]\tvalid_0's l1: 0.255524\tvalid_0's l2: 0.116116\n",
      "[84]\tvalid_0's l1: 0.255259\tvalid_0's l2: 0.115981\n",
      "[85]\tvalid_0's l1: 0.255262\tvalid_0's l2: 0.116009\n",
      "[86]\tvalid_0's l1: 0.255275\tvalid_0's l2: 0.116021\n",
      "[87]\tvalid_0's l1: 0.25512\tvalid_0's l2: 0.115858\n",
      "[88]\tvalid_0's l1: 0.255071\tvalid_0's l2: 0.115829\n",
      "[89]\tvalid_0's l1: 0.254971\tvalid_0's l2: 0.115774\n",
      "[90]\tvalid_0's l1: 0.254491\tvalid_0's l2: 0.1155\n",
      "[91]\tvalid_0's l1: 0.254383\tvalid_0's l2: 0.115426\n",
      "[92]\tvalid_0's l1: 0.254609\tvalid_0's l2: 0.11566\n",
      "[93]\tvalid_0's l1: 0.254542\tvalid_0's l2: 0.11566\n",
      "[94]\tvalid_0's l1: 0.25448\tvalid_0's l2: 0.115634\n",
      "[95]\tvalid_0's l1: 0.254528\tvalid_0's l2: 0.115672\n",
      "[96]\tvalid_0's l1: 0.254499\tvalid_0's l2: 0.115656\n",
      "[97]\tvalid_0's l1: 0.254049\tvalid_0's l2: 0.115387\n",
      "[98]\tvalid_0's l1: 0.253874\tvalid_0's l2: 0.115255\n",
      "[99]\tvalid_0's l1: 0.253896\tvalid_0's l2: 0.115276\n",
      "[100]\tvalid_0's l1: 0.253944\tvalid_0's l2: 0.115296\n",
      "[LightGBM] [Warning] Unknown parameter: learnnig_rage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:179: UserWarning: Converting column-vector to 1d array\n",
      "  _log_warning('Converting column-vector to 1d array')\n",
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:179: UserWarning: Converting column-vector to 1d array\n",
      "  _log_warning('Converting column-vector to 1d array')\n",
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:179: UserWarning: Converting column-vector to 1d array\n",
      "  _log_warning('Converting column-vector to 1d array')\n",
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:179: UserWarning: Converting column-vector to 1d array\n",
      "  _log_warning('Converting column-vector to 1d array')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l1: 0.770946\tvalid_0's l2: 0.845893\n",
      "[2]\tvalid_0's l1: 0.700474\tvalid_0's l2: 0.708292\n",
      "[3]\tvalid_0's l1: 0.638377\tvalid_0's l2: 0.599015\n",
      "[4]\tvalid_0's l1: 0.58006\tvalid_0's l2: 0.506139\n",
      "[5]\tvalid_0's l1: 0.526337\tvalid_0's l2: 0.430114\n",
      "[6]\tvalid_0's l1: 0.481069\tvalid_0's l2: 0.37063\n",
      "[7]\tvalid_0's l1: 0.438643\tvalid_0's l2: 0.321092\n",
      "[8]\tvalid_0's l1: 0.402074\tvalid_0's l2: 0.281341\n",
      "[9]\tvalid_0's l1: 0.372208\tvalid_0's l2: 0.249349\n",
      "[10]\tvalid_0's l1: 0.34661\tvalid_0's l2: 0.223966\n",
      "[11]\tvalid_0's l1: 0.323701\tvalid_0's l2: 0.202025\n",
      "[12]\tvalid_0's l1: 0.306762\tvalid_0's l2: 0.185892\n",
      "[13]\tvalid_0's l1: 0.294206\tvalid_0's l2: 0.17332\n",
      "[14]\tvalid_0's l1: 0.283847\tvalid_0's l2: 0.162629\n",
      "[15]\tvalid_0's l1: 0.274904\tvalid_0's l2: 0.153824\n",
      "[16]\tvalid_0's l1: 0.266864\tvalid_0's l2: 0.146535\n",
      "[17]\tvalid_0's l1: 0.260381\tvalid_0's l2: 0.140729\n",
      "[18]\tvalid_0's l1: 0.256607\tvalid_0's l2: 0.136897\n",
      "[19]\tvalid_0's l1: 0.253991\tvalid_0's l2: 0.134725\n",
      "[20]\tvalid_0's l1: 0.250847\tvalid_0's l2: 0.131731\n",
      "[21]\tvalid_0's l1: 0.249147\tvalid_0's l2: 0.130301\n",
      "[22]\tvalid_0's l1: 0.248365\tvalid_0's l2: 0.129074\n",
      "[23]\tvalid_0's l1: 0.247911\tvalid_0's l2: 0.128252\n",
      "[24]\tvalid_0's l1: 0.24803\tvalid_0's l2: 0.127816\n",
      "[25]\tvalid_0's l1: 0.247975\tvalid_0's l2: 0.127581\n",
      "[26]\tvalid_0's l1: 0.24826\tvalid_0's l2: 0.12763\n",
      "[27]\tvalid_0's l1: 0.248435\tvalid_0's l2: 0.12749\n",
      "[28]\tvalid_0's l1: 0.248902\tvalid_0's l2: 0.127424\n",
      "[29]\tvalid_0's l1: 0.250291\tvalid_0's l2: 0.128343\n",
      "[30]\tvalid_0's l1: 0.250613\tvalid_0's l2: 0.128153\n",
      "[31]\tvalid_0's l1: 0.251383\tvalid_0's l2: 0.128348\n",
      "[32]\tvalid_0's l1: 0.252527\tvalid_0's l2: 0.128896\n",
      "[33]\tvalid_0's l1: 0.253035\tvalid_0's l2: 0.128978\n",
      "[34]\tvalid_0's l1: 0.253597\tvalid_0's l2: 0.129586\n",
      "[35]\tvalid_0's l1: 0.255046\tvalid_0's l2: 0.130863\n",
      "[36]\tvalid_0's l1: 0.255725\tvalid_0's l2: 0.131297\n",
      "[37]\tvalid_0's l1: 0.256969\tvalid_0's l2: 0.132282\n",
      "[38]\tvalid_0's l1: 0.258759\tvalid_0's l2: 0.133696\n",
      "[39]\tvalid_0's l1: 0.259179\tvalid_0's l2: 0.133779\n",
      "[40]\tvalid_0's l1: 0.260348\tvalid_0's l2: 0.134764\n",
      "[41]\tvalid_0's l1: 0.261542\tvalid_0's l2: 0.13581\n",
      "[42]\tvalid_0's l1: 0.261617\tvalid_0's l2: 0.135775\n",
      "[43]\tvalid_0's l1: 0.262697\tvalid_0's l2: 0.136627\n",
      "[44]\tvalid_0's l1: 0.263272\tvalid_0's l2: 0.137016\n",
      "[45]\tvalid_0's l1: 0.263813\tvalid_0's l2: 0.137502\n",
      "[46]\tvalid_0's l1: 0.264243\tvalid_0's l2: 0.137955\n",
      "[47]\tvalid_0's l1: 0.264794\tvalid_0's l2: 0.138294\n",
      "[48]\tvalid_0's l1: 0.265714\tvalid_0's l2: 0.139012\n",
      "[49]\tvalid_0's l1: 0.266204\tvalid_0's l2: 0.139329\n",
      "[50]\tvalid_0's l1: 0.266425\tvalid_0's l2: 0.13951\n",
      "[51]\tvalid_0's l1: 0.266914\tvalid_0's l2: 0.139842\n",
      "[52]\tvalid_0's l1: 0.267284\tvalid_0's l2: 0.140464\n",
      "[53]\tvalid_0's l1: 0.267798\tvalid_0's l2: 0.140791\n",
      "[54]\tvalid_0's l1: 0.268104\tvalid_0's l2: 0.140922\n",
      "[55]\tvalid_0's l1: 0.268278\tvalid_0's l2: 0.141062\n",
      "[56]\tvalid_0's l1: 0.268591\tvalid_0's l2: 0.141213\n",
      "[57]\tvalid_0's l1: 0.26905\tvalid_0's l2: 0.141813\n",
      "[58]\tvalid_0's l1: 0.269205\tvalid_0's l2: 0.141877\n",
      "[59]\tvalid_0's l1: 0.269047\tvalid_0's l2: 0.141657\n",
      "[60]\tvalid_0's l1: 0.269418\tvalid_0's l2: 0.141875\n",
      "[61]\tvalid_0's l1: 0.269083\tvalid_0's l2: 0.141517\n",
      "[62]\tvalid_0's l1: 0.269489\tvalid_0's l2: 0.141683\n",
      "[63]\tvalid_0's l1: 0.269616\tvalid_0's l2: 0.141689\n",
      "[64]\tvalid_0's l1: 0.269927\tvalid_0's l2: 0.14192\n",
      "[65]\tvalid_0's l1: 0.270356\tvalid_0's l2: 0.142187\n",
      "[66]\tvalid_0's l1: 0.270095\tvalid_0's l2: 0.141854\n",
      "[67]\tvalid_0's l1: 0.270298\tvalid_0's l2: 0.141903\n",
      "[68]\tvalid_0's l1: 0.270697\tvalid_0's l2: 0.142176\n",
      "[69]\tvalid_0's l1: 0.270182\tvalid_0's l2: 0.141657\n",
      "[70]\tvalid_0's l1: 0.270295\tvalid_0's l2: 0.141759\n",
      "[71]\tvalid_0's l1: 0.270377\tvalid_0's l2: 0.141769\n",
      "[72]\tvalid_0's l1: 0.270493\tvalid_0's l2: 0.141867\n",
      "[73]\tvalid_0's l1: 0.270722\tvalid_0's l2: 0.141977\n",
      "[74]\tvalid_0's l1: 0.270877\tvalid_0's l2: 0.1422\n",
      "[75]\tvalid_0's l1: 0.271074\tvalid_0's l2: 0.142566\n",
      "[76]\tvalid_0's l1: 0.27079\tvalid_0's l2: 0.142234\n",
      "[77]\tvalid_0's l1: 0.270559\tvalid_0's l2: 0.142039\n",
      "[78]\tvalid_0's l1: 0.270444\tvalid_0's l2: 0.141982\n",
      "[79]\tvalid_0's l1: 0.270095\tvalid_0's l2: 0.141706\n",
      "[80]\tvalid_0's l1: 0.270191\tvalid_0's l2: 0.141776\n",
      "[81]\tvalid_0's l1: 0.269778\tvalid_0's l2: 0.141287\n",
      "[82]\tvalid_0's l1: 0.269865\tvalid_0's l2: 0.141379\n",
      "[83]\tvalid_0's l1: 0.269821\tvalid_0's l2: 0.141396\n",
      "[84]\tvalid_0's l1: 0.26974\tvalid_0's l2: 0.141334\n",
      "[85]\tvalid_0's l1: 0.269763\tvalid_0's l2: 0.1414\n",
      "[86]\tvalid_0's l1: 0.269494\tvalid_0's l2: 0.141107\n",
      "[87]\tvalid_0's l1: 0.269502\tvalid_0's l2: 0.141109\n",
      "[88]\tvalid_0's l1: 0.269521\tvalid_0's l2: 0.141113\n",
      "[89]\tvalid_0's l1: 0.269597\tvalid_0's l2: 0.141184\n",
      "[90]\tvalid_0's l1: 0.269598\tvalid_0's l2: 0.1412\n",
      "[91]\tvalid_0's l1: 0.269635\tvalid_0's l2: 0.141234\n",
      "[92]\tvalid_0's l1: 0.269462\tvalid_0's l2: 0.140937\n",
      "[93]\tvalid_0's l1: 0.269527\tvalid_0's l2: 0.141003\n",
      "[94]\tvalid_0's l1: 0.269359\tvalid_0's l2: 0.140773\n",
      "[95]\tvalid_0's l1: 0.26941\tvalid_0's l2: 0.14082\n",
      "[96]\tvalid_0's l1: 0.269557\tvalid_0's l2: 0.140976\n",
      "[97]\tvalid_0's l1: 0.269188\tvalid_0's l2: 0.140472\n",
      "[98]\tvalid_0's l1: 0.269217\tvalid_0's l2: 0.140455\n",
      "[99]\tvalid_0's l1: 0.269005\tvalid_0's l2: 0.140212\n",
      "[100]\tvalid_0's l1: 0.269049\tvalid_0's l2: 0.140252\n",
      "[LightGBM] [Warning] Unknown parameter: learnnig_rage\n",
      "[1]\tvalid_0's l1: 0.823191\tvalid_0's l2: 1.1956\n",
      "[2]\tvalid_0's l1: 0.76053\tvalid_0's l2: 1.0396\n",
      "[3]\tvalid_0's l1: 0.705408\tvalid_0's l2: 0.913909\n",
      "[4]\tvalid_0's l1: 0.654651\tvalid_0's l2: 0.807984\n",
      "[5]\tvalid_0's l1: 0.610952\tvalid_0's l2: 0.721859\n",
      "[6]\tvalid_0's l1: 0.571816\tvalid_0's l2: 0.648508\n",
      "[7]\tvalid_0's l1: 0.53859\tvalid_0's l2: 0.588478\n",
      "[8]\tvalid_0's l1: 0.509939\tvalid_0's l2: 0.538091\n",
      "[9]\tvalid_0's l1: 0.485053\tvalid_0's l2: 0.494695\n",
      "[10]\tvalid_0's l1: 0.463472\tvalid_0's l2: 0.458447\n",
      "[11]\tvalid_0's l1: 0.446998\tvalid_0's l2: 0.42739\n",
      "[12]\tvalid_0's l1: 0.432837\tvalid_0's l2: 0.402371\n",
      "[13]\tvalid_0's l1: 0.420466\tvalid_0's l2: 0.380178\n",
      "[14]\tvalid_0's l1: 0.410262\tvalid_0's l2: 0.36121\n",
      "[15]\tvalid_0's l1: 0.400866\tvalid_0's l2: 0.344632\n",
      "[16]\tvalid_0's l1: 0.393712\tvalid_0's l2: 0.33111\n",
      "[17]\tvalid_0's l1: 0.386777\tvalid_0's l2: 0.318598\n",
      "[18]\tvalid_0's l1: 0.381404\tvalid_0's l2: 0.30811\n",
      "[19]\tvalid_0's l1: 0.376808\tvalid_0's l2: 0.300365\n",
      "[20]\tvalid_0's l1: 0.372278\tvalid_0's l2: 0.291992\n",
      "[21]\tvalid_0's l1: 0.368261\tvalid_0's l2: 0.285402\n",
      "[22]\tvalid_0's l1: 0.364581\tvalid_0's l2: 0.278875\n",
      "[23]\tvalid_0's l1: 0.361222\tvalid_0's l2: 0.272633\n",
      "[24]\tvalid_0's l1: 0.358302\tvalid_0's l2: 0.267341\n",
      "[25]\tvalid_0's l1: 0.355685\tvalid_0's l2: 0.262645\n",
      "[26]\tvalid_0's l1: 0.354217\tvalid_0's l2: 0.258867\n",
      "[27]\tvalid_0's l1: 0.351224\tvalid_0's l2: 0.254619\n",
      "[28]\tvalid_0's l1: 0.349203\tvalid_0's l2: 0.251056\n",
      "[29]\tvalid_0's l1: 0.347987\tvalid_0's l2: 0.248499\n",
      "[30]\tvalid_0's l1: 0.346165\tvalid_0's l2: 0.245602\n",
      "[31]\tvalid_0's l1: 0.344305\tvalid_0's l2: 0.242961\n",
      "[32]\tvalid_0's l1: 0.34359\tvalid_0's l2: 0.241005\n",
      "[33]\tvalid_0's l1: 0.341824\tvalid_0's l2: 0.238291\n",
      "[34]\tvalid_0's l1: 0.340232\tvalid_0's l2: 0.236424\n",
      "[35]\tvalid_0's l1: 0.339569\tvalid_0's l2: 0.234881\n",
      "[36]\tvalid_0's l1: 0.338677\tvalid_0's l2: 0.233464\n",
      "[37]\tvalid_0's l1: 0.337427\tvalid_0's l2: 0.231949\n",
      "[38]\tvalid_0's l1: 0.337252\tvalid_0's l2: 0.231152\n",
      "[39]\tvalid_0's l1: 0.336525\tvalid_0's l2: 0.229917\n",
      "[40]\tvalid_0's l1: 0.335403\tvalid_0's l2: 0.228854\n",
      "[41]\tvalid_0's l1: 0.335164\tvalid_0's l2: 0.228253\n",
      "[42]\tvalid_0's l1: 0.334559\tvalid_0's l2: 0.227472\n",
      "[43]\tvalid_0's l1: 0.33382\tvalid_0's l2: 0.226339\n",
      "[44]\tvalid_0's l1: 0.333323\tvalid_0's l2: 0.225702\n",
      "[45]\tvalid_0's l1: 0.332804\tvalid_0's l2: 0.2249\n",
      "[46]\tvalid_0's l1: 0.332261\tvalid_0's l2: 0.223899\n",
      "[47]\tvalid_0's l1: 0.331815\tvalid_0's l2: 0.223102\n",
      "[48]\tvalid_0's l1: 0.331\tvalid_0's l2: 0.222191\n",
      "[49]\tvalid_0's l1: 0.330586\tvalid_0's l2: 0.221341\n",
      "[50]\tvalid_0's l1: 0.330109\tvalid_0's l2: 0.220797\n",
      "[51]\tvalid_0's l1: 0.330023\tvalid_0's l2: 0.220599\n",
      "[52]\tvalid_0's l1: 0.329912\tvalid_0's l2: 0.220294\n",
      "[53]\tvalid_0's l1: 0.329472\tvalid_0's l2: 0.219618\n",
      "[54]\tvalid_0's l1: 0.329102\tvalid_0's l2: 0.219188\n",
      "[55]\tvalid_0's l1: 0.328874\tvalid_0's l2: 0.219015\n",
      "[56]\tvalid_0's l1: 0.328435\tvalid_0's l2: 0.218537\n",
      "[57]\tvalid_0's l1: 0.328592\tvalid_0's l2: 0.218475\n",
      "[58]\tvalid_0's l1: 0.328162\tvalid_0's l2: 0.217665\n",
      "[59]\tvalid_0's l1: 0.328205\tvalid_0's l2: 0.217507\n",
      "[60]\tvalid_0's l1: 0.327986\tvalid_0's l2: 0.217112\n",
      "[61]\tvalid_0's l1: 0.328054\tvalid_0's l2: 0.216704\n",
      "[62]\tvalid_0's l1: 0.328069\tvalid_0's l2: 0.216728\n",
      "[63]\tvalid_0's l1: 0.327766\tvalid_0's l2: 0.216348\n",
      "[64]\tvalid_0's l1: 0.327915\tvalid_0's l2: 0.216315\n",
      "[65]\tvalid_0's l1: 0.327553\tvalid_0's l2: 0.215518\n",
      "[66]\tvalid_0's l1: 0.327163\tvalid_0's l2: 0.215298\n",
      "[67]\tvalid_0's l1: 0.326736\tvalid_0's l2: 0.214541\n",
      "[68]\tvalid_0's l1: 0.326032\tvalid_0's l2: 0.214062\n",
      "[69]\tvalid_0's l1: 0.325982\tvalid_0's l2: 0.213904\n",
      "[70]\tvalid_0's l1: 0.325773\tvalid_0's l2: 0.213615\n",
      "[71]\tvalid_0's l1: 0.325692\tvalid_0's l2: 0.213636\n",
      "[72]\tvalid_0's l1: 0.325605\tvalid_0's l2: 0.213482\n",
      "[73]\tvalid_0's l1: 0.325548\tvalid_0's l2: 0.213147\n",
      "[74]\tvalid_0's l1: 0.325309\tvalid_0's l2: 0.212852\n",
      "[75]\tvalid_0's l1: 0.325238\tvalid_0's l2: 0.212839\n",
      "[76]\tvalid_0's l1: 0.325218\tvalid_0's l2: 0.212665\n",
      "[77]\tvalid_0's l1: 0.325248\tvalid_0's l2: 0.212754\n",
      "[78]\tvalid_0's l1: 0.324856\tvalid_0's l2: 0.212502\n",
      "[79]\tvalid_0's l1: 0.324668\tvalid_0's l2: 0.21234\n",
      "[80]\tvalid_0's l1: 0.324713\tvalid_0's l2: 0.212072\n",
      "[81]\tvalid_0's l1: 0.324718\tvalid_0's l2: 0.211974\n",
      "[82]\tvalid_0's l1: 0.324797\tvalid_0's l2: 0.21197\n",
      "[83]\tvalid_0's l1: 0.324618\tvalid_0's l2: 0.211926\n",
      "[84]\tvalid_0's l1: 0.324705\tvalid_0's l2: 0.211898\n",
      "[85]\tvalid_0's l1: 0.324793\tvalid_0's l2: 0.211889\n",
      "[86]\tvalid_0's l1: 0.324781\tvalid_0's l2: 0.21188\n",
      "[87]\tvalid_0's l1: 0.324585\tvalid_0's l2: 0.211743\n",
      "[88]\tvalid_0's l1: 0.324645\tvalid_0's l2: 0.211779\n",
      "[89]\tvalid_0's l1: 0.324703\tvalid_0's l2: 0.211844\n",
      "[90]\tvalid_0's l1: 0.324971\tvalid_0's l2: 0.211845\n",
      "[91]\tvalid_0's l1: 0.324995\tvalid_0's l2: 0.211879\n",
      "[92]\tvalid_0's l1: 0.324925\tvalid_0's l2: 0.211678\n",
      "[93]\tvalid_0's l1: 0.325053\tvalid_0's l2: 0.211678\n",
      "[94]\tvalid_0's l1: 0.325127\tvalid_0's l2: 0.211695\n",
      "[95]\tvalid_0's l1: 0.325047\tvalid_0's l2: 0.211682\n",
      "[96]\tvalid_0's l1: 0.325159\tvalid_0's l2: 0.211744\n",
      "[97]\tvalid_0's l1: 0.325411\tvalid_0's l2: 0.211881\n",
      "[98]\tvalid_0's l1: 0.325479\tvalid_0's l2: 0.211884\n",
      "[99]\tvalid_0's l1: 0.32554\tvalid_0's l2: 0.2119\n",
      "[100]\tvalid_0's l1: 0.325483\tvalid_0's l2: 0.211888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:179: UserWarning: Converting column-vector to 1d array\n",
      "  _log_warning('Converting column-vector to 1d array')\n",
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:179: UserWarning: Converting column-vector to 1d array\n",
      "  _log_warning('Converting column-vector to 1d array')\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'task': 'train', \n",
    "    'boosting': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'num_leaves': 10,\n",
    "    'learnnig_rage': 0.05,\n",
    "    'metric': {'l2','l1'},\n",
    "    'verbose': -1\n",
    "}\n",
    "\n",
    "LIGHTGBM_spring_mae, LIGHTGBM_spring_TC_pred = Lightgbm_model('spring')\n",
    "LIGHTGBM_summer_mae, LIGHTGBM_summer_TC_pred = Lightgbm_model('summer')\n",
    "LIGHTGBM_autumn_mae, LIGHTGBM_autumn_TC_pred = Lightgbm_model('autumn')\n",
    "LIGHTGBM_winter_mae, LIGHTGBM_winter_TC_pred = Lightgbm_model('winter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7777e6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert each dictionary to a DataFrame\n",
    "LIGHTGBM_spring_df = pd.DataFrame.from_dict(LIGHTGBM_spring_mae, orient='index', columns=['MAE'])\n",
    "LIGHTGBM_summer_df = pd.DataFrame.from_dict(LIGHTGBM_summer_mae, orient='index', columns=['MAE'])\n",
    "LIGHTGBM_autumn_df = pd.DataFrame.from_dict(LIGHTGBM_autumn_mae, orient='index', columns=['MAE'])\n",
    "LIGHTGBM_winter_df = pd.DataFrame.from_dict(LIGHTGBM_winter_mae, orient='index', columns=['MAE'])\n",
    "\n",
    "LIGHTGBM_mae_df = pd.concat([LIGHTGBM_spring_df, LIGHTGBM_summer_df, LIGHTGBM_autumn_df, LIGHTGBM_winter_df], axis=0)\n",
    "LIGHTGBM_mae_df.columns = ['LIGHTGBM_MAE']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "305b075a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIGHTGBM_MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>146_spring</th>\n",
       "      <td>3.006070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212_spring</th>\n",
       "      <td>2.648066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245_spring</th>\n",
       "      <td>3.009543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146_summer</th>\n",
       "      <td>2.175785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212_summer</th>\n",
       "      <td>2.404646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245_summer</th>\n",
       "      <td>2.802043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146_autumn</th>\n",
       "      <td>1.460923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212_autumn</th>\n",
       "      <td>2.011332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245_autumn</th>\n",
       "      <td>2.112772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146_winter</th>\n",
       "      <td>1.794211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212_winter</th>\n",
       "      <td>1.900934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245_winter</th>\n",
       "      <td>2.299664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            LIGHTGBM_MAE\n",
       "146_spring      3.006070\n",
       "212_spring      2.648066\n",
       "245_spring      3.009543\n",
       "146_summer      2.175785\n",
       "212_summer      2.404646\n",
       "245_summer      2.802043\n",
       "146_autumn      1.460923\n",
       "212_autumn      2.011332\n",
       "245_autumn      2.112772\n",
       "146_winter      1.794211\n",
       "212_winter      1.900934\n",
       "245_winter      2.299664"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LIGHTGBM_mae_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac6d762",
   "metadata": {},
   "source": [
    "# KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "641536e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNeighbors_model(weather):\n",
    "    # initialize result dictionaries\n",
    "    mae_results = {}\n",
    "    TC_pred_results = {}\n",
    "\n",
    "    train = pd.read_csv(\"Train_data.csv\")\n",
    "    train['Date'] = pd.to_datetime(train['Date'])\n",
    "\n",
    "    # Add filter for months based on weather\n",
    "    if weather == 'spring':\n",
    "        train = train[train['Date'].dt.month.isin([2, 3, 4])]\n",
    "    elif weather == 'summer':\n",
    "        train = train[train['Date'].dt.month.isin([5, 6, 7])]\n",
    "    elif weather == 'autumn':\n",
    "        train = train[train['Date'].dt.month.isin([8, 9, 10])]\n",
    "    elif weather == 'winter':\n",
    "        train = train[train['Date'].dt.month.isin([11, 12, 1])]\n",
    "\n",
    "    # 스케일러 생성\n",
    "    # 평균 0, 표준편차 1로 스케일링\n",
    "    scaler = StandardScaler()\n",
    "    y_scaler = StandardScaler()\n",
    "\n",
    "    # train 데이터로 스케일러 학습\n",
    "    x_train = scaler.fit_transform(train.iloc[:,2:12])\n",
    "    y_train = y_scaler.fit_transform(train.iloc[:,-1].values.reshape(-1, 1))\n",
    "    \n",
    "    for file in test_col:\n",
    "        if weather in file:\n",
    "            test = pd.read_csv(file)\n",
    "            test['Date'] = pd.to_datetime(test['Date'])\n",
    "            \n",
    "            x_test = scaler.transform(test.iloc[:,2:12])\n",
    "            y_test = test.iloc[:,-1].values  # add this line\n",
    "\n",
    "            x_train_df = pd.DataFrame(x_train)\n",
    "            x_test_df = pd.DataFrame(x_test)\n",
    "\n",
    "            # Create a model\n",
    "\n",
    "            RegModel = KNeighborsRegressor(n_neighbors=10)\n",
    "\n",
    "            #Creating the model on Training Data\n",
    "            model=RegModel.fit(x_train_df, y_train)\n",
    "            y_pred = model.predict(x_test)\n",
    "\n",
    "            TC_pred = y_scaler.inverse_transform(y_pred.reshape(-1, 1))\n",
    "            \n",
    "            # Evaluate the model\n",
    "            mae = mean_absolute_error(y_test, TC_pred)\n",
    "\n",
    "            # save the results with the filename as the key\n",
    "            filename = os.path.splitext(os.path.basename(file))[0]  # extract filename without extension\n",
    "            mae_results[filename] = mae\n",
    "            TC_pred_results[filename] = TC_pred\n",
    "\n",
    "    return mae_results, TC_pred_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8c27cf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNEIGHBORS_spring_mae, KNEIGHBORS_spring_TC_pred = KNeighbors_model('spring')\n",
    "KNEIGHBORS_summer_mae, KNEIGHBORS_summer_TC_pred = KNeighbors_model('summer')\n",
    "KNEIGHBORS_autumn_mae, KNEIGHBORS_autumn_TC_pred = KNeighbors_model('autumn')\n",
    "KNEIGHBORS_winter_mae, KNEIGHBORS_winter_TC_pred = KNeighbors_model('winter')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dd1f6439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert each dictionary to a DataFrame\n",
    "KNEIGHBORS_spring_df = pd.DataFrame.from_dict(KNEIGHBORS_spring_mae, orient='index', columns=['MAE'])\n",
    "KNEIGHBORS_summer_df = pd.DataFrame.from_dict(KNEIGHBORS_summer_mae, orient='index', columns=['MAE'])\n",
    "KNEIGHBORS_autumn_df = pd.DataFrame.from_dict(KNEIGHBORS_autumn_mae, orient='index', columns=['MAE'])\n",
    "KNEIGHBORS_winter_df = pd.DataFrame.from_dict(KNEIGHBORS_winter_mae, orient='index', columns=['MAE'])\n",
    "\n",
    "\n",
    "KNEIGHBORS_mae_df = pd.concat([KNEIGHBORS_spring_df, KNEIGHBORS_summer_df, KNEIGHBORS_autumn_df, KNEIGHBORS_winter_df], axis=0)\n",
    "KNEIGHBORS_mae_df.columns = ['KNEIGHBORS_MAE']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "be347034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KNEIGHBORS_MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>146_spring</th>\n",
       "      <td>2.837316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212_spring</th>\n",
       "      <td>3.064942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245_spring</th>\n",
       "      <td>2.945654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146_summer</th>\n",
       "      <td>2.024141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212_summer</th>\n",
       "      <td>2.566502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245_summer</th>\n",
       "      <td>2.908134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146_autumn</th>\n",
       "      <td>1.477209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212_autumn</th>\n",
       "      <td>2.013186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245_autumn</th>\n",
       "      <td>2.294865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146_winter</th>\n",
       "      <td>1.587083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212_winter</th>\n",
       "      <td>1.943698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245_winter</th>\n",
       "      <td>2.425334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            KNEIGHBORS_MAE\n",
       "146_spring        2.837316\n",
       "212_spring        3.064942\n",
       "245_spring        2.945654\n",
       "146_summer        2.024141\n",
       "212_summer        2.566502\n",
       "245_summer        2.908134\n",
       "146_autumn        1.477209\n",
       "212_autumn        2.013186\n",
       "245_autumn        2.294865\n",
       "146_winter        1.587083\n",
       "212_winter        1.943698\n",
       "245_winter        2.425334"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNEIGHBORS_mae_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02aaa348",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6367021e",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping()\n",
    "\n",
    "def LSTM_model(weather):\n",
    "    # initialize result dictionaries\n",
    "    mae_results = {}\n",
    "    TC_pred_results = {}\n",
    "\n",
    "    train = pd.read_csv(\"Train_data.csv\")\n",
    "    train['Date'] = pd.to_datetime(train['Date'])\n",
    "\n",
    "    # Add filter for months based on weather\n",
    "    if weather == 'spring':\n",
    "        train = train[train['Date'].dt.month.isin([2, 3, 4])]\n",
    "    elif weather == 'summer':\n",
    "        train = train[train['Date'].dt.month.isin([5, 6, 7])]\n",
    "    elif weather == 'autumn':\n",
    "        train = train[train['Date'].dt.month.isin([8, 9, 10])]\n",
    "    elif weather == 'winter':\n",
    "        train = train[train['Date'].dt.month.isin([11, 12, 1])]\n",
    "\n",
    "    # 스케일러 생성\n",
    "    # 평균 0, 표준편차 1로 스케일링\n",
    "    scaler = StandardScaler()\n",
    "    y_scaler = StandardScaler()\n",
    "\n",
    "    # train 데이터로 스케일러 학습\n",
    "    x_train = scaler.fit_transform(train.iloc[:,2:12])\n",
    "    y_train = y_scaler.fit_transform(train.iloc[:,-1].values.reshape(-1, 1))\n",
    "    \n",
    "    for file in test_col:\n",
    "        if weather in file:\n",
    "            test = pd.read_csv(file)\n",
    "            test['Date'] = pd.to_datetime(test['Date'])\n",
    "            \n",
    "            x_test = scaler.transform(test.iloc[:,2:12])\n",
    "            y_test = test.iloc[:,-1].values  # add this line\n",
    "\n",
    "            \n",
    "            #x_train = x_train.reshape((-1, 10, 1))\n",
    "            x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], 1)\n",
    "            x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], 1)\n",
    "\n",
    "            # Create a model\n",
    "            \n",
    "            # LSTM 모델 생성\n",
    "            model = Sequential()\n",
    "            model.add(LSTM(64, activation='relu', input_shape=(10, 1), return_sequences=True))  # LSTM 레이어\n",
    "            model.add(Dropout(0.3)) #과적합 방지를 위한 드랍아웃 비율은 0.3\n",
    "            model.add(Dense(32)) #은닉층\n",
    "            model.add(Dropout(0.3)) #드랍아웃 층\n",
    "            model.add(LSTM(16, activation='relu', input_shape=(10, 1), return_sequences=False))\n",
    "            model.add(Dropout(0.3)) #드랍아웃 층\n",
    "            model.add(Dense(1))\n",
    "            adam = optimizers.Adam(learning_rate = 0.001)\n",
    "            model.compile(loss='mae', optimizer='adam')\n",
    "            model.summary()\n",
    "\n",
    "            # Fit the model\n",
    "            model.fit(x_train, y_train, epochs=20, batch_size=64, verbose=2)\n",
    "\n",
    "            # Make predictions\n",
    "            y_pred = model.predict(x_test)\n",
    "    \n",
    "            TC_pred = y_scaler.inverse_transform(y_pred)\n",
    "\n",
    "            # Evaluate the model\n",
    "            mae = mean_absolute_error(y_test, TC_pred)\n",
    "\n",
    "            # save the results with the filename as the key\n",
    "            filename = os.path.splitext(os.path.basename(file))[0]  # extract filename without extension\n",
    "            mae_results[filename] = mae\n",
    "            TC_pred_results[filename] = TC_pred\n",
    "\n",
    "    return mae_results, TC_pred_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "54fcd938",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 10, 64)            16896     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 10, 64)            0         \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 10, 32)            2080      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 10, 32)            0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 16)                3136      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22,129\n",
      "Trainable params: 22,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1673/1673 - 11s - loss: 0.3651 - 11s/epoch - 7ms/step\n",
      "Epoch 2/20\n",
      "1673/1673 - 9s - loss: 0.3161 - 9s/epoch - 6ms/step\n",
      "Epoch 3/20\n",
      "1673/1673 - 9s - loss: 0.3082 - 9s/epoch - 6ms/step\n",
      "Epoch 4/20\n",
      "1673/1673 - 9s - loss: 0.3030 - 9s/epoch - 6ms/step\n",
      "Epoch 5/20\n",
      "1673/1673 - 9s - loss: 0.2996 - 9s/epoch - 6ms/step\n",
      "Epoch 6/20\n",
      "1673/1673 - 9s - loss: 0.2980 - 9s/epoch - 5ms/step\n",
      "Epoch 7/20\n",
      "1673/1673 - 9s - loss: 0.2951 - 9s/epoch - 5ms/step\n",
      "Epoch 8/20\n",
      "1673/1673 - 9s - loss: 0.2937 - 9s/epoch - 5ms/step\n",
      "Epoch 9/20\n",
      "1673/1673 - 9s - loss: 0.2929 - 9s/epoch - 5ms/step\n",
      "Epoch 10/20\n",
      "1673/1673 - 9s - loss: 0.2924 - 9s/epoch - 5ms/step\n",
      "Epoch 11/20\n",
      "1673/1673 - 9s - loss: 0.2910 - 9s/epoch - 5ms/step\n",
      "Epoch 12/20\n",
      "1673/1673 - 9s - loss: 0.2897 - 9s/epoch - 5ms/step\n",
      "Epoch 13/20\n",
      "1673/1673 - 9s - loss: 0.2895 - 9s/epoch - 5ms/step\n",
      "Epoch 14/20\n",
      "1673/1673 - 9s - loss: 0.2910 - 9s/epoch - 5ms/step\n",
      "Epoch 15/20\n",
      "1673/1673 - 9s - loss: 0.2887 - 9s/epoch - 5ms/step\n",
      "Epoch 16/20\n",
      "1673/1673 - 9s - loss: 0.2892 - 9s/epoch - 5ms/step\n",
      "Epoch 17/20\n",
      "1673/1673 - 9s - loss: 0.2881 - 9s/epoch - 5ms/step\n",
      "Epoch 18/20\n",
      "1673/1673 - 9s - loss: 0.2869 - 9s/epoch - 5ms/step\n",
      "Epoch 19/20\n",
      "1673/1673 - 9s - loss: 0.2864 - 9s/epoch - 5ms/step\n",
      "Epoch 20/20\n",
      "1673/1673 - 9s - loss: 0.2860 - 9s/epoch - 5ms/step\n",
      "70/70 [==============================] - 0s 2ms/step\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 10, 64)            16896     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 10, 64)            0         \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 10, 32)            2080      \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 10, 32)            0         \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 16)                3136      \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22,129\n",
      "Trainable params: 22,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1673/1673 - 11s - loss: 0.3684 - 11s/epoch - 6ms/step\n",
      "Epoch 2/20\n",
      "1673/1673 - 9s - loss: 0.3144 - 9s/epoch - 5ms/step\n",
      "Epoch 3/20\n",
      "1673/1673 - 9s - loss: 0.3058 - 9s/epoch - 5ms/step\n",
      "Epoch 4/20\n",
      "1673/1673 - 9s - loss: 0.3018 - 9s/epoch - 5ms/step\n",
      "Epoch 5/20\n",
      "1673/1673 - 9s - loss: 0.2991 - 9s/epoch - 5ms/step\n",
      "Epoch 6/20\n",
      "1673/1673 - 9s - loss: 0.2969 - 9s/epoch - 5ms/step\n",
      "Epoch 7/20\n",
      "1673/1673 - 9s - loss: 0.2948 - 9s/epoch - 5ms/step\n",
      "Epoch 8/20\n",
      "1673/1673 - 9s - loss: 0.2933 - 9s/epoch - 5ms/step\n",
      "Epoch 9/20\n",
      "1673/1673 - 9s - loss: 0.2922 - 9s/epoch - 5ms/step\n",
      "Epoch 10/20\n",
      "1673/1673 - 9s - loss: 0.2923 - 9s/epoch - 5ms/step\n",
      "Epoch 11/20\n",
      "1673/1673 - 9s - loss: 0.2900 - 9s/epoch - 5ms/step\n",
      "Epoch 12/20\n",
      "1673/1673 - 9s - loss: 0.2902 - 9s/epoch - 5ms/step\n",
      "Epoch 13/20\n",
      "1673/1673 - 9s - loss: 0.2879 - 9s/epoch - 5ms/step\n",
      "Epoch 14/20\n",
      "1673/1673 - 9s - loss: 0.2881 - 9s/epoch - 5ms/step\n",
      "Epoch 15/20\n",
      "1673/1673 - 9s - loss: 0.2883 - 9s/epoch - 5ms/step\n",
      "Epoch 16/20\n",
      "1673/1673 - 9s - loss: 0.2864 - 9s/epoch - 5ms/step\n",
      "Epoch 17/20\n",
      "1673/1673 - 9s - loss: 0.2870 - 9s/epoch - 5ms/step\n",
      "Epoch 18/20\n",
      "1673/1673 - 9s - loss: 0.2859 - 9s/epoch - 5ms/step\n",
      "Epoch 19/20\n",
      "1673/1673 - 9s - loss: 0.2850 - 9s/epoch - 5ms/step\n",
      "Epoch 20/20\n",
      "1673/1673 - 10s - loss: 0.2850 - 10s/epoch - 6ms/step\n",
      "70/70 [==============================] - 0s 2ms/step\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_4 (LSTM)               (None, 10, 64)            16896     \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 10, 64)            0         \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 10, 32)            2080      \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 10, 32)            0         \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 16)                3136      \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22,129\n",
      "Trainable params: 22,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1673/1673 - 11s - loss: 0.3714 - 11s/epoch - 7ms/step\n",
      "Epoch 2/20\n",
      "1673/1673 - 10s - loss: 0.3173 - 10s/epoch - 6ms/step\n",
      "Epoch 3/20\n",
      "1673/1673 - 10s - loss: 0.3065 - 10s/epoch - 6ms/step\n",
      "Epoch 4/20\n",
      "1673/1673 - 9s - loss: 0.3032 - 9s/epoch - 5ms/step\n",
      "Epoch 5/20\n",
      "1673/1673 - 9s - loss: 0.2968 - 9s/epoch - 5ms/step\n",
      "Epoch 6/20\n",
      "1673/1673 - 9s - loss: 0.2952 - 9s/epoch - 6ms/step\n",
      "Epoch 7/20\n",
      "1673/1673 - 9s - loss: 0.2930 - 9s/epoch - 6ms/step\n",
      "Epoch 8/20\n",
      "1673/1673 - 9s - loss: 0.2931 - 9s/epoch - 6ms/step\n",
      "Epoch 9/20\n",
      "1673/1673 - 9s - loss: 0.2920 - 9s/epoch - 6ms/step\n",
      "Epoch 10/20\n",
      "1673/1673 - 9s - loss: 0.2913 - 9s/epoch - 6ms/step\n",
      "Epoch 11/20\n",
      "1673/1673 - 9s - loss: 0.2901 - 9s/epoch - 6ms/step\n",
      "Epoch 12/20\n",
      "1673/1673 - 9s - loss: 0.2883 - 9s/epoch - 6ms/step\n",
      "Epoch 13/20\n",
      "1673/1673 - 9s - loss: 0.2892 - 9s/epoch - 6ms/step\n",
      "Epoch 14/20\n",
      "1673/1673 - 9s - loss: 0.2875 - 9s/epoch - 5ms/step\n",
      "Epoch 15/20\n",
      "1673/1673 - 10s - loss: 0.2880 - 10s/epoch - 6ms/step\n",
      "Epoch 16/20\n",
      "1673/1673 - 9s - loss: 0.2873 - 9s/epoch - 6ms/step\n",
      "Epoch 17/20\n",
      "1673/1673 - 9s - loss: 0.2867 - 9s/epoch - 6ms/step\n",
      "Epoch 18/20\n",
      "1673/1673 - 9s - loss: 0.2864 - 9s/epoch - 5ms/step\n",
      "Epoch 19/20\n",
      "1673/1673 - 9s - loss: 0.2860 - 9s/epoch - 5ms/step\n",
      "Epoch 20/20\n",
      "1673/1673 - 9s - loss: 0.2861 - 9s/epoch - 6ms/step\n",
      "70/70 [==============================] - 0s 2ms/step\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " lstm_6 (LSTM)               (None, 10, 64)            16896     \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 10, 64)            0         \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 10, 32)            2080      \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 10, 32)            0         \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 16)                3136      \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22,129\n",
      "Trainable params: 22,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1725/1725 - 11s - loss: 0.3913 - 11s/epoch - 6ms/step\n",
      "Epoch 2/20\n",
      "1725/1725 - 9s - loss: 0.3393 - 9s/epoch - 5ms/step\n",
      "Epoch 3/20\n",
      "1725/1725 - 9s - loss: 0.3231 - 9s/epoch - 5ms/step\n",
      "Epoch 4/20\n",
      "1725/1725 - 9s - loss: 0.3146 - 9s/epoch - 5ms/step\n",
      "Epoch 5/20\n",
      "1725/1725 - 9s - loss: 0.3090 - 9s/epoch - 5ms/step\n",
      "Epoch 6/20\n",
      "1725/1725 - 9s - loss: 0.3060 - 9s/epoch - 5ms/step\n",
      "Epoch 7/20\n",
      "1725/1725 - 9s - loss: 0.3029 - 9s/epoch - 5ms/step\n",
      "Epoch 8/20\n",
      "1725/1725 - 9s - loss: 0.3015 - 9s/epoch - 5ms/step\n",
      "Epoch 9/20\n",
      "1725/1725 - 9s - loss: 0.2987 - 9s/epoch - 5ms/step\n",
      "Epoch 10/20\n",
      "1725/1725 - 9s - loss: 0.2979 - 9s/epoch - 5ms/step\n",
      "Epoch 11/20\n",
      "1725/1725 - 9s - loss: 0.2972 - 9s/epoch - 5ms/step\n",
      "Epoch 12/20\n",
      "1725/1725 - 9s - loss: 0.2972 - 9s/epoch - 5ms/step\n",
      "Epoch 13/20\n",
      "1725/1725 - 9s - loss: 0.2967 - 9s/epoch - 5ms/step\n",
      "Epoch 14/20\n",
      "1725/1725 - 9s - loss: 0.2955 - 9s/epoch - 5ms/step\n",
      "Epoch 15/20\n",
      "1725/1725 - 9s - loss: 0.2953 - 9s/epoch - 5ms/step\n",
      "Epoch 16/20\n",
      "1725/1725 - 9s - loss: 0.2945 - 9s/epoch - 5ms/step\n",
      "Epoch 17/20\n",
      "1725/1725 - 9s - loss: 0.2939 - 9s/epoch - 5ms/step\n",
      "Epoch 18/20\n",
      "1725/1725 - 9s - loss: 0.2944 - 9s/epoch - 5ms/step\n",
      "Epoch 19/20\n",
      "1725/1725 - 9s - loss: 0.2935 - 9s/epoch - 5ms/step\n",
      "Epoch 20/20\n",
      "1725/1725 - 9s - loss: 0.2929 - 9s/epoch - 5ms/step\n",
      "72/72 [==============================] - 0s 2ms/step\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_8 (LSTM)               (None, 10, 64)            16896     \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 10, 64)            0         \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 10, 32)            2080      \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 10, 32)            0         \n",
      "                                                                 \n",
      " lstm_9 (LSTM)               (None, 16)                3136      \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22,129\n",
      "Trainable params: 22,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1725/1725 - 11s - loss: 0.3920 - 11s/epoch - 6ms/step\n",
      "Epoch 2/20\n",
      "1725/1725 - 9s - loss: 0.3311 - 9s/epoch - 5ms/step\n",
      "Epoch 3/20\n",
      "1725/1725 - 9s - loss: 0.3193 - 9s/epoch - 5ms/step\n",
      "Epoch 4/20\n",
      "1725/1725 - 9s - loss: 0.3106 - 9s/epoch - 5ms/step\n",
      "Epoch 5/20\n",
      "1725/1725 - 9s - loss: 0.3067 - 9s/epoch - 5ms/step\n",
      "Epoch 6/20\n",
      "1725/1725 - 9s - loss: 0.3048 - 9s/epoch - 5ms/step\n",
      "Epoch 7/20\n",
      "1725/1725 - 9s - loss: 0.3013 - 9s/epoch - 5ms/step\n",
      "Epoch 8/20\n",
      "1725/1725 - 9s - loss: 0.3001 - 9s/epoch - 5ms/step\n",
      "Epoch 9/20\n",
      "1725/1725 - 9s - loss: 0.2985 - 9s/epoch - 5ms/step\n",
      "Epoch 10/20\n",
      "1725/1725 - 9s - loss: 0.2971 - 9s/epoch - 5ms/step\n",
      "Epoch 11/20\n",
      "1725/1725 - 9s - loss: 0.2969 - 9s/epoch - 5ms/step\n",
      "Epoch 12/20\n",
      "1725/1725 - 9s - loss: 0.2962 - 9s/epoch - 5ms/step\n",
      "Epoch 13/20\n",
      "1725/1725 - 9s - loss: 0.2946 - 9s/epoch - 5ms/step\n",
      "Epoch 14/20\n",
      "1725/1725 - 9s - loss: 0.2945 - 9s/epoch - 5ms/step\n",
      "Epoch 15/20\n",
      "1725/1725 - 9s - loss: 0.2942 - 9s/epoch - 5ms/step\n",
      "Epoch 16/20\n",
      "1725/1725 - 9s - loss: 0.2945 - 9s/epoch - 5ms/step\n",
      "Epoch 17/20\n",
      "1725/1725 - 9s - loss: 0.2938 - 9s/epoch - 5ms/step\n",
      "Epoch 18/20\n",
      "1725/1725 - 9s - loss: 0.2930 - 9s/epoch - 5ms/step\n",
      "Epoch 19/20\n",
      "1725/1725 - 9s - loss: 0.2917 - 9s/epoch - 5ms/step\n",
      "Epoch 20/20\n",
      "1725/1725 - 9s - loss: 0.2925 - 9s/epoch - 5ms/step\n",
      "72/72 [==============================] - 0s 1ms/step\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_10 (LSTM)              (None, 10, 64)            16896     \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 10, 64)            0         \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 10, 32)            2080      \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 10, 32)            0         \n",
      "                                                                 \n",
      " lstm_11 (LSTM)              (None, 16)                3136      \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22,129\n",
      "Trainable params: 22,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1725/1725 - 10s - loss: 0.3891 - 10s/epoch - 6ms/step\n",
      "Epoch 2/20\n",
      "1725/1725 - 9s - loss: 0.3311 - 9s/epoch - 5ms/step\n",
      "Epoch 3/20\n",
      "1725/1725 - 9s - loss: 0.3174 - 9s/epoch - 5ms/step\n",
      "Epoch 4/20\n",
      "1725/1725 - 9s - loss: 0.3114 - 9s/epoch - 5ms/step\n",
      "Epoch 5/20\n",
      "1725/1725 - 9s - loss: 0.3072 - 9s/epoch - 5ms/step\n",
      "Epoch 6/20\n",
      "1725/1725 - 9s - loss: 0.3028 - 9s/epoch - 5ms/step\n",
      "Epoch 7/20\n",
      "1725/1725 - 9s - loss: 0.3009 - 9s/epoch - 5ms/step\n",
      "Epoch 8/20\n",
      "1725/1725 - 9s - loss: 0.2991 - 9s/epoch - 5ms/step\n",
      "Epoch 9/20\n",
      "1725/1725 - 9s - loss: 0.2982 - 9s/epoch - 5ms/step\n",
      "Epoch 10/20\n",
      "1725/1725 - 9s - loss: 0.2963 - 9s/epoch - 5ms/step\n",
      "Epoch 11/20\n",
      "1725/1725 - 9s - loss: 0.2945 - 9s/epoch - 5ms/step\n",
      "Epoch 12/20\n",
      "1725/1725 - 9s - loss: 0.2957 - 9s/epoch - 5ms/step\n",
      "Epoch 13/20\n",
      "1725/1725 - 9s - loss: 0.2949 - 9s/epoch - 5ms/step\n",
      "Epoch 14/20\n",
      "1725/1725 - 9s - loss: 0.2947 - 9s/epoch - 5ms/step\n",
      "Epoch 15/20\n",
      "1725/1725 - 9s - loss: 0.2934 - 9s/epoch - 5ms/step\n",
      "Epoch 16/20\n",
      "1725/1725 - 9s - loss: 0.2931 - 9s/epoch - 5ms/step\n",
      "Epoch 17/20\n",
      "1725/1725 - 9s - loss: 0.2918 - 9s/epoch - 5ms/step\n",
      "Epoch 18/20\n",
      "1725/1725 - 9s - loss: 0.2922 - 9s/epoch - 5ms/step\n",
      "Epoch 19/20\n",
      "1725/1725 - 9s - loss: 0.2911 - 9s/epoch - 5ms/step\n",
      "Epoch 20/20\n",
      "1725/1725 - 9s - loss: 0.2911 - 9s/epoch - 5ms/step\n",
      "72/72 [==============================] - 0s 1ms/step\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_12 (LSTM)              (None, 10, 64)            16896     \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 10, 64)            0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " dense_48 (Dense)            (None, 10, 32)            2080      \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 10, 32)            0         \n",
      "                                                                 \n",
      " lstm_13 (LSTM)              (None, 16)                3136      \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22,129\n",
      "Trainable params: 22,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1725/1725 - 9s - loss: 0.3415 - 9s/epoch - 5ms/step\n",
      "Epoch 2/20\n",
      "1725/1725 - 8s - loss: 0.3005 - 8s/epoch - 4ms/step\n",
      "Epoch 3/20\n",
      "1725/1725 - 8s - loss: 0.2943 - 8s/epoch - 4ms/step\n",
      "Epoch 4/20\n",
      "1725/1725 - 8s - loss: 0.2904 - 8s/epoch - 4ms/step\n",
      "Epoch 5/20\n",
      "1725/1725 - 8s - loss: 0.2857 - 8s/epoch - 4ms/step\n",
      "Epoch 6/20\n",
      "1725/1725 - 7s - loss: 0.2836 - 7s/epoch - 4ms/step\n",
      "Epoch 7/20\n",
      "1725/1725 - 8s - loss: 0.2827 - 8s/epoch - 4ms/step\n",
      "Epoch 8/20\n",
      "1725/1725 - 7s - loss: 0.2813 - 7s/epoch - 4ms/step\n",
      "Epoch 9/20\n",
      "1725/1725 - 7s - loss: 0.2796 - 7s/epoch - 4ms/step\n",
      "Epoch 10/20\n",
      "1725/1725 - 8s - loss: 0.2794 - 8s/epoch - 4ms/step\n",
      "Epoch 11/20\n",
      "1725/1725 - 8s - loss: 0.2780 - 8s/epoch - 4ms/step\n",
      "Epoch 12/20\n",
      "1725/1725 - 8s - loss: 0.2772 - 8s/epoch - 4ms/step\n",
      "Epoch 13/20\n",
      "1725/1725 - 8s - loss: 0.2763 - 8s/epoch - 4ms/step\n",
      "Epoch 14/20\n",
      "1725/1725 - 7s - loss: 0.2748 - 7s/epoch - 4ms/step\n",
      "Epoch 15/20\n",
      "1725/1725 - 8s - loss: 0.2740 - 8s/epoch - 4ms/step\n",
      "Epoch 16/20\n",
      "1725/1725 - 7s - loss: 0.2735 - 7s/epoch - 4ms/step\n",
      "Epoch 17/20\n",
      "1725/1725 - 8s - loss: 0.2740 - 8s/epoch - 4ms/step\n",
      "Epoch 18/20\n",
      "1725/1725 - 7s - loss: 0.2725 - 7s/epoch - 4ms/step\n",
      "Epoch 19/20\n",
      "1725/1725 - 7s - loss: 0.2731 - 7s/epoch - 4ms/step\n",
      "Epoch 20/20\n",
      "1725/1725 - 7s - loss: 0.2729 - 7s/epoch - 4ms/step\n",
      "72/72 [==============================] - 0s 2ms/step\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_14 (LSTM)              (None, 10, 64)            16896     \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 10, 64)            0         \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 10, 32)            2080      \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 10, 32)            0         \n",
      "                                                                 \n",
      " lstm_15 (LSTM)              (None, 16)                3136      \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22,129\n",
      "Trainable params: 22,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1725/1725 - 9s - loss: 0.3463 - 9s/epoch - 5ms/step\n",
      "Epoch 2/20\n",
      "1725/1725 - 8s - loss: 0.3026 - 8s/epoch - 4ms/step\n",
      "Epoch 3/20\n",
      "1725/1725 - 8s - loss: 0.2962 - 8s/epoch - 4ms/step\n",
      "Epoch 4/20\n",
      "1725/1725 - 8s - loss: 0.2917 - 8s/epoch - 4ms/step\n",
      "Epoch 5/20\n",
      "1725/1725 - 7s - loss: 0.2880 - 7s/epoch - 4ms/step\n",
      "Epoch 6/20\n",
      "1725/1725 - 7s - loss: 0.2862 - 7s/epoch - 4ms/step\n",
      "Epoch 7/20\n",
      "1725/1725 - 8s - loss: 0.2825 - 8s/epoch - 4ms/step\n",
      "Epoch 8/20\n",
      "1725/1725 - 8s - loss: 0.2815 - 8s/epoch - 4ms/step\n",
      "Epoch 9/20\n",
      "1725/1725 - 7s - loss: 0.2806 - 7s/epoch - 4ms/step\n",
      "Epoch 10/20\n",
      "1725/1725 - 7s - loss: 0.2795 - 7s/epoch - 4ms/step\n",
      "Epoch 11/20\n",
      "1725/1725 - 7s - loss: 0.2772 - 7s/epoch - 4ms/step\n",
      "Epoch 12/20\n",
      "1725/1725 - 8s - loss: 0.2769 - 8s/epoch - 4ms/step\n",
      "Epoch 13/20\n",
      "1725/1725 - 8s - loss: 0.2755 - 8s/epoch - 4ms/step\n",
      "Epoch 14/20\n",
      "1725/1725 - 8s - loss: 0.2747 - 8s/epoch - 4ms/step\n",
      "Epoch 15/20\n",
      "1725/1725 - 7s - loss: 0.2745 - 7s/epoch - 4ms/step\n",
      "Epoch 16/20\n",
      "1725/1725 - 7s - loss: 0.2737 - 7s/epoch - 4ms/step\n",
      "Epoch 17/20\n",
      "1725/1725 - 7s - loss: 0.2729 - 7s/epoch - 4ms/step\n",
      "Epoch 18/20\n",
      "1725/1725 - 7s - loss: 0.2729 - 7s/epoch - 4ms/step\n",
      "Epoch 19/20\n",
      "1725/1725 - 7s - loss: 0.2723 - 7s/epoch - 4ms/step\n",
      "Epoch 20/20\n",
      "1725/1725 - 7s - loss: 0.2714 - 7s/epoch - 4ms/step\n",
      "72/72 [==============================] - 0s 1ms/step\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_16 (LSTM)              (None, 10, 64)            16896     \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, 10, 64)            0         \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 10, 32)            2080      \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 10, 32)            0         \n",
      "                                                                 \n",
      " lstm_17 (LSTM)              (None, 16)                3136      \n",
      "                                                                 \n",
      " dropout_26 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22,129\n",
      "Trainable params: 22,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1725/1725 - 8s - loss: 0.3487 - 8s/epoch - 5ms/step\n",
      "Epoch 2/20\n",
      "1725/1725 - 7s - loss: 0.3012 - 7s/epoch - 4ms/step\n",
      "Epoch 3/20\n",
      "1725/1725 - 7s - loss: 0.2970 - 7s/epoch - 4ms/step\n",
      "Epoch 4/20\n",
      "1725/1725 - 7s - loss: 0.2927 - 7s/epoch - 4ms/step\n",
      "Epoch 5/20\n",
      "1725/1725 - 7s - loss: 0.2876 - 7s/epoch - 4ms/step\n",
      "Epoch 6/20\n",
      "1725/1725 - 7s - loss: 0.2853 - 7s/epoch - 4ms/step\n",
      "Epoch 7/20\n",
      "1725/1725 - 7s - loss: 0.2840 - 7s/epoch - 4ms/step\n",
      "Epoch 8/20\n",
      "1725/1725 - 7s - loss: 0.2808 - 7s/epoch - 4ms/step\n",
      "Epoch 9/20\n",
      "1725/1725 - 7s - loss: 0.2797 - 7s/epoch - 4ms/step\n",
      "Epoch 10/20\n",
      "1725/1725 - 7s - loss: 0.2803 - 7s/epoch - 4ms/step\n",
      "Epoch 11/20\n",
      "1725/1725 - 7s - loss: 0.2776 - 7s/epoch - 4ms/step\n",
      "Epoch 12/20\n",
      "1725/1725 - 7s - loss: 0.2778 - 7s/epoch - 4ms/step\n",
      "Epoch 13/20\n",
      "1725/1725 - 7s - loss: 0.2769 - 7s/epoch - 4ms/step\n",
      "Epoch 14/20\n",
      "1725/1725 - 7s - loss: 0.2755 - 7s/epoch - 4ms/step\n",
      "Epoch 15/20\n",
      "1725/1725 - 7s - loss: 0.2755 - 7s/epoch - 4ms/step\n",
      "Epoch 16/20\n",
      "1725/1725 - 7s - loss: 0.2751 - 7s/epoch - 4ms/step\n",
      "Epoch 17/20\n",
      "1725/1725 - 7s - loss: 0.2731 - 7s/epoch - 4ms/step\n",
      "Epoch 18/20\n",
      "1725/1725 - 7s - loss: 0.2733 - 7s/epoch - 4ms/step\n",
      "Epoch 19/20\n",
      "1725/1725 - 7s - loss: 0.2735 - 7s/epoch - 4ms/step\n",
      "Epoch 20/20\n",
      "1725/1725 - 7s - loss: 0.2718 - 7s/epoch - 4ms/step\n",
      "72/72 [==============================] - 0s 1ms/step\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_18 (LSTM)              (None, 10, 64)            16896     \n",
      "                                                                 \n",
      " dropout_27 (Dropout)        (None, 10, 64)            0         \n",
      "                                                                 \n",
      " dense_54 (Dense)            (None, 10, 32)            2080      \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dropout_28 (Dropout)        (None, 10, 32)            0         \n",
      "                                                                 \n",
      " lstm_19 (LSTM)              (None, 16)                3136      \n",
      "                                                                 \n",
      " dropout_29 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22,129\n",
      "Trainable params: 22,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1725/1725 - 9s - loss: 0.3542 - 9s/epoch - 5ms/step\n",
      "Epoch 2/20\n",
      "1725/1725 - 8s - loss: 0.3183 - 8s/epoch - 4ms/step\n",
      "Epoch 3/20\n",
      "1725/1725 - 8s - loss: 0.3137 - 8s/epoch - 4ms/step\n",
      "Epoch 4/20\n",
      "1725/1725 - 7s - loss: 0.3116 - 7s/epoch - 4ms/step\n",
      "Epoch 5/20\n",
      "1725/1725 - 7s - loss: 0.3090 - 7s/epoch - 4ms/step\n",
      "Epoch 6/20\n",
      "1725/1725 - 7s - loss: 0.3074 - 7s/epoch - 4ms/step\n",
      "Epoch 7/20\n",
      "1725/1725 - 7s - loss: 0.3064 - 7s/epoch - 4ms/step\n",
      "Epoch 8/20\n",
      "1725/1725 - 7s - loss: 0.3049 - 7s/epoch - 4ms/step\n",
      "Epoch 9/20\n",
      "1725/1725 - 7s - loss: 0.3043 - 7s/epoch - 4ms/step\n",
      "Epoch 10/20\n",
      "1725/1725 - 7s - loss: 0.3036 - 7s/epoch - 4ms/step\n",
      "Epoch 11/20\n",
      "1725/1725 - 7s - loss: 0.3049 - 7s/epoch - 4ms/step\n",
      "Epoch 12/20\n",
      "1725/1725 - 7s - loss: 0.3027 - 7s/epoch - 4ms/step\n",
      "Epoch 13/20\n",
      "1725/1725 - 7s - loss: 0.3019 - 7s/epoch - 4ms/step\n",
      "Epoch 14/20\n",
      "1725/1725 - 7s - loss: 0.3012 - 7s/epoch - 4ms/step\n",
      "Epoch 15/20\n",
      "1725/1725 - 8s - loss: 0.3015 - 8s/epoch - 4ms/step\n",
      "Epoch 16/20\n",
      "1725/1725 - 7s - loss: 0.3001 - 7s/epoch - 4ms/step\n",
      "Epoch 17/20\n",
      "1725/1725 - 7s - loss: 0.2988 - 7s/epoch - 4ms/step\n",
      "Epoch 18/20\n",
      "1725/1725 - 7s - loss: 0.2986 - 7s/epoch - 4ms/step\n",
      "Epoch 19/20\n",
      "1725/1725 - 8s - loss: 0.2988 - 8s/epoch - 4ms/step\n",
      "Epoch 20/20\n",
      "1725/1725 - 8s - loss: 0.2970 - 8s/epoch - 4ms/step\n",
      "72/72 [==============================] - 0s 1ms/step\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_20 (LSTM)              (None, 10, 64)            16896     \n",
      "                                                                 \n",
      " dropout_30 (Dropout)        (None, 10, 64)            0         \n",
      "                                                                 \n",
      " dense_56 (Dense)            (None, 10, 32)            2080      \n",
      "                                                                 \n",
      " dropout_31 (Dropout)        (None, 10, 32)            0         \n",
      "                                                                 \n",
      " lstm_21 (LSTM)              (None, 16)                3136      \n",
      "                                                                 \n",
      " dropout_32 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_57 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22,129\n",
      "Trainable params: 22,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1725/1725 - 8s - loss: 0.3571 - 8s/epoch - 5ms/step\n",
      "Epoch 2/20\n",
      "1725/1725 - 7s - loss: 0.3159 - 7s/epoch - 4ms/step\n",
      "Epoch 3/20\n",
      "1725/1725 - 7s - loss: 0.3103 - 7s/epoch - 4ms/step\n",
      "Epoch 4/20\n",
      "1725/1725 - 7s - loss: 0.3082 - 7s/epoch - 4ms/step\n",
      "Epoch 5/20\n",
      "1725/1725 - 7s - loss: 0.3062 - 7s/epoch - 4ms/step\n",
      "Epoch 6/20\n",
      "1725/1725 - 7s - loss: 0.3040 - 7s/epoch - 4ms/step\n",
      "Epoch 7/20\n",
      "1725/1725 - 7s - loss: 0.3038 - 7s/epoch - 4ms/step\n",
      "Epoch 8/20\n",
      "1725/1725 - 7s - loss: 0.3029 - 7s/epoch - 4ms/step\n",
      "Epoch 9/20\n",
      "1725/1725 - 7s - loss: 0.3027 - 7s/epoch - 4ms/step\n",
      "Epoch 10/20\n",
      "1725/1725 - 7s - loss: 0.3017 - 7s/epoch - 4ms/step\n",
      "Epoch 11/20\n",
      "1725/1725 - 7s - loss: 0.3002 - 7s/epoch - 4ms/step\n",
      "Epoch 12/20\n",
      "1725/1725 - 7s - loss: 0.2997 - 7s/epoch - 4ms/step\n",
      "Epoch 13/20\n",
      "1725/1725 - 7s - loss: 0.2999 - 7s/epoch - 4ms/step\n",
      "Epoch 14/20\n",
      "1725/1725 - 7s - loss: 0.2992 - 7s/epoch - 4ms/step\n",
      "Epoch 15/20\n",
      "1725/1725 - 7s - loss: 0.2981 - 7s/epoch - 4ms/step\n",
      "Epoch 16/20\n",
      "1725/1725 - 7s - loss: 0.2981 - 7s/epoch - 4ms/step\n",
      "Epoch 17/20\n",
      "1725/1725 - 7s - loss: 0.2960 - 7s/epoch - 4ms/step\n",
      "Epoch 18/20\n",
      "1725/1725 - 7s - loss: 0.2959 - 7s/epoch - 4ms/step\n",
      "Epoch 19/20\n",
      "1725/1725 - 7s - loss: 0.2958 - 7s/epoch - 4ms/step\n",
      "Epoch 20/20\n",
      "1725/1725 - 7s - loss: 0.2951 - 7s/epoch - 4ms/step\n",
      "72/72 [==============================] - 0s 1ms/step\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_22 (LSTM)              (None, 10, 64)            16896     \n",
      "                                                                 \n",
      " dropout_33 (Dropout)        (None, 10, 64)            0         \n",
      "                                                                 \n",
      " dense_58 (Dense)            (None, 10, 32)            2080      \n",
      "                                                                 \n",
      " dropout_34 (Dropout)        (None, 10, 32)            0         \n",
      "                                                                 \n",
      " lstm_23 (LSTM)              (None, 16)                3136      \n",
      "                                                                 \n",
      " dropout_35 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_59 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22,129\n",
      "Trainable params: 22,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1725/1725 - 8s - loss: 0.3595 - 8s/epoch - 5ms/step\n",
      "Epoch 2/20\n",
      "1725/1725 - 8s - loss: 0.3219 - 8s/epoch - 4ms/step\n",
      "Epoch 3/20\n",
      "1725/1725 - 8s - loss: 0.3178 - 8s/epoch - 4ms/step\n",
      "Epoch 4/20\n",
      "1725/1725 - 8s - loss: 0.3139 - 8s/epoch - 4ms/step\n",
      "Epoch 5/20\n",
      "1725/1725 - 7s - loss: 0.3124 - 7s/epoch - 4ms/step\n",
      "Epoch 6/20\n",
      "1725/1725 - 9s - loss: 0.3113 - 9s/epoch - 5ms/step\n",
      "Epoch 7/20\n",
      "1725/1725 - 8s - loss: 0.3107 - 8s/epoch - 4ms/step\n",
      "Epoch 8/20\n",
      "1725/1725 - 8s - loss: 0.3092 - 8s/epoch - 4ms/step\n",
      "Epoch 9/20\n",
      "1725/1725 - 8s - loss: 0.3080 - 8s/epoch - 5ms/step\n",
      "Epoch 10/20\n",
      "1725/1725 - 8s - loss: 0.3077 - 8s/epoch - 4ms/step\n",
      "Epoch 11/20\n",
      "1725/1725 - 8s - loss: 0.3063 - 8s/epoch - 5ms/step\n",
      "Epoch 12/20\n",
      "1725/1725 - 8s - loss: 0.3059 - 8s/epoch - 5ms/step\n",
      "Epoch 13/20\n",
      "1725/1725 - 8s - loss: 0.3054 - 8s/epoch - 5ms/step\n",
      "Epoch 14/20\n",
      "1725/1725 - 8s - loss: 0.3049 - 8s/epoch - 4ms/step\n",
      "Epoch 15/20\n",
      "1725/1725 - 8s - loss: 0.3037 - 8s/epoch - 4ms/step\n",
      "Epoch 16/20\n",
      "1725/1725 - 8s - loss: 0.3038 - 8s/epoch - 4ms/step\n",
      "Epoch 17/20\n",
      "1725/1725 - 8s - loss: 0.3026 - 8s/epoch - 4ms/step\n",
      "Epoch 18/20\n",
      "1725/1725 - 7s - loss: 0.3022 - 7s/epoch - 4ms/step\n",
      "Epoch 19/20\n",
      "1725/1725 - 8s - loss: 0.3021 - 8s/epoch - 4ms/step\n",
      "Epoch 20/20\n",
      "1725/1725 - 8s - loss: 0.3012 - 8s/epoch - 4ms/step\n",
      "72/72 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "LSTM_spring_mae, LSTM_spring_TC_pred = LSTM_model('spring')\n",
    "LSTM_summer_mae, LSTM_summer_TC_pred = LSTM_model('summer')\n",
    "LSTM_autumn_mae, LSTM_autumn_TC_pred = LSTM_model('autumn')\n",
    "LSTM_winter_mae, LSTM_winter_TC_pred = LSTM_model('winter')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fc54f4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert each dictionary to a DataFrame\n",
    "LSTM_spring_df = pd.DataFrame.from_dict(LSTM_spring_mae, orient='index', columns=['MAE'])\n",
    "LSTM_summer_df = pd.DataFrame.from_dict(LSTM_summer_mae, orient='index', columns=['MAE'])\n",
    "LSTM_autumn_df = pd.DataFrame.from_dict(LSTM_autumn_mae, orient='index', columns=['MAE'])\n",
    "LSTM_winter_df = pd.DataFrame.from_dict(LSTM_winter_mae, orient='index', columns=['MAE'])\n",
    "\n",
    "\n",
    "LSTM_mae_df = pd.concat([LSTM_spring_df, LSTM_summer_df, LSTM_autumn_df, LSTM_winter_df], axis=0)\n",
    "LSTM_mae_df.columns = ['LSTM_MAE']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d314baa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAE_df = pd.concat([linear_mae_df, xgb_mae_df, randomforest_mae_df, MLP_mae_df, ROCKET_mae_df, LIGHTGBM_mae_df, KNEIGHBORS_mae_df, LSTM_mae_df], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7061a334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>linear_MAE</th>\n",
       "      <th>xgb_MAE</th>\n",
       "      <th>randomforest_MAE</th>\n",
       "      <th>MLP_MAE</th>\n",
       "      <th>ROCKET_MAE</th>\n",
       "      <th>LIGHTGBM_MAE</th>\n",
       "      <th>KNEIGHBORS_MAE</th>\n",
       "      <th>LSTM_MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>146_spring</th>\n",
       "      <td>2.958766</td>\n",
       "      <td>2.860067</td>\n",
       "      <td>1.874011</td>\n",
       "      <td>3.128461</td>\n",
       "      <td>3.424482</td>\n",
       "      <td>3.006070</td>\n",
       "      <td>2.837316</td>\n",
       "      <td>3.180801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212_spring</th>\n",
       "      <td>2.497689</td>\n",
       "      <td>2.733979</td>\n",
       "      <td>2.730103</td>\n",
       "      <td>3.382251</td>\n",
       "      <td>3.710736</td>\n",
       "      <td>2.648066</td>\n",
       "      <td>3.064942</td>\n",
       "      <td>3.048517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245_spring</th>\n",
       "      <td>3.265469</td>\n",
       "      <td>2.935691</td>\n",
       "      <td>2.948562</td>\n",
       "      <td>2.819685</td>\n",
       "      <td>3.046481</td>\n",
       "      <td>3.009543</td>\n",
       "      <td>2.945654</td>\n",
       "      <td>2.775928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146_summer</th>\n",
       "      <td>2.392061</td>\n",
       "      <td>2.068598</td>\n",
       "      <td>1.105620</td>\n",
       "      <td>2.217413</td>\n",
       "      <td>2.511090</td>\n",
       "      <td>2.175785</td>\n",
       "      <td>2.024141</td>\n",
       "      <td>2.132910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212_summer</th>\n",
       "      <td>2.585919</td>\n",
       "      <td>2.508226</td>\n",
       "      <td>2.329581</td>\n",
       "      <td>2.720822</td>\n",
       "      <td>2.788610</td>\n",
       "      <td>2.404646</td>\n",
       "      <td>2.566502</td>\n",
       "      <td>2.271968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245_summer</th>\n",
       "      <td>3.056754</td>\n",
       "      <td>2.838604</td>\n",
       "      <td>2.794261</td>\n",
       "      <td>2.956115</td>\n",
       "      <td>3.091276</td>\n",
       "      <td>2.802043</td>\n",
       "      <td>2.908134</td>\n",
       "      <td>2.720606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146_autumn</th>\n",
       "      <td>1.628457</td>\n",
       "      <td>1.506823</td>\n",
       "      <td>0.766125</td>\n",
       "      <td>1.872520</td>\n",
       "      <td>1.945156</td>\n",
       "      <td>1.460923</td>\n",
       "      <td>1.477209</td>\n",
       "      <td>1.423678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212_autumn</th>\n",
       "      <td>1.968480</td>\n",
       "      <td>2.176668</td>\n",
       "      <td>1.947382</td>\n",
       "      <td>2.053449</td>\n",
       "      <td>2.218871</td>\n",
       "      <td>2.011332</td>\n",
       "      <td>2.013186</td>\n",
       "      <td>1.796450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245_autumn</th>\n",
       "      <td>2.111603</td>\n",
       "      <td>2.125981</td>\n",
       "      <td>2.161125</td>\n",
       "      <td>2.029369</td>\n",
       "      <td>2.597645</td>\n",
       "      <td>2.112772</td>\n",
       "      <td>2.294865</td>\n",
       "      <td>2.123052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146_winter</th>\n",
       "      <td>2.128955</td>\n",
       "      <td>1.665869</td>\n",
       "      <td>0.908747</td>\n",
       "      <td>1.855936</td>\n",
       "      <td>2.104441</td>\n",
       "      <td>1.794211</td>\n",
       "      <td>1.587083</td>\n",
       "      <td>1.700722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212_winter</th>\n",
       "      <td>2.544382</td>\n",
       "      <td>1.850723</td>\n",
       "      <td>1.858714</td>\n",
       "      <td>1.798033</td>\n",
       "      <td>2.114252</td>\n",
       "      <td>1.900934</td>\n",
       "      <td>1.943698</td>\n",
       "      <td>1.662010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245_winter</th>\n",
       "      <td>2.800569</td>\n",
       "      <td>2.309207</td>\n",
       "      <td>2.306708</td>\n",
       "      <td>2.262796</td>\n",
       "      <td>2.724552</td>\n",
       "      <td>2.299664</td>\n",
       "      <td>2.425334</td>\n",
       "      <td>2.307085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            linear_MAE   xgb_MAE  randomforest_MAE   MLP_MAE  ROCKET_MAE  \\\n",
       "146_spring    2.958766  2.860067          1.874011  3.128461    3.424482   \n",
       "212_spring    2.497689  2.733979          2.730103  3.382251    3.710736   \n",
       "245_spring    3.265469  2.935691          2.948562  2.819685    3.046481   \n",
       "146_summer    2.392061  2.068598          1.105620  2.217413    2.511090   \n",
       "212_summer    2.585919  2.508226          2.329581  2.720822    2.788610   \n",
       "245_summer    3.056754  2.838604          2.794261  2.956115    3.091276   \n",
       "146_autumn    1.628457  1.506823          0.766125  1.872520    1.945156   \n",
       "212_autumn    1.968480  2.176668          1.947382  2.053449    2.218871   \n",
       "245_autumn    2.111603  2.125981          2.161125  2.029369    2.597645   \n",
       "146_winter    2.128955  1.665869          0.908747  1.855936    2.104441   \n",
       "212_winter    2.544382  1.850723          1.858714  1.798033    2.114252   \n",
       "245_winter    2.800569  2.309207          2.306708  2.262796    2.724552   \n",
       "\n",
       "            LIGHTGBM_MAE  KNEIGHBORS_MAE  LSTM_MAE  \n",
       "146_spring      3.006070        2.837316  3.180801  \n",
       "212_spring      2.648066        3.064942  3.048517  \n",
       "245_spring      3.009543        2.945654  2.775928  \n",
       "146_summer      2.175785        2.024141  2.132910  \n",
       "212_summer      2.404646        2.566502  2.271968  \n",
       "245_summer      2.802043        2.908134  2.720606  \n",
       "146_autumn      1.460923        1.477209  1.423678  \n",
       "212_autumn      2.011332        2.013186  1.796450  \n",
       "245_autumn      2.112772        2.294865  2.123052  \n",
       "146_winter      1.794211        1.587083  1.700722  \n",
       "212_winter      1.900934        1.943698  1.662010  \n",
       "245_winter      2.299664        2.425334  2.307085  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAE_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "365db4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAE_df.to_csv('3MAE.csv', encoding = 'cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e555b31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
